{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zac Wellmer's Project 1\n",
    "# student id: 20363317\n",
    "## Imports of utility functions we will be using\n",
    "below we import the work for our residual network and deep hybrid scatter network. All the real 'heavy lifting' for this project was done in the resnet and ScatterTransform scripts. For a more detailed look at what's going on under the hood go give the scripts a peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/ubuntu/feature_viz/resnet')\n",
    "sys.path.append('/home/ubuntu/feature_viz/ScatteringTransform/src/model')\n",
    "from flags import define_flags as scatternet_define_flags\n",
    "from train_mnist import train_model as scatternet_train\n",
    "from res_features import train as resnet_train\n",
    "from visualize import visualize_features\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "x_test, y_test = mnist.test.next_batch(1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION WITH RESIDUAL NETWORK AND FINE TUNING\n",
    "## Resnet 50 pretrained from the Kth layer and higher\n",
    "Below we generate two different pretrained residual networks. In both cases we generate a 50 layer residual network. The network variables are initialized with the values from a pretrained imagenet model. The difference between these two models is that one freezes weights before layer k while the other network leaves all variables as trainable. The inspiration behind this type of pretraining is because the initial layers of a CNN are learning features which are generally task invariant. As a result of this we make the assumption that the layers before K are \"good enough\" and our training should be spent on tuning the layers >= K.\n",
    "\n",
    "In the case of both resnets we stack an additional 3 fully connected layers on top of the flattened previously generated features. The first 2 layers use recified linear units as activation functions followed by a final layer which uses a softmax. All 3 of these layers initialize weights with a uniform Xavier initializer. More information on the motivation behind Xavier initializers can be found [here](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "The purpose of the final 3 stacked fully connected layers is to generate logits for classification. These layers can be thought of as replacements to the final fully connected layers generating logits for the 1000 imagenet classes. In addition to a classification mismatch between imagenet and MNIST we do not take variables from these layers because they are far more task dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/feature_viz/resnet/resnet_v1_50.ckpt\n",
      "iter 0 train accuracy: 0.0703125\n",
      "iter 100 test accuracy: 0.7599999904632568\n",
      "EPOCH:  0\n",
      "saving after 100 iterations\n",
      "iter 100 train accuracy: 0.78125\n",
      "iter 200 test accuracy: 0.7200000286102295\n",
      "EPOCH:  0\n",
      "saving after 200 iterations\n",
      "iter 200 train accuracy: 0.8359375\n",
      "iter 300 test accuracy: 0.8899999856948853\n",
      "EPOCH:  0\n",
      "saving after 300 iterations\n",
      "iter 300 train accuracy: 0.8984375\n",
      "iter 400 test accuracy: 0.8399999737739563\n",
      "EPOCH:  0\n",
      "saving after 400 iterations\n",
      "iter 400 train accuracy: 0.8984375\n",
      "iter 500 test accuracy: 0.9399999976158142\n",
      "EPOCH:  1\n",
      "saving after 500 iterations\n",
      "iter 500 train accuracy: 0.9140625\n",
      "iter 600 test accuracy: 0.8700000047683716\n",
      "EPOCH:  1\n",
      "saving after 600 iterations\n",
      "iter 600 train accuracy: 0.9140625\n",
      "iter 700 test accuracy: 0.9100000262260437\n",
      "EPOCH:  1\n",
      "saving after 700 iterations\n",
      "iter 700 train accuracy: 0.921875\n",
      "iter 800 test accuracy: 0.8899999856948853\n",
      "EPOCH:  1\n",
      "saving after 800 iterations\n",
      "iter 800 train accuracy: 0.9375\n",
      "iter 900 test accuracy: 0.9200000166893005\n",
      "EPOCH:  2\n",
      "saving after 900 iterations\n",
      "iter 900 train accuracy: 0.953125\n",
      "iter 1000 test accuracy: 0.9200000166893005\n",
      "EPOCH:  2\n",
      "saving after 1000 iterations\n",
      "iter 1000 train accuracy: 0.890625\n",
      "iter 1100 test accuracy: 0.9800000190734863\n",
      "EPOCH:  2\n",
      "saving after 1100 iterations\n",
      "iter 1100 train accuracy: 0.9375\n",
      "iter 1200 test accuracy: 0.9599999785423279\n",
      "EPOCH:  2\n",
      "saving after 1200 iterations\n",
      "iter 1200 train accuracy: 0.953125\n",
      "iter 1300 test accuracy: 0.9399999976158142\n",
      "EPOCH:  3\n",
      "saving after 1300 iterations\n",
      "iter 1300 train accuracy: 0.953125\n",
      "iter 1400 test accuracy: 0.9300000071525574\n",
      "EPOCH:  3\n",
      "saving after 1400 iterations\n",
      "iter 1400 train accuracy: 0.9296875\n",
      "iter 1500 test accuracy: 0.9800000190734863\n",
      "EPOCH:  3\n",
      "saving after 1500 iterations\n",
      "iter 1500 train accuracy: 0.9609375\n",
      "iter 1600 test accuracy: 0.9599999785423279\n",
      "EPOCH:  3\n",
      "saving after 1600 iterations\n",
      "iter 1600 train accuracy: 0.96875\n",
      "iter 1700 test accuracy: 0.9100000262260437\n",
      "EPOCH:  3\n",
      "saving after 1700 iterations\n",
      "iter 1700 train accuracy: 0.9375\n",
      "iter 1800 test accuracy: 0.9800000190734863\n",
      "EPOCH:  4\n",
      "saving after 1800 iterations\n",
      "iter 1800 train accuracy: 0.9140625\n",
      "iter 1900 test accuracy: 0.9399999976158142\n",
      "EPOCH:  4\n",
      "saving after 1900 iterations\n",
      "iter 1900 train accuracy: 0.953125\n",
      "iter 2000 test accuracy: 0.9800000190734863\n",
      "EPOCH:  4\n",
      "saving after 2000 iterations\n",
      "iter 2000 train accuracy: 0.8984375\n",
      "iter 2100 test accuracy: 0.9599999785423279\n",
      "EPOCH:  4\n",
      "saving after 2100 iterations\n",
      "iter 2100 train accuracy: 0.9765625\n",
      "iter 2200 test accuracy: 0.9599999785423279\n",
      "EPOCH:  5\n",
      "saving after 2200 iterations\n",
      "iter 2200 train accuracy: 0.9609375\n",
      "iter 2300 test accuracy: 0.9200000166893005\n",
      "EPOCH:  5\n",
      "saving after 2300 iterations\n",
      "iter 2300 train accuracy: 0.96875\n",
      "iter 2400 test accuracy: 0.8899999856948853\n",
      "EPOCH:  5\n",
      "saving after 2400 iterations\n",
      "iter 2400 train accuracy: 0.953125\n",
      "iter 2500 test accuracy: 0.949999988079071\n",
      "EPOCH:  5\n",
      "saving after 2500 iterations\n",
      "iter 2500 train accuracy: 0.9609375\n",
      "iter 2600 test accuracy: 0.949999988079071\n",
      "EPOCH:  6\n",
      "saving after 2600 iterations\n",
      "iter 2600 train accuracy: 0.984375\n",
      "iter 2700 test accuracy: 0.9300000071525574\n",
      "EPOCH:  6\n",
      "saving after 2700 iterations\n",
      "iter 2700 train accuracy: 0.921875\n",
      "iter 2800 test accuracy: 0.9700000286102295\n",
      "EPOCH:  6\n",
      "saving after 2800 iterations\n",
      "iter 2800 train accuracy: 0.9921875\n",
      "iter 2900 test accuracy: 0.9700000286102295\n",
      "EPOCH:  6\n",
      "saving after 2900 iterations\n",
      "iter 2900 train accuracy: 0.96875\n",
      "iter 3000 test accuracy: 0.9300000071525574\n",
      "EPOCH:  6\n",
      "saving after 3000 iterations\n",
      "iter 3000 train accuracy: 0.96875\n",
      "iter 3100 test accuracy: 0.9599999785423279\n",
      "EPOCH:  7\n",
      "saving after 3100 iterations\n",
      "iter 3100 train accuracy: 0.9609375\n",
      "iter 3200 test accuracy: 0.9100000262260437\n",
      "EPOCH:  7\n",
      "saving after 3200 iterations\n",
      "iter 3200 train accuracy: 0.921875\n",
      "iter 3300 test accuracy: 0.9599999785423279\n",
      "EPOCH:  7\n",
      "saving after 3300 iterations\n",
      "iter 3300 train accuracy: 0.9375\n",
      "iter 3400 test accuracy: 0.9599999785423279\n",
      "EPOCH:  7\n",
      "saving after 3400 iterations\n",
      "iter 3400 train accuracy: 0.9609375\n",
      "iter 3500 test accuracy: 0.9800000190734863\n",
      "EPOCH:  8\n",
      "saving after 3500 iterations\n",
      "iter 3500 train accuracy: 0.9765625\n",
      "iter 3600 test accuracy: 0.9800000190734863\n",
      "EPOCH:  8\n",
      "saving after 3600 iterations\n",
      "iter 3600 train accuracy: 0.9453125\n",
      "iter 3700 test accuracy: 0.9800000190734863\n",
      "EPOCH:  8\n",
      "saving after 3700 iterations\n",
      "iter 3700 train accuracy: 0.9296875\n",
      "iter 3800 test accuracy: 0.9700000286102295\n",
      "EPOCH:  8\n",
      "saving after 3800 iterations\n",
      "iter 3800 train accuracy: 0.9609375\n",
      "iter 3900 test accuracy: 0.9300000071525574\n",
      "EPOCH:  9\n",
      "saving after 3900 iterations\n",
      "iter 3900 train accuracy: 0.8984375\n",
      "iter 4000 test accuracy: 0.9300000071525574\n",
      "EPOCH:  9\n",
      "saving after 4000 iterations\n",
      "iter 4000 train accuracy: 0.953125\n",
      "iter 4100 test accuracy: 0.9399999976158142\n",
      "EPOCH:  9\n",
      "saving after 4100 iterations\n",
      "iter 4100 train accuracy: 0.953125\n",
      "iter 4200 test accuracy: 0.9200000166893005\n",
      "EPOCH:  9\n",
      "saving after 4200 iterations\n",
      "iter 4200 train accuracy: 0.96875\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/feature_viz/resnet/resnet_v1_50.ckpt\n",
      "iter 0 train accuracy: 0.1328125\n",
      "iter 100 test accuracy: 0.9300000071525574\n",
      "EPOCH:  0\n",
      "saving after 100 iterations\n",
      "iter 100 train accuracy: 0.9140625\n",
      "iter 200 test accuracy: 0.949999988079071\n",
      "EPOCH:  0\n",
      "saving after 200 iterations\n",
      "iter 200 train accuracy: 0.984375\n",
      "iter 300 test accuracy: 0.949999988079071\n",
      "EPOCH:  0\n",
      "saving after 300 iterations\n",
      "iter 300 train accuracy: 0.9765625\n",
      "iter 400 test accuracy: 0.9599999785423279\n",
      "EPOCH:  0\n",
      "saving after 400 iterations\n",
      "iter 400 train accuracy: 0.9921875\n",
      "iter 500 test accuracy: 0.9599999785423279\n",
      "EPOCH:  1\n",
      "saving after 500 iterations\n",
      "iter 500 train accuracy: 0.9765625\n",
      "iter 600 test accuracy: 0.9800000190734863\n",
      "EPOCH:  1\n",
      "saving after 600 iterations\n",
      "iter 600 train accuracy: 0.96875\n",
      "iter 700 test accuracy: 0.9800000190734863\n",
      "EPOCH:  1\n",
      "saving after 700 iterations\n",
      "iter 700 train accuracy: 0.984375\n",
      "iter 800 test accuracy: 1.0\n",
      "EPOCH:  1\n",
      "saving after 800 iterations\n",
      "iter 800 train accuracy: 0.9921875\n",
      "iter 900 test accuracy: 1.0\n",
      "EPOCH:  2\n",
      "saving after 900 iterations\n",
      "iter 900 train accuracy: 0.9921875\n",
      "iter 1000 test accuracy: 1.0\n",
      "EPOCH:  2\n",
      "saving after 1000 iterations\n",
      "iter 1000 train accuracy: 0.96875\n",
      "iter 1100 test accuracy: 0.949999988079071\n",
      "EPOCH:  2\n",
      "saving after 1100 iterations\n",
      "iter 1100 train accuracy: 0.9921875\n",
      "iter 1200 test accuracy: 1.0\n",
      "EPOCH:  2\n",
      "saving after 1200 iterations\n",
      "iter 1200 train accuracy: 0.9609375\n",
      "iter 1300 test accuracy: 1.0\n",
      "EPOCH:  3\n",
      "saving after 1300 iterations\n",
      "iter 1300 train accuracy: 0.984375\n",
      "iter 1400 test accuracy: 0.9599999785423279\n",
      "EPOCH:  3\n",
      "saving after 1400 iterations\n",
      "iter 1400 train accuracy: 0.96875\n",
      "iter 1500 test accuracy: 0.9900000095367432\n",
      "EPOCH:  3\n",
      "saving after 1500 iterations\n",
      "iter 1500 train accuracy: 0.984375\n",
      "iter 1600 test accuracy: 1.0\n",
      "EPOCH:  3\n",
      "saving after 1600 iterations\n",
      "iter 1600 train accuracy: 0.9921875\n",
      "iter 1700 test accuracy: 0.9900000095367432\n",
      "EPOCH:  3\n",
      "saving after 1700 iterations\n",
      "iter 1700 train accuracy: 0.9765625\n",
      "iter 1800 test accuracy: 0.9900000095367432\n",
      "EPOCH:  4\n",
      "saving after 1800 iterations\n",
      "iter 1800 train accuracy: 0.984375\n",
      "iter 1900 test accuracy: 0.9900000095367432\n",
      "EPOCH:  4\n",
      "saving after 1900 iterations\n",
      "iter 1900 train accuracy: 1.0\n",
      "iter 2000 test accuracy: 0.9900000095367432\n",
      "EPOCH:  4\n",
      "saving after 2000 iterations\n",
      "iter 2000 train accuracy: 0.9921875\n",
      "iter 2100 test accuracy: 0.9800000190734863\n",
      "EPOCH:  4\n",
      "saving after 2100 iterations\n",
      "iter 2100 train accuracy: 0.953125\n",
      "iter 2200 test accuracy: 1.0\n",
      "EPOCH:  5\n",
      "saving after 2200 iterations\n",
      "iter 2200 train accuracy: 1.0\n",
      "iter 2300 test accuracy: 0.9900000095367432\n",
      "EPOCH:  5\n",
      "saving after 2300 iterations\n",
      "iter 2300 train accuracy: 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2400 test accuracy: 0.9700000286102295\n",
      "EPOCH:  5\n",
      "saving after 2400 iterations\n",
      "iter 2400 train accuracy: 0.9921875\n",
      "iter 2500 test accuracy: 0.9900000095367432\n",
      "EPOCH:  5\n",
      "saving after 2500 iterations\n",
      "iter 2500 train accuracy: 0.9765625\n",
      "iter 2600 test accuracy: 0.9800000190734863\n",
      "EPOCH:  6\n",
      "saving after 2600 iterations\n",
      "iter 2600 train accuracy: 0.9921875\n",
      "iter 2700 test accuracy: 0.9900000095367432\n",
      "EPOCH:  6\n",
      "saving after 2700 iterations\n",
      "iter 2700 train accuracy: 0.9921875\n",
      "iter 2800 test accuracy: 0.9900000095367432\n",
      "EPOCH:  6\n",
      "saving after 2800 iterations\n",
      "iter 2800 train accuracy: 0.9921875\n",
      "iter 2900 test accuracy: 0.9700000286102295\n",
      "EPOCH:  6\n",
      "saving after 2900 iterations\n",
      "iter 2900 train accuracy: 1.0\n",
      "iter 3000 test accuracy: 1.0\n",
      "EPOCH:  6\n",
      "saving after 3000 iterations\n",
      "iter 3000 train accuracy: 0.984375\n",
      "iter 3100 test accuracy: 1.0\n",
      "EPOCH:  7\n",
      "saving after 3100 iterations\n",
      "iter 3100 train accuracy: 0.9921875\n",
      "iter 3200 test accuracy: 1.0\n",
      "EPOCH:  7\n",
      "saving after 3200 iterations\n",
      "iter 3200 train accuracy: 0.984375\n",
      "iter 3300 test accuracy: 0.9800000190734863\n",
      "EPOCH:  7\n",
      "saving after 3300 iterations\n",
      "iter 3300 train accuracy: 1.0\n",
      "iter 3400 test accuracy: 0.9900000095367432\n",
      "EPOCH:  7\n",
      "saving after 3400 iterations\n",
      "iter 3400 train accuracy: 0.984375\n",
      "iter 3500 test accuracy: 0.9800000190734863\n",
      "EPOCH:  8\n",
      "saving after 3500 iterations\n",
      "iter 3500 train accuracy: 0.9921875\n",
      "iter 3600 test accuracy: 0.9800000190734863\n",
      "EPOCH:  8\n",
      "saving after 3600 iterations\n",
      "iter 3600 train accuracy: 1.0\n",
      "iter 3700 test accuracy: 0.9700000286102295\n",
      "EPOCH:  8\n",
      "saving after 3700 iterations\n",
      "iter 3700 train accuracy: 0.984375\n",
      "iter 3800 test accuracy: 0.9800000190734863\n",
      "EPOCH:  8\n",
      "saving after 3800 iterations\n",
      "iter 3800 train accuracy: 0.9921875\n",
      "iter 3900 test accuracy: 0.9700000286102295\n",
      "EPOCH:  9\n",
      "saving after 3900 iterations\n",
      "iter 3900 train accuracy: 1.0\n",
      "iter 4000 test accuracy: 0.9800000190734863\n",
      "EPOCH:  9\n",
      "saving after 4000 iterations\n",
      "iter 4000 train accuracy: 0.9765625\n",
      "iter 4100 test accuracy: 0.9700000286102295\n",
      "EPOCH:  9\n",
      "saving after 4100 iterations\n",
      "iter 4100 train accuracy: 0.9921875\n",
      "iter 4200 test accuracy: 1.0\n",
      "EPOCH:  9\n",
      "saving after 4200 iterations\n",
      "iter 4200 train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "resnet_classifier_k = resnet_train(freeze_before_k=3) # all blocks before block k are frozen for training\n",
    "resnet_k_features_test = resnet_classifier_k.get_features(x_test)\n",
    "\n",
    "tf.reset_default_graph() # clear graph for classifier_0\n",
    "resnet_classifier_0 = resnet_train(freeze_before_k=0)\n",
    "resnet_0_features_test = resnet_classifier_0.get_features(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION WITH SCATTER NETWORK\n",
    "## Scatternet Training and Testing on MNIST\n",
    "The work for scatternet was mostly based off the work done by [tdeboissiere](https://github.com/tdeboissiere) found [here](https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/ScatteringTransform). This scatter network is actually a bit different than the scatter network found in Brunna & Mallat's work. What we analyze here is  a deep hybrid scatter network. We use scatter transforms similar to those found in [Brunna & Mallat's work](https://arxiv.org/abs/1203.1513) followed by a few convolutional layers and fully connected layers. A detailed explanation of how this works can be found in Oyallon's [Deep Hybrid Networks paper](https://arxiv.org/abs/1703.08961)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up TF session:\n",
      "\n",
      "Configuring directories:\n",
      "[Deleting] /home/ubuntu/feature_viz/ScatteringTransform/src/logs\n",
      "[Deleting] /home/ubuntu/feature_viz/ScatteringTransform/src/models\n",
      "[Deleting] /home/ubuntu/feature_viz/ScatteringTransform/src/figures\n",
      "[Creating] /home/ubuntu/feature_viz/ScatteringTransform/src/logs\n",
      "[Creating] /home/ubuntu/feature_viz/ScatteringTransform/src/models\n",
      "[Creating] /home/ubuntu/feature_viz/ScatteringTransform/src/figures\n",
      "Extracting /home/ubuntu/feature_viz/ScatteringTransform/src/data/raw/train-images-idx3-ubyte.gz\n",
      "Extracting /home/ubuntu/feature_viz/ScatteringTransform/src/data/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/ubuntu/feature_viz/ScatteringTransform/src/data/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/ubuntu/feature_viz/ScatteringTransform/src/data/raw/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Summary name HCNN/CONV2D/conv2d/w:0 is illegal; using HCNN/CONV2D/conv2d/w_0 instead.\n",
      "INFO:tensorflow:Summary name HCNN/CONV2D/conv2d/b:0 is illegal; using HCNN/CONV2D/conv2d/b_0 instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense1/w:0 is illegal; using HCNN/dense1/w_0 instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense1/b:0 is illegal; using HCNN/dense1/b_0 instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense2/w:0 is illegal; using HCNN/dense2/w_0 instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense2/b:0 is illegal; using HCNN/dense2/b_0 instead.\n",
      "INFO:tensorflow:Summary name HCNN/scat_bn/beta:0/gradient is illegal; using HCNN/scat_bn/beta_0/gradient instead.\n",
      "INFO:tensorflow:Summary name HCNN/CONV2D/conv2d/w:0/gradient is illegal; using HCNN/CONV2D/conv2d/w_0/gradient instead.\n",
      "INFO:tensorflow:Summary name HCNN/CONV2D/conv2d/b:0/gradient is illegal; using HCNN/CONV2D/conv2d/b_0/gradient instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense1/w:0/gradient is illegal; using HCNN/dense1/w_0/gradient instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense1/b:0/gradient is illegal; using HCNN/dense1/b_0/gradient instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense2/w:0/gradient is illegal; using HCNN/dense2/w_0/gradient instead.\n",
      "INFO:tensorflow:Summary name HCNN/dense2/b:0/gradient is illegal; using HCNN/dense2/b_0/gradient instead.\n",
      "\n",
      "Initialization:\n",
      "[Created session saver] \n",
      "[Ran init ops] \n",
      "\n",
      "Queues:\n",
      "[Created coordinator] \n",
      "[Started queue runner] \n",
      "\n",
      "Summaries:\n",
      "[HCNN/CONV2D/conv2d/HCNN/CONV2D/conv2d/w_0:0] \n",
      "[HCNN/CONV2D/conv2d/HCNN/CONV2D/conv2d/b_0:0] \n",
      "[HCNN/dense1/HCNN/dense1/w_0:0] \n",
      "[HCNN/dense1/HCNN/dense1/b_0:0] \n",
      "[HCNN/dense2/HCNN/dense2/w_0:0] \n",
      "[HCNN/dense2/HCNN/dense2/b_0:0] \n",
      "[HCNN/scat_bn/beta_0/gradient:0] \n",
      "[HCNN/CONV2D/conv2d/w_0/gradient:0] \n",
      "[HCNN/CONV2D/conv2d/b_0/gradient:0] \n",
      "[HCNN/dense1/w_0/gradient:0] \n",
      "[HCNN/dense1/b_0/gradient:0] \n",
      "[HCNN/dense2/w_0/gradient:0] \n",
      "[HCNN/dense2/b_0/gradient:0] \n",
      "[loss:0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 0: - train loss: 2.32 val loss: 2.43 - train acc: 0.18 val acc: 0.11:   0%|          | 0/30 [00:03<?, ?it/s]\n",
      "Epoch 0: - train loss: 2.32 val loss: 2.43 - train acc: 0.18 val acc: 0.11:   3%|▎         | 1/30 [00:03<01:37,  3.37s/it]\n",
      "Epoch 0: - train loss: 2.40 val loss: 2.41 - train acc: 0.08 val acc: 0.15:   3%|▎         | 1/30 [00:03<01:47,  3.69s/it]\n",
      "Epoch 0: - train loss: 2.37 val loss: 2.32 - train acc: 0.19 val acc: 0.15:   3%|▎         | 1/30 [00:03<01:55,  4.00s/it]\n",
      "Epoch 0: - train loss: 2.37 val loss: 2.32 - train acc: 0.19 val acc: 0.15:  10%|█         | 3/30 [00:04<00:36,  1.33s/it]\n",
      "Epoch 0: - train loss: 2.38 val loss: 2.31 - train acc: 0.12 val acc: 0.15:  10%|█         | 3/30 [00:04<00:38,  1.43s/it]\n",
      "Epoch 0: - train loss: 2.35 val loss: 2.24 - train acc: 0.14 val acc: 0.20:  10%|█         | 3/30 [00:04<00:41,  1.53s/it]\n",
      "Epoch 0: - train loss: 2.35 val loss: 2.24 - train acc: 0.14 val acc: 0.20:  17%|█▋        | 5/30 [00:04<00:22,  1.09it/s]\n",
      "Epoch 0: - train loss: 2.29 val loss: 2.37 - train acc: 0.16 val acc: 0.10:  17%|█▋        | 5/30 [00:04<00:24,  1.02it/s]\n",
      "Epoch 0: - train loss: 2.27 val loss: 2.31 - train acc: 0.16 val acc: 0.12:  17%|█▋        | 5/30 [00:05<00:25,  1.04s/it]\n",
      "Epoch 0: - train loss: 2.27 val loss: 2.31 - train acc: 0.16 val acc: 0.12:  23%|██▎       | 7/30 [00:05<00:17,  1.35it/s]\n",
      "Epoch 0: - train loss: 2.33 val loss: 2.26 - train acc: 0.20 val acc: 0.17:  23%|██▎       | 7/30 [00:05<00:18,  1.28it/s]\n",
      "Epoch 0: - train loss: 2.29 val loss: 2.30 - train acc: 0.19 val acc: 0.17:  23%|██▎       | 7/30 [00:05<00:18,  1.21it/s]\n",
      "Epoch 0: - train loss: 2.29 val loss: 2.30 - train acc: 0.19 val acc: 0.17:  30%|███       | 9/30 [00:05<00:13,  1.56it/s]\n",
      "Epoch 0: - train loss: 2.34 val loss: 2.26 - train acc: 0.11 val acc: 0.15:  30%|███       | 9/30 [00:06<00:14,  1.48it/s]\n",
      "Epoch 0: - train loss: 2.30 val loss: 2.22 - train acc: 0.18 val acc: 0.22:  30%|███       | 9/30 [00:06<00:14,  1.41it/s]\n",
      "Epoch 0: - train loss: 2.30 val loss: 2.22 - train acc: 0.18 val acc: 0.22:  37%|███▋      | 11/30 [00:06<00:10,  1.73it/s]\n",
      "Epoch 0: - train loss: 2.19 val loss: 2.24 - train acc: 0.25 val acc: 0.17:  37%|███▋      | 11/30 [00:06<00:11,  1.65it/s]\n",
      "Epoch 0: - train loss: 2.24 val loss: 2.26 - train acc: 0.22 val acc: 0.16:  37%|███▋      | 11/30 [00:06<00:12,  1.58it/s]\n",
      "Epoch 0: - train loss: 2.24 val loss: 2.26 - train acc: 0.22 val acc: 0.16:  43%|████▎     | 13/30 [00:06<00:09,  1.87it/s]\n",
      "Epoch 0: - train loss: 2.23 val loss: 2.21 - train acc: 0.20 val acc: 0.20:  43%|████▎     | 13/30 [00:07<00:09,  1.79it/s]\n",
      "Epoch 0: - train loss: 2.18 val loss: 2.21 - train acc: 0.23 val acc: 0.24:  43%|████▎     | 13/30 [00:07<00:09,  1.72it/s]\n",
      "Epoch 0: - train loss: 2.18 val loss: 2.21 - train acc: 0.23 val acc: 0.24:  50%|█████     | 15/30 [00:07<00:07,  1.99it/s]\n",
      "Epoch 0: - train loss: 2.26 val loss: 2.25 - train acc: 0.20 val acc: 0.16:  50%|█████     | 15/30 [00:07<00:07,  1.91it/s]\n",
      "Epoch 0: - train loss: 2.24 val loss: 2.22 - train acc: 0.14 val acc: 0.16:  50%|█████     | 15/30 [00:08<00:08,  1.84it/s]\n",
      "Epoch 0: - train loss: 2.24 val loss: 2.22 - train acc: 0.14 val acc: 0.16:  57%|█████▋    | 17/30 [00:08<00:06,  2.09it/s]\n",
      "Epoch 0: - train loss: 2.19 val loss: 2.22 - train acc: 0.17 val acc: 0.16:  57%|█████▋    | 17/30 [00:08<00:06,  2.01it/s]\n",
      "Epoch 0: - train loss: 2.17 val loss: 2.22 - train acc: 0.26 val acc: 0.17:  57%|█████▋    | 17/30 [00:08<00:06,  1.94it/s]\n",
      "Epoch 0: - train loss: 2.17 val loss: 2.22 - train acc: 0.26 val acc: 0.17:  63%|██████▎   | 19/30 [00:08<00:05,  2.17it/s]\n",
      "Epoch 0: - train loss: 2.20 val loss: 2.14 - train acc: 0.26 val acc: 0.23:  63%|██████▎   | 19/30 [00:09<00:05,  2.10it/s]\n",
      "Epoch 0: - train loss: 2.22 val loss: 2.22 - train acc: 0.18 val acc: 0.22:  63%|██████▎   | 19/30 [00:09<00:05,  2.03it/s]\n",
      "Epoch 0: - train loss: 2.22 val loss: 2.22 - train acc: 0.18 val acc: 0.22:  70%|███████   | 21/30 [00:09<00:04,  2.25it/s]\n",
      "Epoch 0: - train loss: 2.18 val loss: 2.16 - train acc: 0.25 val acc: 0.20:  70%|███████   | 21/30 [00:09<00:04,  2.17it/s]\n",
      "Epoch 0: - train loss: 2.18 val loss: 2.19 - train acc: 0.21 val acc: 0.21:  70%|███████   | 21/30 [00:09<00:04,  2.11it/s]\n",
      "Epoch 0: - train loss: 2.18 val loss: 2.19 - train acc: 0.21 val acc: 0.21:  77%|███████▋  | 23/30 [00:09<00:03,  2.31it/s]\n",
      "Epoch 0: - train loss: 2.11 val loss: 2.15 - train acc: 0.27 val acc: 0.23:  77%|███████▋  | 23/30 [00:10<00:03,  2.23it/s]\n",
      "Epoch 0: - train loss: 2.13 val loss: 2.14 - train acc: 0.25 val acc: 0.27:  77%|███████▋  | 23/30 [00:10<00:03,  2.17it/s]\n",
      "Epoch 0: - train loss: 2.13 val loss: 2.14 - train acc: 0.25 val acc: 0.27:  83%|████████▎ | 25/30 [00:10<00:02,  2.36it/s]\n",
      "Epoch 0: - train loss: 2.12 val loss: 2.13 - train acc: 0.28 val acc: 0.27:  83%|████████▎ | 25/30 [00:10<00:02,  2.30it/s]\n",
      "Epoch 0: - train loss: 2.06 val loss: 2.08 - train acc: 0.30 val acc: 0.34:  83%|████████▎ | 25/30 [00:11<00:02,  2.24it/s]\n",
      "Epoch 0: - train loss: 2.06 val loss: 2.08 - train acc: 0.30 val acc: 0.34:  90%|█████████ | 27/30 [00:11<00:01,  2.42it/s]\n",
      "Epoch 0: - train loss: 2.10 val loss: 2.11 - train acc: 0.31 val acc: 0.30:  90%|█████████ | 27/30 [00:11<00:01,  2.36it/s]\n",
      "Epoch 0: - train loss: 2.09 val loss: 2.14 - train acc: 0.30 val acc: 0.26:  90%|█████████ | 27/30 [00:11<00:01,  2.29it/s]\n",
      "Epoch 0: - train loss: 2.09 val loss: 2.14 - train acc: 0.30 val acc: 0.26:  97%|█████████▋| 29/30 [00:11<00:00,  2.46it/s]\n",
      "Epoch 0: - train loss: 2.15 val loss: 2.06 - train acc: 0.26 val acc: 0.32:  97%|█████████▋| 29/30 [00:12<00:00,  2.40it/s]\n",
      "Training progress:   3%|▎         | 1/30 [00:12<05:50, 12.08s/it]acc: 0.32: 100%|██████████| 30/30 [00:12<00:00,  2.48it/s]\n",
      "Epoch 1:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 1: - train loss: 2.06 val loss: 2.03 - train acc: 0.35 val acc: 0.38:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 1: - train loss: 2.05 val loss: 2.07 - train acc: 0.36 val acc: 0.34:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 1: - train loss: 2.05 val loss: 2.07 - train acc: 0.36 val acc: 0.34:   7%|▋         | 2/30 [00:00<00:08,  3.41it/s]\n",
      "Epoch 1: - train loss: 2.13 val loss: 2.13 - train acc: 0.24 val acc: 0.32:   7%|▋         | 2/30 [00:00<00:12,  2.28it/s]\n",
      "Epoch 1: - train loss: 2.01 val loss: 2.07 - train acc: 0.36 val acc: 0.34:   7%|▋         | 2/30 [00:01<00:16,  1.71it/s]\n",
      "Epoch 1: - train loss: 2.01 val loss: 2.07 - train acc: 0.36 val acc: 0.34:  13%|█▎        | 4/30 [00:01<00:07,  3.41it/s]\n",
      "Epoch 1: - train loss: 2.07 val loss: 2.05 - train acc: 0.38 val acc: 0.34:  13%|█▎        | 4/30 [00:01<00:09,  2.73it/s]\n",
      "Epoch 1: - train loss: 2.05 val loss: 2.04 - train acc: 0.34 val acc: 0.38:  13%|█▎        | 4/30 [00:01<00:11,  2.28it/s]\n",
      "Epoch 1: - train loss: 2.05 val loss: 2.04 - train acc: 0.34 val acc: 0.38:  20%|██        | 6/30 [00:01<00:07,  3.41it/s]\n",
      "Epoch 1: - train loss: 2.03 val loss: 2.09 - train acc: 0.34 val acc: 0.29:  20%|██        | 6/30 [00:02<00:08,  2.92it/s]\n",
      "Epoch 1: - train loss: 2.07 val loss: 2.04 - train acc: 0.35 val acc: 0.35:  20%|██        | 6/30 [00:02<00:09,  2.56it/s]\n",
      "Epoch 1: - train loss: 2.07 val loss: 2.04 - train acc: 0.35 val acc: 0.35:  27%|██▋       | 8/30 [00:02<00:06,  3.41it/s]\n",
      "Epoch 1: - train loss: 1.98 val loss: 1.97 - train acc: 0.40 val acc: 0.48:  27%|██▋       | 8/30 [00:02<00:07,  3.03it/s]\n",
      "Epoch 1: - train loss: 2.00 val loss: 1.98 - train acc: 0.38 val acc: 0.47:  27%|██▋       | 8/30 [00:02<00:08,  2.73it/s]\n",
      "Epoch 1: - train loss: 2.00 val loss: 1.98 - train acc: 0.38 val acc: 0.47:  33%|███▎      | 10/30 [00:02<00:05,  3.41it/s]\n",
      "Epoch 1: - train loss: 2.07 val loss: 2.02 - train acc: 0.31 val acc: 0.37:  33%|███▎      | 10/30 [00:03<00:06,  3.08it/s]\n",
      "Epoch 1: - train loss: 2.01 val loss: 2.04 - train acc: 0.42 val acc: 0.40:  33%|███▎      | 10/30 [00:03<00:07,  2.80it/s]\n",
      "Epoch 1: - train loss: 2.01 val loss: 2.04 - train acc: 0.42 val acc: 0.40:  40%|████      | 12/30 [00:03<00:05,  3.36it/s]\n",
      "Epoch 1: - train loss: 2.00 val loss: 2.02 - train acc: 0.42 val acc: 0.39:  40%|████      | 12/30 [00:03<00:05,  3.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: - train loss: 2.06 val loss: 2.01 - train acc: 0.34 val acc: 0.45:  40%|████      | 12/30 [00:04<00:06,  2.87it/s]\n",
      "Epoch 1: - train loss: 2.06 val loss: 2.01 - train acc: 0.34 val acc: 0.45:  47%|████▋     | 14/30 [00:04<00:04,  3.35it/s]\n",
      "Epoch 1: - train loss: 1.95 val loss: 1.99 - train acc: 0.45 val acc: 0.40:  47%|████▋     | 14/30 [00:04<00:05,  3.13it/s]\n",
      "Epoch 1: - train loss: 1.96 val loss: 1.99 - train acc: 0.45 val acc: 0.41:  47%|████▋     | 14/30 [00:04<00:05,  2.94it/s]\n",
      "Epoch 1: - train loss: 1.96 val loss: 1.99 - train acc: 0.45 val acc: 0.41:  53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s]\n",
      "Epoch 1: - train loss: 1.95 val loss: 1.94 - train acc: 0.38 val acc: 0.45:  53%|█████▎    | 16/30 [00:05<00:04,  3.17it/s]\n",
      "Epoch 1: - train loss: 1.99 val loss: 1.93 - train acc: 0.40 val acc: 0.45:  53%|█████▎    | 16/30 [00:05<00:04,  2.99it/s]\n",
      "Epoch 1: - train loss: 1.99 val loss: 1.93 - train acc: 0.40 val acc: 0.45:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 1: - train loss: 1.97 val loss: 1.94 - train acc: 0.38 val acc: 0.48:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 1: - train loss: 1.99 val loss: 1.96 - train acc: 0.39 val acc: 0.38:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 1: - train loss: 1.99 val loss: 1.96 - train acc: 0.39 val acc: 0.38:  67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s]\n",
      "Epoch 1: - train loss: 1.90 val loss: 1.91 - train acc: 0.45 val acc: 0.48:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 1: - train loss: 1.90 val loss: 1.91 - train acc: 0.49 val acc: 0.48:  67%|██████▋   | 20/30 [00:06<00:03,  3.07it/s]\n",
      "Epoch 1: - train loss: 1.90 val loss: 1.91 - train acc: 0.49 val acc: 0.48:  73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s]\n",
      "Epoch 1: - train loss: 1.90 val loss: 1.87 - train acc: 0.49 val acc: 0.55:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 1: - train loss: 1.91 val loss: 1.99 - train acc: 0.42 val acc: 0.41:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 1: - train loss: 1.91 val loss: 1.99 - train acc: 0.42 val acc: 0.41:  80%|████████  | 24/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 1: - train loss: 1.88 val loss: 1.93 - train acc: 0.50 val acc: 0.46:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 1: - train loss: 1.88 val loss: 1.89 - train acc: 0.48 val acc: 0.52:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 1: - train loss: 1.88 val loss: 1.89 - train acc: 0.48 val acc: 0.52:  87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 1: - train loss: 1.94 val loss: 1.84 - train acc: 0.43 val acc: 0.56:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 1: - train loss: 1.88 val loss: 1.84 - train acc: 0.45 val acc: 0.51:  87%|████████▋ | 26/30 [00:08<00:01,  3.11it/s]\n",
      "Epoch 1: - train loss: 1.88 val loss: 1.84 - train acc: 0.45 val acc: 0.51:  93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s]\n",
      "Epoch 1: - train loss: 1.87 val loss: 1.85 - train acc: 0.55 val acc: 0.53:  93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s]\n",
      "Epoch 1: - train loss: 1.86 val loss: 1.82 - train acc: 0.49 val acc: 0.52:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 1: - train loss: 1.86 val loss: 1.82 - train acc: 0.49 val acc: 0.52: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:   7%|▋         | 2/30 [00:21<04:54, 10.52s/it]\n",
      "Epoch 2:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 2: - train loss: 1.81 val loss: 1.83 - train acc: 0.56 val acc: 0.56:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 2: - train loss: 1.77 val loss: 1.81 - train acc: 0.60 val acc: 0.52:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 2: - train loss: 1.77 val loss: 1.81 - train acc: 0.60 val acc: 0.52:   7%|▋         | 2/30 [00:00<00:08,  3.43it/s]\n",
      "Epoch 2: - train loss: 1.81 val loss: 1.83 - train acc: 0.47 val acc: 0.51:   7%|▋         | 2/30 [00:00<00:12,  2.28it/s]\n",
      "Epoch 2: - train loss: 1.79 val loss: 1.85 - train acc: 0.55 val acc: 0.53:   7%|▋         | 2/30 [00:01<00:16,  1.68it/s]\n",
      "Epoch 2: - train loss: 1.79 val loss: 1.85 - train acc: 0.55 val acc: 0.53:  13%|█▎        | 4/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 2: - train loss: 1.89 val loss: 1.85 - train acc: 0.41 val acc: 0.49:  13%|█▎        | 4/30 [00:01<00:09,  2.69it/s]\n",
      "Epoch 2: - train loss: 1.82 val loss: 1.79 - train acc: 0.52 val acc: 0.53:  13%|█▎        | 4/30 [00:01<00:11,  2.25it/s]\n",
      "Epoch 2: - train loss: 1.82 val loss: 1.79 - train acc: 0.52 val acc: 0.53:  20%|██        | 6/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 2: - train loss: 1.76 val loss: 1.82 - train acc: 0.60 val acc: 0.53:  20%|██        | 6/30 [00:02<00:08,  2.90it/s]\n",
      "Epoch 2: - train loss: 1.85 val loss: 1.76 - train acc: 0.49 val acc: 0.59:  20%|██        | 6/30 [00:02<00:09,  2.54it/s]\n",
      "Epoch 2: - train loss: 1.85 val loss: 1.76 - train acc: 0.49 val acc: 0.59:  27%|██▋       | 8/30 [00:02<00:06,  3.38it/s]\n",
      "Epoch 2: - train loss: 1.82 val loss: 1.75 - train acc: 0.54 val acc: 0.66:  27%|██▋       | 8/30 [00:02<00:07,  3.00it/s]\n",
      "Epoch 2: - train loss: 1.77 val loss: 1.79 - train acc: 0.52 val acc: 0.54:  27%|██▋       | 8/30 [00:02<00:08,  2.71it/s]\n",
      "Epoch 2: - train loss: 1.77 val loss: 1.79 - train acc: 0.52 val acc: 0.54:  33%|███▎      | 10/30 [00:02<00:05,  3.38it/s]\n",
      "Epoch 2: - train loss: 1.86 val loss: 1.75 - train acc: 0.50 val acc: 0.58:  33%|███▎      | 10/30 [00:03<00:06,  3.08it/s]\n",
      "Epoch 2: - train loss: 1.79 val loss: 1.76 - train acc: 0.52 val acc: 0.58:  33%|███▎      | 10/30 [00:03<00:07,  2.83it/s]\n",
      "Epoch 2: - train loss: 1.79 val loss: 1.76 - train acc: 0.52 val acc: 0.58:  40%|████      | 12/30 [00:03<00:05,  3.39it/s]\n",
      "Epoch 2: - train loss: 1.74 val loss: 1.75 - train acc: 0.58 val acc: 0.58:  40%|████      | 12/30 [00:03<00:05,  3.13it/s]\n",
      "Epoch 2: - train loss: 1.73 val loss: 1.74 - train acc: 0.61 val acc: 0.57:  40%|████      | 12/30 [00:04<00:06,  2.91it/s]\n",
      "Epoch 2: - train loss: 1.73 val loss: 1.74 - train acc: 0.61 val acc: 0.57:  47%|████▋     | 14/30 [00:04<00:04,  3.39it/s]\n",
      "Epoch 2: - train loss: 1.76 val loss: 1.79 - train acc: 0.58 val acc: 0.61:  47%|████▋     | 14/30 [00:04<00:05,  3.17it/s]\n",
      "Epoch 2: - train loss: 1.75 val loss: 1.72 - train acc: 0.63 val acc: 0.62:  47%|████▋     | 14/30 [00:04<00:05,  2.97it/s]\n",
      "Epoch 2: - train loss: 1.75 val loss: 1.72 - train acc: 0.63 val acc: 0.62:  53%|█████▎    | 16/30 [00:04<00:04,  3.39it/s]\n",
      "Epoch 2: - train loss: 1.75 val loss: 1.71 - train acc: 0.59 val acc: 0.61:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 2: - train loss: 1.74 val loss: 1.71 - train acc: 0.61 val acc: 0.66:  53%|█████▎    | 16/30 [00:05<00:04,  3.01it/s]\n",
      "Epoch 2: - train loss: 1.74 val loss: 1.71 - train acc: 0.61 val acc: 0.66:  60%|██████    | 18/30 [00:05<00:03,  3.38it/s]\n",
      "Epoch 2: - train loss: 1.70 val loss: 1.65 - train acc: 0.62 val acc: 0.72:  60%|██████    | 18/30 [00:05<00:03,  3.20it/s]\n",
      "Epoch 2: - train loss: 1.68 val loss: 1.67 - train acc: 0.67 val acc: 0.73:  60%|██████    | 18/30 [00:05<00:03,  3.05it/s]\n",
      "Epoch 2: - train loss: 1.68 val loss: 1.67 - train acc: 0.67 val acc: 0.73:  67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s]\n",
      "Epoch 2: - train loss: 1.71 val loss: 1.72 - train acc: 0.62 val acc: 0.59:  67%|██████▋   | 20/30 [00:06<00:03,  3.22it/s]\n",
      "Epoch 2: - train loss: 1.65 val loss: 1.65 - train acc: 0.73 val acc: 0.70:  67%|██████▋   | 20/30 [00:06<00:03,  3.08it/s]\n",
      "Epoch 2: - train loss: 1.65 val loss: 1.65 - train acc: 0.73 val acc: 0.70:  73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s]\n",
      "Epoch 2: - train loss: 1.70 val loss: 1.68 - train acc: 0.65 val acc: 0.64:  73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s]\n",
      "Epoch 2: - train loss: 1.71 val loss: 1.72 - train acc: 0.66 val acc: 0.64:  73%|███████▎  | 22/30 [00:07<00:02,  3.10it/s]\n",
      "Epoch 2: - train loss: 1.71 val loss: 1.72 - train acc: 0.66 val acc: 0.64:  80%|████████  | 24/30 [00:07<00:01,  3.38it/s]\n",
      "Epoch 2: - train loss: 1.63 val loss: 1.66 - train acc: 0.72 val acc: 0.71:  80%|████████  | 24/30 [00:07<00:01,  3.25it/s]\n",
      "Epoch 2: - train loss: 1.66 val loss: 1.67 - train acc: 0.68 val acc: 0.67:  80%|████████  | 24/30 [00:07<00:01,  3.12it/s]\n",
      "Epoch 2: - train loss: 1.66 val loss: 1.67 - train acc: 0.68 val acc: 0.67:  87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: - train loss: 1.65 val loss: 1.58 - train acc: 0.77 val acc: 0.77:  87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s]\n",
      "Epoch 2: - train loss: 1.64 val loss: 1.68 - train acc: 0.70 val acc: 0.63:  87%|████████▋ | 26/30 [00:08<00:01,  3.14it/s]\n",
      "Epoch 2: - train loss: 1.64 val loss: 1.68 - train acc: 0.70 val acc: 0.63:  93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s]\n",
      "Epoch 2: - train loss: 1.63 val loss: 1.63 - train acc: 0.70 val acc: 0.66:  93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s]\n",
      "Epoch 2: - train loss: 1.61 val loss: 1.59 - train acc: 0.75 val acc: 0.77:  93%|█████████▎| 28/30 [00:08<00:00,  3.16it/s]\n",
      "Epoch 2: - train loss: 1.61 val loss: 1.59 - train acc: 0.75 val acc: 0.77: 100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n",
      "Training progress:  10%|█         | 3/30 [00:29<04:29,  9.98s/it]\n",
      "Epoch 3:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 3: - train loss: 1.60 val loss: 1.60 - train acc: 0.70 val acc: 0.70:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 3: - train loss: 1.58 val loss: 1.61 - train acc: 0.70 val acc: 0.73:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 3: - train loss: 1.58 val loss: 1.61 - train acc: 0.70 val acc: 0.73:   7%|▋         | 2/30 [00:00<00:08,  3.25it/s]\n",
      "Epoch 3: - train loss: 1.66 val loss: 1.61 - train acc: 0.69 val acc: 0.65:   7%|▋         | 2/30 [00:00<00:13,  2.15it/s]\n",
      "Epoch 3: - train loss: 1.57 val loss: 1.52 - train acc: 0.75 val acc: 0.75:   7%|▋         | 2/30 [00:01<00:17,  1.64it/s]\n",
      "Epoch 3: - train loss: 1.57 val loss: 1.52 - train acc: 0.75 val acc: 0.75:  13%|█▎        | 4/30 [00:01<00:07,  3.27it/s]\n",
      "Epoch 3: - train loss: 1.55 val loss: 1.55 - train acc: 0.74 val acc: 0.77:  13%|█▎        | 4/30 [00:01<00:09,  2.64it/s]\n",
      "Epoch 3: - train loss: 1.56 val loss: 1.60 - train acc: 0.76 val acc: 0.68:  13%|█▎        | 4/30 [00:01<00:11,  2.19it/s]\n",
      "Epoch 3: - train loss: 1.56 val loss: 1.60 - train acc: 0.76 val acc: 0.68:  20%|██        | 6/30 [00:01<00:07,  3.28it/s]\n",
      "Epoch 3: - train loss: 1.59 val loss: 1.51 - train acc: 0.70 val acc: 0.77:  20%|██        | 6/30 [00:02<00:08,  2.80it/s]\n",
      "Epoch 3: - train loss: 1.51 val loss: 1.54 - train acc: 0.77 val acc: 0.76:  20%|██        | 6/30 [00:02<00:09,  2.46it/s]\n",
      "Epoch 3: - train loss: 1.51 val loss: 1.54 - train acc: 0.77 val acc: 0.76:  27%|██▋       | 8/30 [00:02<00:06,  3.28it/s]\n",
      "Epoch 3: - train loss: 1.58 val loss: 1.49 - train acc: 0.71 val acc: 0.79:  27%|██▋       | 8/30 [00:02<00:07,  2.93it/s]\n",
      "Epoch 3: - train loss: 1.51 val loss: 1.53 - train acc: 0.80 val acc: 0.75:  27%|██▋       | 8/30 [00:03<00:08,  2.63it/s]\n",
      "Epoch 3: - train loss: 1.51 val loss: 1.53 - train acc: 0.80 val acc: 0.75:  33%|███▎      | 10/30 [00:03<00:06,  3.28it/s]\n",
      "Epoch 3: - train loss: 1.52 val loss: 1.52 - train acc: 0.73 val acc: 0.80:  33%|███▎      | 10/30 [00:03<00:06,  2.99it/s]\n",
      "Epoch 3: - train loss: 1.49 val loss: 1.50 - train acc: 0.73 val acc: 0.77:  33%|███▎      | 10/30 [00:03<00:07,  2.76it/s]\n",
      "Epoch 3: - train loss: 1.49 val loss: 1.50 - train acc: 0.73 val acc: 0.77:  40%|████      | 12/30 [00:03<00:05,  3.30it/s]\n",
      "Epoch 3: - train loss: 1.51 val loss: 1.51 - train acc: 0.77 val acc: 0.75:  40%|████      | 12/30 [00:03<00:05,  3.06it/s]\n",
      "Epoch 3: - train loss: 1.52 val loss: 1.47 - train acc: 0.72 val acc: 0.80:  40%|████      | 12/30 [00:04<00:06,  2.83it/s]\n",
      "Epoch 3: - train loss: 1.52 val loss: 1.47 - train acc: 0.72 val acc: 0.80:  47%|████▋     | 14/30 [00:04<00:04,  3.30it/s]\n",
      "Epoch 3: - train loss: 1.49 val loss: 1.48 - train acc: 0.76 val acc: 0.79:  47%|████▋     | 14/30 [00:04<00:05,  3.09it/s]\n",
      "Epoch 3: - train loss: 1.53 val loss: 1.48 - train acc: 0.71 val acc: 0.77:  47%|████▋     | 14/30 [00:04<00:05,  2.90it/s]\n",
      "Epoch 3: - train loss: 1.53 val loss: 1.48 - train acc: 0.71 val acc: 0.77:  53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s]\n",
      "Epoch 3: - train loss: 1.54 val loss: 1.41 - train acc: 0.70 val acc: 0.82:  53%|█████▎    | 16/30 [00:05<00:04,  3.13it/s]\n",
      "Epoch 3: - train loss: 1.44 val loss: 1.46 - train acc: 0.78 val acc: 0.80:  53%|█████▎    | 16/30 [00:05<00:04,  2.96it/s]\n",
      "Epoch 3: - train loss: 1.44 val loss: 1.46 - train acc: 0.78 val acc: 0.80:  60%|██████    | 18/30 [00:05<00:03,  3.33it/s]\n",
      "Epoch 3: - train loss: 1.47 val loss: 1.53 - train acc: 0.80 val acc: 0.74:  60%|██████    | 18/30 [00:05<00:03,  3.16it/s]\n",
      "Epoch 3: - train loss: 1.49 val loss: 1.45 - train acc: 0.73 val acc: 0.77:  60%|██████    | 18/30 [00:06<00:04,  2.99it/s]\n",
      "Epoch 3: - train loss: 1.49 val loss: 1.45 - train acc: 0.73 val acc: 0.77:  67%|██████▋   | 20/30 [00:06<00:03,  3.32it/s]\n",
      "Epoch 3: - train loss: 1.41 val loss: 1.42 - train acc: 0.81 val acc: 0.80:  67%|██████▋   | 20/30 [00:06<00:03,  3.17it/s]\n",
      "Epoch 3: - train loss: 1.48 val loss: 1.39 - train acc: 0.72 val acc: 0.83:  67%|██████▋   | 20/30 [00:06<00:03,  3.03it/s]\n",
      "Epoch 3: - train loss: 1.48 val loss: 1.39 - train acc: 0.72 val acc: 0.83:  73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s]\n",
      "Epoch 3: - train loss: 1.45 val loss: 1.51 - train acc: 0.77 val acc: 0.66:  73%|███████▎  | 22/30 [00:06<00:02,  3.19it/s]\n",
      "Epoch 3: - train loss: 1.48 val loss: 1.41 - train acc: 0.77 val acc: 0.80:  73%|███████▎  | 22/30 [00:07<00:02,  3.06it/s]\n",
      "Epoch 3: - train loss: 1.48 val loss: 1.41 - train acc: 0.77 val acc: 0.80:  80%|████████  | 24/30 [00:07<00:01,  3.34it/s]\n",
      "Epoch 3: - train loss: 1.40 val loss: 1.42 - train acc: 0.80 val acc: 0.79:  80%|████████  | 24/30 [00:07<00:01,  3.21it/s]\n",
      "Epoch 3: - train loss: 1.38 val loss: 1.43 - train acc: 0.78 val acc: 0.76:  80%|████████  | 24/30 [00:07<00:01,  3.08it/s]\n",
      "Epoch 3: - train loss: 1.38 val loss: 1.43 - train acc: 0.78 val acc: 0.76:  87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s]\n",
      "Epoch 3: - train loss: 1.42 val loss: 1.40 - train acc: 0.77 val acc: 0.75:  87%|████████▋ | 26/30 [00:08<00:01,  3.22it/s]\n",
      "Epoch 3: - train loss: 1.40 val loss: 1.41 - train acc: 0.80 val acc: 0.77:  87%|████████▋ | 26/30 [00:08<00:01,  3.11it/s]\n",
      "Epoch 3: - train loss: 1.40 val loss: 1.41 - train acc: 0.80 val acc: 0.77:  93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s]\n",
      "Epoch 3: - train loss: 1.42 val loss: 1.29 - train acc: 0.80 val acc: 0.89:  93%|█████████▎| 28/30 [00:08<00:00,  3.22it/s]\n",
      "Epoch 3: - train loss: 1.38 val loss: 1.36 - train acc: 0.83 val acc: 0.88:  93%|█████████▎| 28/30 [00:08<00:00,  3.12it/s]\n",
      "Epoch 3: - train loss: 1.38 val loss: 1.36 - train acc: 0.83 val acc: 0.88: 100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
      "Training progress:  13%|█▎        | 4/30 [00:38<04:12,  9.73s/it]\n",
      "Epoch 4:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 4: - train loss: 1.37 val loss: 1.37 - train acc: 0.86 val acc: 0.80:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 4: - train loss: 1.43 val loss: 1.33 - train acc: 0.81 val acc: 0.87:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 4: - train loss: 1.43 val loss: 1.33 - train acc: 0.81 val acc: 0.87:   7%|▋         | 2/30 [00:00<00:08,  3.41it/s]\n",
      "Epoch 4: - train loss: 1.40 val loss: 1.38 - train acc: 0.80 val acc: 0.82:   7%|▋         | 2/30 [00:00<00:12,  2.28it/s]\n",
      "Epoch 4: - train loss: 1.35 val loss: 1.35 - train acc: 0.85 val acc: 0.84:   7%|▋         | 2/30 [00:01<00:16,  1.71it/s]\n",
      "Epoch 4: - train loss: 1.35 val loss: 1.35 - train acc: 0.85 val acc: 0.84:  13%|█▎        | 4/30 [00:01<00:07,  3.42it/s]\n",
      "Epoch 4: - train loss: 1.27 val loss: 1.30 - train acc: 0.87 val acc: 0.88:  13%|█▎        | 4/30 [00:01<00:09,  2.74it/s]\n",
      "Epoch 4: - train loss: 1.32 val loss: 1.31 - train acc: 0.86 val acc: 0.85:  13%|█▎        | 4/30 [00:01<00:11,  2.28it/s]\n",
      "Epoch 4: - train loss: 1.32 val loss: 1.31 - train acc: 0.86 val acc: 0.85:  20%|██        | 6/30 [00:01<00:07,  3.42it/s]\n",
      "Epoch 4: - train loss: 1.30 val loss: 1.34 - train acc: 0.84 val acc: 0.84:  20%|██        | 6/30 [00:02<00:08,  2.94it/s]\n",
      "Epoch 4: - train loss: 1.32 val loss: 1.37 - train acc: 0.85 val acc: 0.80:  20%|██        | 6/30 [00:02<00:09,  2.58it/s]\n",
      "Epoch 4: - train loss: 1.32 val loss: 1.37 - train acc: 0.85 val acc: 0.80:  27%|██▋       | 8/30 [00:02<00:06,  3.43it/s]\n",
      "Epoch 4: - train loss: 1.29 val loss: 1.24 - train acc: 0.85 val acc: 0.85:  27%|██▋       | 8/30 [00:02<00:07,  3.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: - train loss: 1.31 val loss: 1.25 - train acc: 0.83 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:08,  2.75it/s]\n",
      "Epoch 4: - train loss: 1.31 val loss: 1.25 - train acc: 0.83 val acc: 0.91:  33%|███▎      | 10/30 [00:02<00:05,  3.43it/s]\n",
      "Epoch 4: - train loss: 1.30 val loss: 1.24 - train acc: 0.80 val acc: 0.88:  33%|███▎      | 10/30 [00:03<00:06,  3.12it/s]\n",
      "Epoch 4: - train loss: 1.31 val loss: 1.26 - train acc: 0.84 val acc: 0.86:  33%|███▎      | 10/30 [00:03<00:07,  2.86it/s]\n",
      "Epoch 4: - train loss: 1.31 val loss: 1.26 - train acc: 0.84 val acc: 0.86:  40%|████      | 12/30 [00:03<00:05,  3.42it/s]\n",
      "Epoch 4: - train loss: 1.28 val loss: 1.39 - train acc: 0.84 val acc: 0.78:  40%|████      | 12/30 [00:03<00:05,  3.17it/s]\n",
      "Epoch 4: - train loss: 1.23 val loss: 1.26 - train acc: 0.87 val acc: 0.89:  40%|████      | 12/30 [00:04<00:06,  2.94it/s]\n",
      "Epoch 4: - train loss: 1.23 val loss: 1.26 - train acc: 0.87 val acc: 0.89:  47%|████▋     | 14/30 [00:04<00:04,  3.43it/s]\n",
      "Epoch 4: - train loss: 1.23 val loss: 1.27 - train acc: 0.88 val acc: 0.84:  47%|████▋     | 14/30 [00:04<00:04,  3.20it/s]\n",
      "Epoch 4: - train loss: 1.23 val loss: 1.22 - train acc: 0.83 val acc: 0.90:  47%|████▋     | 14/30 [00:04<00:05,  3.00it/s]\n",
      "Epoch 4: - train loss: 1.23 val loss: 1.22 - train acc: 0.83 val acc: 0.90:  53%|█████▎    | 16/30 [00:04<00:04,  3.43it/s]\n",
      "Epoch 4: - train loss: 1.29 val loss: 1.23 - train acc: 0.84 val acc: 0.80:  53%|█████▎    | 16/30 [00:04<00:04,  3.21it/s]\n",
      "Epoch 4: - train loss: 1.27 val loss: 1.20 - train acc: 0.80 val acc: 0.86:  53%|█████▎    | 16/30 [00:05<00:04,  3.04it/s]\n",
      "Epoch 4: - train loss: 1.27 val loss: 1.20 - train acc: 0.80 val acc: 0.86:  60%|██████    | 18/30 [00:05<00:03,  3.41it/s]\n",
      "Epoch 4: - train loss: 1.22 val loss: 1.22 - train acc: 0.89 val acc: 0.89:  60%|██████    | 18/30 [00:05<00:03,  3.23it/s]\n",
      "Epoch 4: - train loss: 1.27 val loss: 1.20 - train acc: 0.87 val acc: 0.89:  60%|██████    | 18/30 [00:05<00:03,  3.06it/s]\n",
      "Epoch 4: - train loss: 1.27 val loss: 1.20 - train acc: 0.87 val acc: 0.89:  67%|██████▋   | 20/30 [00:05<00:02,  3.40it/s]\n",
      "Epoch 4: - train loss: 1.31 val loss: 1.21 - train acc: 0.78 val acc: 0.87:  67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s]\n",
      "Epoch 4: - train loss: 1.16 val loss: 1.22 - train acc: 0.84 val acc: 0.82:  67%|██████▋   | 20/30 [00:06<00:03,  3.08it/s]\n",
      "Epoch 4: - train loss: 1.16 val loss: 1.22 - train acc: 0.84 val acc: 0.82:  73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s]\n",
      "Epoch 4: - train loss: 1.19 val loss: 1.25 - train acc: 0.87 val acc: 0.80:  73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s]\n",
      "Epoch 4: - train loss: 1.25 val loss: 1.20 - train acc: 0.85 val acc: 0.89:  73%|███████▎  | 22/30 [00:07<00:02,  3.11it/s]\n",
      "Epoch 4: - train loss: 1.25 val loss: 1.20 - train acc: 0.85 val acc: 0.89:  80%|████████  | 24/30 [00:07<00:01,  3.39it/s]\n",
      "Epoch 4: - train loss: 1.22 val loss: 1.16 - train acc: 0.80 val acc: 0.88:  80%|████████  | 24/30 [00:07<00:01,  3.25it/s]\n",
      "Epoch 4: - train loss: 1.17 val loss: 1.17 - train acc: 0.87 val acc: 0.88:  80%|████████  | 24/30 [00:07<00:01,  3.12it/s]\n",
      "Epoch 4: - train loss: 1.17 val loss: 1.17 - train acc: 0.87 val acc: 0.88:  87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s]\n",
      "Epoch 4: - train loss: 1.17 val loss: 1.08 - train acc: 0.88 val acc: 0.93:  87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s]\n",
      "Epoch 4: - train loss: 1.22 val loss: 1.14 - train acc: 0.83 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.15it/s]\n",
      "Epoch 4: - train loss: 1.22 val loss: 1.14 - train acc: 0.83 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.39it/s]\n",
      "Epoch 4: - train loss: 1.15 val loss: 1.10 - train acc: 0.84 val acc: 0.91:  93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s]\n",
      "Epoch 4: - train loss: 1.11 val loss: 1.14 - train acc: 0.89 val acc: 0.88:  93%|█████████▎| 28/30 [00:08<00:00,  3.16it/s]\n",
      "Epoch 4: - train loss: 1.11 val loss: 1.14 - train acc: 0.89 val acc: 0.88: 100%|██████████| 30/30 [00:08<00:00,  3.39it/s]\n",
      "Training progress:  17%|█▋        | 5/30 [00:47<03:58,  9.56s/it]\n",
      "Epoch 5:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 5: - train loss: 1.12 val loss: 1.14 - train acc: 0.82 val acc: 0.90:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 5: - train loss: 1.10 val loss: 1.10 - train acc: 0.91 val acc: 0.87:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 5: - train loss: 1.10 val loss: 1.10 - train acc: 0.91 val acc: 0.87:   7%|▋         | 2/30 [00:00<00:08,  3.28it/s]\n",
      "Epoch 5: - train loss: 1.12 val loss: 1.12 - train acc: 0.89 val acc: 0.88:   7%|▋         | 2/30 [00:00<00:12,  2.23it/s]\n",
      "Epoch 5: - train loss: 1.09 val loss: 1.08 - train acc: 0.88 val acc: 0.86:   7%|▋         | 2/30 [00:01<00:16,  1.69it/s]\n",
      "Epoch 5: - train loss: 1.09 val loss: 1.08 - train acc: 0.88 val acc: 0.86:  13%|█▎        | 4/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 5: - train loss: 1.13 val loss: 1.05 - train acc: 0.86 val acc: 0.90:  13%|█▎        | 4/30 [00:01<00:09,  2.66it/s]\n",
      "Epoch 5: - train loss: 1.10 val loss: 1.09 - train acc: 0.88 val acc: 0.88:  13%|█▎        | 4/30 [00:01<00:11,  2.20it/s]\n",
      "Epoch 5: - train loss: 1.10 val loss: 1.09 - train acc: 0.88 val acc: 0.88:  20%|██        | 6/30 [00:01<00:07,  3.30it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 1.04 - train acc: 0.92 val acc: 0.92:  20%|██        | 6/30 [00:02<00:08,  2.85it/s]\n",
      "Epoch 5: - train loss: 1.10 val loss: 1.09 - train acc: 0.88 val acc: 0.90:  20%|██        | 6/30 [00:02<00:09,  2.50it/s]\n",
      "Epoch 5: - train loss: 1.10 val loss: 1.09 - train acc: 0.88 val acc: 0.90:  27%|██▋       | 8/30 [00:02<00:06,  3.33it/s]\n",
      "Epoch 5: - train loss: 1.08 val loss: 1.08 - train acc: 0.85 val acc: 0.88:  27%|██▋       | 8/30 [00:02<00:07,  2.97it/s]\n",
      "Epoch 5: - train loss: 1.05 val loss: 1.08 - train acc: 0.88 val acc: 0.91:  27%|██▋       | 8/30 [00:03<00:08,  2.66it/s]\n",
      "Epoch 5: - train loss: 1.05 val loss: 1.08 - train acc: 0.88 val acc: 0.91:  33%|███▎      | 10/30 [00:03<00:06,  3.32it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 1.10 - train acc: 0.89 val acc: 0.88:  33%|███▎      | 10/30 [00:03<00:06,  3.03it/s]\n",
      "Epoch 5: - train loss: 1.06 val loss: 1.08 - train acc: 0.87 val acc: 0.88:  33%|███▎      | 10/30 [00:03<00:07,  2.78it/s]\n",
      "Epoch 5: - train loss: 1.06 val loss: 1.08 - train acc: 0.87 val acc: 0.88:  40%|████      | 12/30 [00:03<00:05,  3.34it/s]\n",
      "Epoch 5: - train loss: 1.00 val loss: 1.08 - train acc: 0.92 val acc: 0.91:  40%|████      | 12/30 [00:03<00:05,  3.09it/s]\n",
      "Epoch 5: - train loss: 1.05 val loss: 1.06 - train acc: 0.86 val acc: 0.87:  40%|████      | 12/30 [00:04<00:06,  2.86it/s]\n",
      "Epoch 5: - train loss: 1.05 val loss: 1.06 - train acc: 0.86 val acc: 0.87:  47%|████▋     | 14/30 [00:04<00:04,  3.33it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 1.04 - train acc: 0.89 val acc: 0.89:  47%|████▋     | 14/30 [00:04<00:05,  3.11it/s]\n",
      "Epoch 5: - train loss: 1.04 val loss: 1.03 - train acc: 0.86 val acc: 0.86:  47%|████▋     | 14/30 [00:04<00:05,  2.92it/s]\n",
      "Epoch 5: - train loss: 1.04 val loss: 1.03 - train acc: 0.86 val acc: 0.86:  53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s]\n",
      "Epoch 5: - train loss: 0.99 val loss: 1.07 - train acc: 0.90 val acc: 0.87:  53%|█████▎    | 16/30 [00:05<00:04,  3.15it/s]\n",
      "Epoch 5: - train loss: 1.04 val loss: 1.05 - train acc: 0.88 val acc: 0.86:  53%|█████▎    | 16/30 [00:05<00:04,  2.98it/s]\n",
      "Epoch 5: - train loss: 1.04 val loss: 1.05 - train acc: 0.88 val acc: 0.86:  60%|██████    | 18/30 [00:05<00:03,  3.35it/s]\n",
      "Epoch 5: - train loss: 1.11 val loss: 0.96 - train acc: 0.84 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.17it/s]\n",
      "Epoch 5: - train loss: 1.01 val loss: 1.04 - train acc: 0.93 val acc: 0.86:  60%|██████    | 18/30 [00:05<00:03,  3.00it/s]\n",
      "Epoch 5: - train loss: 1.01 val loss: 1.04 - train acc: 0.93 val acc: 0.86:  67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s]\n",
      "Epoch 5: - train loss: 0.97 val loss: 1.03 - train acc: 0.91 val acc: 0.89:  67%|██████▋   | 20/30 [00:06<00:03,  3.18it/s]\n",
      "Epoch 5: - train loss: 0.96 val loss: 1.03 - train acc: 0.89 val acc: 0.86:  67%|██████▋   | 20/30 [00:06<00:03,  3.04it/s]\n",
      "Epoch 5: - train loss: 0.96 val loss: 1.03 - train acc: 0.89 val acc: 0.86:  73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: - train loss: 1.05 val loss: 1.03 - train acc: 0.85 val acc: 0.86:  73%|███████▎  | 22/30 [00:06<00:02,  3.20it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 1.01 - train acc: 0.87 val acc: 0.88:  73%|███████▎  | 22/30 [00:07<00:02,  3.07it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 1.01 - train acc: 0.87 val acc: 0.88:  80%|████████  | 24/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 5: - train loss: 0.99 val loss: 0.95 - train acc: 0.89 val acc: 0.88:  80%|████████  | 24/30 [00:07<00:01,  3.22it/s]\n",
      "Epoch 5: - train loss: 1.05 val loss: 0.98 - train acc: 0.88 val acc: 0.90:  80%|████████  | 24/30 [00:07<00:01,  3.09it/s]\n",
      "Epoch 5: - train loss: 1.05 val loss: 0.98 - train acc: 0.88 val acc: 0.90:  87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s]\n",
      "Epoch 5: - train loss: 1.02 val loss: 0.99 - train acc: 0.88 val acc: 0.91:  87%|████████▋ | 26/30 [00:08<00:01,  3.22it/s]\n",
      "Epoch 5: - train loss: 0.90 val loss: 1.08 - train acc: 0.94 val acc: 0.81:  87%|████████▋ | 26/30 [00:08<00:01,  3.11it/s]\n",
      "Epoch 5: - train loss: 0.90 val loss: 1.08 - train acc: 0.94 val acc: 0.81:  93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s]\n",
      "Epoch 5: - train loss: 0.97 val loss: 0.99 - train acc: 0.89 val acc: 0.85:  93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 0.97 - train acc: 0.84 val acc: 0.90:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 5: - train loss: 1.03 val loss: 0.97 - train acc: 0.84 val acc: 0.90: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:  20%|██        | 6/30 [00:56<03:46,  9.46s/it]\n",
      "Epoch 6:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 6: - train loss: 0.94 val loss: 0.91 - train acc: 0.85 val acc: 0.90:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 6: - train loss: 0.93 val loss: 0.95 - train acc: 0.95 val acc: 0.89:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 6: - train loss: 0.93 val loss: 0.95 - train acc: 0.95 val acc: 0.89:   7%|▋         | 2/30 [00:00<00:08,  3.42it/s]\n",
      "Epoch 6: - train loss: 0.87 val loss: 0.92 - train acc: 0.94 val acc: 0.92:   7%|▋         | 2/30 [00:00<00:12,  2.29it/s]\n",
      "Epoch 6: - train loss: 1.01 val loss: 0.95 - train acc: 0.87 val acc: 0.90:   7%|▋         | 2/30 [00:01<00:16,  1.71it/s]\n",
      "Epoch 6: - train loss: 1.01 val loss: 0.95 - train acc: 0.87 val acc: 0.90:  13%|█▎        | 4/30 [00:01<00:07,  3.42it/s]\n",
      "Epoch 6: - train loss: 0.86 val loss: 0.95 - train acc: 0.91 val acc: 0.89:  13%|█▎        | 4/30 [00:01<00:09,  2.74it/s]\n",
      "Epoch 6: - train loss: 0.91 val loss: 0.94 - train acc: 0.88 val acc: 0.90:  13%|█▎        | 4/30 [00:01<00:11,  2.25it/s]\n",
      "Epoch 6: - train loss: 0.91 val loss: 0.94 - train acc: 0.88 val acc: 0.90:  20%|██        | 6/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.97 - train acc: 0.91 val acc: 0.86:  20%|██        | 6/30 [00:02<00:08,  2.90it/s]\n",
      "Epoch 6: - train loss: 0.86 val loss: 0.91 - train acc: 0.91 val acc: 0.87:  20%|██        | 6/30 [00:02<00:09,  2.54it/s]\n",
      "Epoch 6: - train loss: 0.86 val loss: 0.91 - train acc: 0.91 val acc: 0.87:  27%|██▋       | 8/30 [00:02<00:06,  3.39it/s]\n",
      "Epoch 6: - train loss: 0.97 val loss: 0.89 - train acc: 0.88 val acc: 0.93:  27%|██▋       | 8/30 [00:02<00:07,  3.02it/s]\n",
      "Epoch 6: - train loss: 0.94 val loss: 0.93 - train acc: 0.85 val acc: 0.88:  27%|██▋       | 8/30 [00:02<00:08,  2.72it/s]\n",
      "Epoch 6: - train loss: 0.94 val loss: 0.93 - train acc: 0.85 val acc: 0.88:  33%|███▎      | 10/30 [00:02<00:05,  3.39it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.94 - train acc: 0.87 val acc: 0.86:  33%|███▎      | 10/30 [00:03<00:06,  3.09it/s]\n",
      "Epoch 6: - train loss: 0.90 val loss: 0.88 - train acc: 0.88 val acc: 0.90:  33%|███▎      | 10/30 [00:03<00:07,  2.83it/s]\n",
      "Epoch 6: - train loss: 0.90 val loss: 0.88 - train acc: 0.88 val acc: 0.90:  40%|████      | 12/30 [00:03<00:05,  3.40it/s]\n",
      "Epoch 6: - train loss: 0.80 val loss: 0.91 - train acc: 0.95 val acc: 0.89:  40%|████      | 12/30 [00:03<00:05,  3.14it/s]\n",
      "Epoch 6: - train loss: 0.79 val loss: 0.93 - train acc: 0.92 val acc: 0.89:  40%|████      | 12/30 [00:04<00:06,  2.90it/s]\n",
      "Epoch 6: - train loss: 0.79 val loss: 0.93 - train acc: 0.92 val acc: 0.89:  47%|████▋     | 14/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 6: - train loss: 0.87 val loss: 0.93 - train acc: 0.93 val acc: 0.85:  47%|████▋     | 14/30 [00:04<00:05,  3.16it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.81 - train acc: 0.91 val acc: 0.90:  47%|████▋     | 14/30 [00:04<00:05,  2.96it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.81 - train acc: 0.91 val acc: 0.90:  53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 6: - train loss: 0.92 val loss: 0.91 - train acc: 0.88 val acc: 0.91:  53%|█████▎    | 16/30 [00:05<00:04,  3.17it/s]\n",
      "Epoch 6: - train loss: 0.81 val loss: 0.85 - train acc: 0.93 val acc: 0.92:  53%|█████▎    | 16/30 [00:05<00:04,  3.00it/s]\n",
      "Epoch 6: - train loss: 0.81 val loss: 0.85 - train acc: 0.93 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.92 val loss: 0.82 - train acc: 0.88 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.18it/s]\n",
      "Epoch 6: - train loss: 0.92 val loss: 0.85 - train acc: 0.86 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 6: - train loss: 0.92 val loss: 0.85 - train acc: 0.86 val acc: 0.91:  67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.83 val loss: 0.84 - train acc: 0.90 val acc: 0.89:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.86 - train acc: 0.86 val acc: 0.91:  67%|██████▋   | 20/30 [00:06<00:03,  3.07it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.86 - train acc: 0.86 val acc: 0.91:  73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.87 val loss: 0.86 - train acc: 0.90 val acc: 0.86:  73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.81 - train acc: 0.88 val acc: 0.88:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 6: - train loss: 0.88 val loss: 0.81 - train acc: 0.88 val acc: 0.88:  80%|████████  | 24/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.83 val loss: 0.86 - train acc: 0.90 val acc: 0.88:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 6: - train loss: 0.82 val loss: 0.79 - train acc: 0.91 val acc: 0.91:  80%|████████  | 24/30 [00:07<00:01,  3.11it/s]\n",
      "Epoch 6: - train loss: 0.82 val loss: 0.79 - train acc: 0.91 val acc: 0.91:  87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.83 val loss: 0.79 - train acc: 0.90 val acc: 0.94:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 6: - train loss: 0.84 val loss: 0.87 - train acc: 0.91 val acc: 0.88:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 6: - train loss: 0.84 val loss: 0.87 - train acc: 0.91 val acc: 0.88:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 6: - train loss: 0.81 val loss: 0.73 - train acc: 0.91 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s]\n",
      "Epoch 6: - train loss: 0.81 val loss: 0.78 - train acc: 0.90 val acc: 0.86:  93%|█████████▎| 28/30 [00:08<00:00,  3.14it/s]\n",
      "Epoch 6: - train loss: 0.81 val loss: 0.78 - train acc: 0.90 val acc: 0.86: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  23%|██▎       | 7/30 [01:05<03:35,  9.38s/it]\n",
      "Epoch 7:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 7: - train loss: 0.82 val loss: 0.80 - train acc: 0.89 val acc: 0.91:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 7: - train loss: 0.83 val loss: 0.80 - train acc: 0.91 val acc: 0.91:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 7: - train loss: 0.83 val loss: 0.80 - train acc: 0.91 val acc: 0.91:   7%|▋         | 2/30 [00:00<00:08,  3.43it/s]\n",
      "Epoch 7: - train loss: 0.80 val loss: 0.82 - train acc: 0.90 val acc: 0.89:   7%|▋         | 2/30 [00:00<00:12,  2.29it/s]\n",
      "Epoch 7: - train loss: 0.74 val loss: 0.78 - train acc: 0.94 val acc: 0.91:   7%|▋         | 2/30 [00:01<00:16,  1.72it/s]\n",
      "Epoch 7: - train loss: 0.74 val loss: 0.78 - train acc: 0.94 val acc: 0.91:  13%|█▎        | 4/30 [00:01<00:07,  3.42it/s]\n",
      "Epoch 7: - train loss: 0.82 val loss: 0.81 - train acc: 0.87 val acc: 0.89:  13%|█▎        | 4/30 [00:01<00:09,  2.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: - train loss: 0.79 val loss: 0.77 - train acc: 0.91 val acc: 0.89:  13%|█▎        | 4/30 [00:01<00:11,  2.25it/s]\n",
      "Epoch 7: - train loss: 0.79 val loss: 0.77 - train acc: 0.91 val acc: 0.89:  20%|██        | 6/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 7: - train loss: 0.81 val loss: 0.78 - train acc: 0.89 val acc: 0.88:  20%|██        | 6/30 [00:02<00:08,  2.87it/s]\n",
      "Epoch 7: - train loss: 0.83 val loss: 0.73 - train acc: 0.90 val acc: 0.93:  20%|██        | 6/30 [00:02<00:09,  2.51it/s]\n",
      "Epoch 7: - train loss: 0.83 val loss: 0.73 - train acc: 0.90 val acc: 0.93:  27%|██▋       | 8/30 [00:02<00:06,  3.35it/s]\n",
      "Epoch 7: - train loss: 0.79 val loss: 0.77 - train acc: 0.90 val acc: 0.88:  27%|██▋       | 8/30 [00:02<00:07,  2.96it/s]\n",
      "Epoch 7: - train loss: 0.79 val loss: 0.74 - train acc: 0.91 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:08,  2.67it/s]\n",
      "Epoch 7: - train loss: 0.79 val loss: 0.74 - train acc: 0.91 val acc: 0.91:  33%|███▎      | 10/30 [00:02<00:05,  3.34it/s]\n",
      "Epoch 7: - train loss: 0.84 val loss: 0.70 - train acc: 0.88 val acc: 0.96:  33%|███▎      | 10/30 [00:03<00:06,  3.02it/s]\n",
      "Epoch 7: - train loss: 0.77 val loss: 0.74 - train acc: 0.92 val acc: 0.92:  33%|███▎      | 10/30 [00:03<00:07,  2.77it/s]\n",
      "Epoch 7: - train loss: 0.77 val loss: 0.74 - train acc: 0.92 val acc: 0.92:  40%|████      | 12/30 [00:03<00:05,  3.32it/s]\n",
      "Epoch 7: - train loss: 0.73 val loss: 0.71 - train acc: 0.91 val acc: 0.94:  40%|████      | 12/30 [00:03<00:05,  3.07it/s]\n",
      "Epoch 7: - train loss: 0.81 val loss: 0.76 - train acc: 0.88 val acc: 0.91:  40%|████      | 12/30 [00:04<00:06,  2.86it/s]\n",
      "Epoch 7: - train loss: 0.81 val loss: 0.76 - train acc: 0.88 val acc: 0.91:  47%|████▋     | 14/30 [00:04<00:04,  3.33it/s]\n",
      "Epoch 7: - train loss: 0.74 val loss: 0.69 - train acc: 0.91 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  3.12it/s]\n",
      "Epoch 7: - train loss: 0.75 val loss: 0.73 - train acc: 0.88 val acc: 0.91:  47%|████▋     | 14/30 [00:04<00:05,  2.93it/s]\n",
      "Epoch 7: - train loss: 0.75 val loss: 0.73 - train acc: 0.88 val acc: 0.91:  53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s]\n",
      "Epoch 7: - train loss: 0.76 val loss: 0.73 - train acc: 0.88 val acc: 0.91:  53%|█████▎    | 16/30 [00:05<00:04,  3.15it/s]\n",
      "Epoch 7: - train loss: 0.73 val loss: 0.74 - train acc: 0.92 val acc: 0.94:  53%|█████▎    | 16/30 [00:05<00:04,  2.98it/s]\n",
      "Epoch 7: - train loss: 0.73 val loss: 0.74 - train acc: 0.92 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 7: - train loss: 0.79 val loss: 0.66 - train acc: 0.91 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.18it/s]\n",
      "Epoch 7: - train loss: 0.71 val loss: 0.71 - train acc: 0.93 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.02it/s]\n",
      "Epoch 7: - train loss: 0.71 val loss: 0.71 - train acc: 0.93 val acc: 0.91:  67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s]\n",
      "Epoch 7: - train loss: 0.68 val loss: 0.72 - train acc: 0.95 val acc: 0.91:  67%|██████▋   | 20/30 [00:06<00:03,  3.19it/s]\n",
      "Epoch 7: - train loss: 0.69 val loss: 0.71 - train acc: 0.92 val acc: 0.93:  67%|██████▋   | 20/30 [00:06<00:03,  3.05it/s]\n",
      "Epoch 7: - train loss: 0.69 val loss: 0.71 - train acc: 0.92 val acc: 0.93:  73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s]\n",
      "Epoch 7: - train loss: 0.70 val loss: 0.69 - train acc: 0.91 val acc: 0.91:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 7: - train loss: 0.71 val loss: 0.74 - train acc: 0.87 val acc: 0.89:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 7: - train loss: 0.71 val loss: 0.74 - train acc: 0.87 val acc: 0.89:  80%|████████  | 24/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 7: - train loss: 0.68 val loss: 0.69 - train acc: 0.94 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 7: - train loss: 0.73 val loss: 0.60 - train acc: 0.90 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.11it/s]\n",
      "Epoch 7: - train loss: 0.73 val loss: 0.60 - train acc: 0.90 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 7: - train loss: 0.59 val loss: 0.72 - train acc: 0.96 val acc: 0.91:  87%|████████▋ | 26/30 [00:08<00:01,  3.25it/s]\n",
      "Epoch 7: - train loss: 0.78 val loss: 0.71 - train acc: 0.87 val acc: 0.90:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 7: - train loss: 0.78 val loss: 0.71 - train acc: 0.87 val acc: 0.90:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 7: - train loss: 0.74 val loss: 0.65 - train acc: 0.89 val acc: 0.92:  93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s]\n",
      "Epoch 7: - train loss: 0.68 val loss: 0.83 - train acc: 0.93 val acc: 0.85:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 7: - train loss: 0.68 val loss: 0.83 - train acc: 0.93 val acc: 0.85: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  27%|██▋       | 8/30 [01:14<03:25,  9.33s/it]\n",
      "Epoch 8:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 8: - train loss: 0.71 val loss: 0.72 - train acc: 0.89 val acc: 0.90:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 8: - train loss: 0.68 val loss: 0.68 - train acc: 0.92 val acc: 0.91:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 8: - train loss: 0.68 val loss: 0.68 - train acc: 0.92 val acc: 0.91:   7%|▋         | 2/30 [00:00<00:08,  3.46it/s]\n",
      "Epoch 8: - train loss: 0.71 val loss: 0.69 - train acc: 0.92 val acc: 0.88:   7%|▋         | 2/30 [00:00<00:12,  2.30it/s]\n",
      "Epoch 8: - train loss: 0.69 val loss: 0.72 - train acc: 0.89 val acc: 0.88:   7%|▋         | 2/30 [00:01<00:16,  1.69it/s]\n",
      "Epoch 8: - train loss: 0.69 val loss: 0.72 - train acc: 0.89 val acc: 0.88:  13%|█▎        | 4/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 8: - train loss: 0.67 val loss: 0.59 - train acc: 0.92 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.66it/s]\n",
      "Epoch 8: - train loss: 0.64 val loss: 0.61 - train acc: 0.92 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.23it/s]\n",
      "Epoch 8: - train loss: 0.64 val loss: 0.61 - train acc: 0.92 val acc: 0.95:  20%|██        | 6/30 [00:01<00:07,  3.34it/s]\n",
      "Epoch 8: - train loss: 0.73 val loss: 0.67 - train acc: 0.91 val acc: 0.88:  20%|██        | 6/30 [00:02<00:08,  2.87it/s]\n",
      "Epoch 8: - train loss: 0.61 val loss: 0.67 - train acc: 0.93 val acc: 0.88:  20%|██        | 6/30 [00:02<00:09,  2.52it/s]\n",
      "Epoch 8: - train loss: 0.61 val loss: 0.67 - train acc: 0.93 val acc: 0.88:  27%|██▋       | 8/30 [00:02<00:06,  3.36it/s]\n",
      "Epoch 8: - train loss: 0.64 val loss: 0.65 - train acc: 0.95 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:07,  2.97it/s]\n",
      "Epoch 8: - train loss: 0.69 val loss: 0.72 - train acc: 0.94 val acc: 0.86:  27%|██▋       | 8/30 [00:02<00:08,  2.68it/s]\n",
      "Epoch 8: - train loss: 0.69 val loss: 0.72 - train acc: 0.94 val acc: 0.86:  33%|███▎      | 10/30 [00:02<00:05,  3.35it/s]\n",
      "Epoch 8: - train loss: 0.68 val loss: 0.63 - train acc: 0.91 val acc: 0.92:  33%|███▎      | 10/30 [00:03<00:06,  3.05it/s]\n",
      "Epoch 8: - train loss: 0.64 val loss: 0.64 - train acc: 0.93 val acc: 0.89:  33%|███▎      | 10/30 [00:03<00:07,  2.80it/s]\n",
      "Epoch 8: - train loss: 0.64 val loss: 0.64 - train acc: 0.93 val acc: 0.89:  40%|████      | 12/30 [00:03<00:05,  3.36it/s]\n",
      "Epoch 8: - train loss: 0.65 val loss: 0.63 - train acc: 0.91 val acc: 0.92:  40%|████      | 12/30 [00:03<00:05,  3.09it/s]\n",
      "Epoch 8: - train loss: 0.62 val loss: 0.62 - train acc: 0.94 val acc: 0.94:  40%|████      | 12/30 [00:04<00:06,  2.87it/s]\n",
      "Epoch 8: - train loss: 0.62 val loss: 0.62 - train acc: 0.94 val acc: 0.94:  47%|████▋     | 14/30 [00:04<00:04,  3.35it/s]\n",
      "Epoch 8: - train loss: 0.63 val loss: 0.65 - train acc: 0.91 val acc: 0.88:  47%|████▋     | 14/30 [00:04<00:05,  3.13it/s]\n",
      "Epoch 8: - train loss: 0.69 val loss: 0.67 - train acc: 0.86 val acc: 0.91:  47%|████▋     | 14/30 [00:04<00:05,  2.93it/s]\n",
      "Epoch 8: - train loss: 0.69 val loss: 0.67 - train acc: 0.86 val acc: 0.91:  53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s]\n",
      "Epoch 8: - train loss: 0.60 val loss: 0.61 - train acc: 0.92 val acc: 0.90:  53%|█████▎    | 16/30 [00:05<00:04,  3.14it/s]\n",
      "Epoch 8: - train loss: 0.57 val loss: 0.59 - train acc: 0.91 val acc: 0.93:  53%|█████▎    | 16/30 [00:05<00:04,  2.97it/s]\n",
      "Epoch 8: - train loss: 0.57 val loss: 0.59 - train acc: 0.91 val acc: 0.93:  60%|██████    | 18/30 [00:05<00:03,  3.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: - train loss: 0.66 val loss: 0.70 - train acc: 0.88 val acc: 0.88:  60%|██████    | 18/30 [00:05<00:03,  3.15it/s]\n",
      "Epoch 8: - train loss: 0.65 val loss: 0.60 - train acc: 0.94 val acc: 0.93:  60%|██████    | 18/30 [00:05<00:03,  3.00it/s]\n",
      "Epoch 8: - train loss: 0.65 val loss: 0.60 - train acc: 0.94 val acc: 0.93:  67%|██████▋   | 20/30 [00:05<00:02,  3.33it/s]\n",
      "Epoch 8: - train loss: 0.61 val loss: 0.62 - train acc: 0.91 val acc: 0.90:  67%|██████▋   | 20/30 [00:06<00:03,  3.18it/s]\n",
      "Epoch 8: - train loss: 0.63 val loss: 0.67 - train acc: 0.91 val acc: 0.90:  67%|██████▋   | 20/30 [00:06<00:03,  3.04it/s]\n",
      "Epoch 8: - train loss: 0.63 val loss: 0.67 - train acc: 0.91 val acc: 0.90:  73%|███████▎  | 22/30 [00:06<00:02,  3.34it/s]\n",
      "Epoch 8: - train loss: 0.63 val loss: 0.61 - train acc: 0.94 val acc: 0.91:  73%|███████▎  | 22/30 [00:06<00:02,  3.20it/s]\n",
      "Epoch 8: - train loss: 0.57 val loss: 0.56 - train acc: 0.94 val acc: 0.92:  73%|███████▎  | 22/30 [00:07<00:02,  3.07it/s]\n",
      "Epoch 8: - train loss: 0.57 val loss: 0.56 - train acc: 0.94 val acc: 0.92:  80%|████████  | 24/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 8: - train loss: 0.61 val loss: 0.58 - train acc: 0.91 val acc: 0.92:  80%|████████  | 24/30 [00:07<00:01,  3.22it/s]\n",
      "Epoch 8: - train loss: 0.62 val loss: 0.58 - train acc: 0.88 val acc: 0.91:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 8: - train loss: 0.62 val loss: 0.58 - train acc: 0.88 val acc: 0.91:  87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 8: - train loss: 0.63 val loss: 0.52 - train acc: 0.92 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.23it/s]\n",
      "Epoch 8: - train loss: 0.61 val loss: 0.60 - train acc: 0.89 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.12it/s]\n",
      "Epoch 8: - train loss: 0.61 val loss: 0.60 - train acc: 0.89 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s]\n",
      "Epoch 8: - train loss: 0.59 val loss: 0.56 - train acc: 0.89 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s]\n",
      "Epoch 8: - train loss: 0.60 val loss: 0.60 - train acc: 0.91 val acc: 0.94:  93%|█████████▎| 28/30 [00:08<00:00,  3.14it/s]\n",
      "Epoch 8: - train loss: 0.60 val loss: 0.60 - train acc: 0.91 val acc: 0.94: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  30%|███       | 9/30 [01:23<03:14,  9.28s/it]\n",
      "Epoch 9:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 9: - train loss: 0.57 val loss: 0.61 - train acc: 0.95 val acc: 0.91:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 9: - train loss: 0.67 val loss: 0.67 - train acc: 0.91 val acc: 0.87:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 9: - train loss: 0.67 val loss: 0.67 - train acc: 0.91 val acc: 0.87:   7%|▋         | 2/30 [00:00<00:08,  3.19it/s]\n",
      "Epoch 9: - train loss: 0.66 val loss: 0.61 - train acc: 0.87 val acc: 0.89:   7%|▋         | 2/30 [00:00<00:12,  2.18it/s]\n",
      "Epoch 9: - train loss: 0.67 val loss: 0.55 - train acc: 0.89 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:17,  1.62it/s]\n",
      "Epoch 9: - train loss: 0.67 val loss: 0.55 - train acc: 0.89 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:08,  3.24it/s]\n",
      "Epoch 9: - train loss: 0.63 val loss: 0.61 - train acc: 0.89 val acc: 0.92:  13%|█▎        | 4/30 [00:01<00:09,  2.62it/s]\n",
      "Epoch 9: - train loss: 0.57 val loss: 0.53 - train acc: 0.95 val acc: 0.93:  13%|█▎        | 4/30 [00:01<00:11,  2.17it/s]\n",
      "Epoch 9: - train loss: 0.57 val loss: 0.53 - train acc: 0.95 val acc: 0.93:  20%|██        | 6/30 [00:01<00:07,  3.26it/s]\n",
      "Epoch 9: - train loss: 0.54 val loss: 0.57 - train acc: 0.93 val acc: 0.88:  20%|██        | 6/30 [00:02<00:08,  2.79it/s]\n",
      "Epoch 9: - train loss: 0.61 val loss: 0.61 - train acc: 0.91 val acc: 0.91:  20%|██        | 6/30 [00:02<00:09,  2.43it/s]\n",
      "Epoch 9: - train loss: 0.61 val loss: 0.61 - train acc: 0.91 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:06,  3.23it/s]\n",
      "Epoch 9: - train loss: 0.65 val loss: 0.59 - train acc: 0.90 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:07,  2.87it/s]\n",
      "Epoch 9: - train loss: 0.54 val loss: 0.53 - train acc: 0.94 val acc: 0.93:  27%|██▋       | 8/30 [00:03<00:08,  2.60it/s]\n",
      "Epoch 9: - train loss: 0.54 val loss: 0.53 - train acc: 0.94 val acc: 0.93:  33%|███▎      | 10/30 [00:03<00:06,  3.25it/s]\n",
      "Epoch 9: - train loss: 0.59 val loss: 0.59 - train acc: 0.91 val acc: 0.88:  33%|███▎      | 10/30 [00:03<00:06,  2.97it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.51 - train acc: 0.96 val acc: 0.96:  33%|███▎      | 10/30 [00:03<00:07,  2.71it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.51 - train acc: 0.96 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.25it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.51 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.02it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.45 - train acc: 0.93 val acc: 0.98:  40%|████      | 12/30 [00:04<00:06,  2.81it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.45 - train acc: 0.93 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:04,  3.28it/s]\n",
      "Epoch 9: - train loss: 0.54 val loss: 0.65 - train acc: 0.91 val acc: 0.87:  47%|████▋     | 14/30 [00:04<00:05,  3.05it/s]\n",
      "Epoch 9: - train loss: 0.52 val loss: 0.55 - train acc: 0.92 val acc: 0.94:  47%|████▋     | 14/30 [00:04<00:05,  2.87it/s]\n",
      "Epoch 9: - train loss: 0.52 val loss: 0.55 - train acc: 0.92 val acc: 0.94:  53%|█████▎    | 16/30 [00:04<00:04,  3.28it/s]\n",
      "Epoch 9: - train loss: 0.58 val loss: 0.54 - train acc: 0.92 val acc: 0.91:  53%|█████▎    | 16/30 [00:05<00:04,  3.10it/s]\n",
      "Epoch 9: - train loss: 0.58 val loss: 0.54 - train acc: 0.94 val acc: 0.92:  53%|█████▎    | 16/30 [00:05<00:04,  2.92it/s]\n",
      "Epoch 9: - train loss: 0.58 val loss: 0.54 - train acc: 0.94 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.28it/s]\n",
      "Epoch 9: - train loss: 0.47 val loss: 0.57 - train acc: 0.95 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.11it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.49 - train acc: 0.91 val acc: 0.94:  60%|██████    | 18/30 [00:06<00:04,  2.96it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.49 - train acc: 0.91 val acc: 0.94:  67%|██████▋   | 20/30 [00:06<00:03,  3.29it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.52 - train acc: 0.94 val acc: 0.94:  67%|██████▋   | 20/30 [00:06<00:03,  3.13it/s]\n",
      "Epoch 9: - train loss: 0.52 val loss: 0.63 - train acc: 0.94 val acc: 0.90:  67%|██████▋   | 20/30 [00:06<00:03,  2.98it/s]\n",
      "Epoch 9: - train loss: 0.52 val loss: 0.63 - train acc: 0.94 val acc: 0.90:  73%|███████▎  | 22/30 [00:06<00:02,  3.28it/s]\n",
      "Epoch 9: - train loss: 0.58 val loss: 0.51 - train acc: 0.92 val acc: 0.91:  73%|███████▎  | 22/30 [00:06<00:02,  3.14it/s]\n",
      "Epoch 9: - train loss: 0.47 val loss: 0.51 - train acc: 0.95 val acc: 0.95:  73%|███████▎  | 22/30 [00:07<00:02,  3.02it/s]\n",
      "Epoch 9: - train loss: 0.47 val loss: 0.51 - train acc: 0.95 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.29it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.51 - train acc: 0.93 val acc: 0.91:  80%|████████  | 24/30 [00:07<00:01,  3.16it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.52 - train acc: 0.91 val acc: 0.90:  80%|████████  | 24/30 [00:07<00:01,  3.05it/s]\n",
      "Epoch 9: - train loss: 0.55 val loss: 0.52 - train acc: 0.91 val acc: 0.90:  87%|████████▋ | 26/30 [00:07<00:01,  3.30it/s]\n",
      "Epoch 9: - train loss: 0.48 val loss: 0.51 - train acc: 0.95 val acc: 0.91:  87%|████████▋ | 26/30 [00:08<00:01,  3.18it/s]\n",
      "Epoch 9: - train loss: 0.57 val loss: 0.50 - train acc: 0.94 val acc: 0.91:  87%|████████▋ | 26/30 [00:08<00:01,  3.06it/s]\n",
      "Epoch 9: - train loss: 0.57 val loss: 0.50 - train acc: 0.94 val acc: 0.91:  93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s]\n",
      "Epoch 9: - train loss: 0.46 val loss: 0.59 - train acc: 0.94 val acc: 0.87:  93%|█████████▎| 28/30 [00:08<00:00,  3.18it/s]\n",
      "Epoch 9: - train loss: 0.54 val loss: 0.52 - train acc: 0.92 val acc: 0.91:  93%|█████████▎| 28/30 [00:09<00:00,  3.08it/s]\n",
      "Epoch 9: - train loss: 0.54 val loss: 0.52 - train acc: 0.92 val acc: 0.91: 100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
      "Training progress:  33%|███▎      | 10/30 [01:32<03:05,  9.27s/it]\n",
      "Epoch 10:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 10: - train loss: 0.53 val loss: 0.53 - train acc: 0.91 val acc: 0.93:   0%|          | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: - train loss: 0.54 val loss: 0.51 - train acc: 0.95 val acc: 0.93:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 10: - train loss: 0.54 val loss: 0.51 - train acc: 0.95 val acc: 0.93:   7%|▋         | 2/30 [00:00<00:08,  3.40it/s]\n",
      "Epoch 10: - train loss: 0.52 val loss: 0.53 - train acc: 0.94 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.21it/s]\n",
      "Epoch 10: - train loss: 0.60 val loss: 0.44 - train acc: 0.86 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:16,  1.67it/s]\n",
      "Epoch 10: - train loss: 0.60 val loss: 0.44 - train acc: 0.86 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:07,  3.33it/s]\n",
      "Epoch 10: - train loss: 0.48 val loss: 0.43 - train acc: 0.98 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.68it/s]\n",
      "Epoch 10: - train loss: 0.49 val loss: 0.50 - train acc: 0.92 val acc: 0.94:  13%|█▎        | 4/30 [00:01<00:11,  2.24it/s]\n",
      "Epoch 10: - train loss: 0.49 val loss: 0.50 - train acc: 0.92 val acc: 0.94:  20%|██        | 6/30 [00:01<00:07,  3.36it/s]\n",
      "Epoch 10: - train loss: 0.55 val loss: 0.48 - train acc: 0.91 val acc: 0.94:  20%|██        | 6/30 [00:02<00:08,  2.89it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.48 - train acc: 0.95 val acc: 0.94:  20%|██        | 6/30 [00:02<00:09,  2.53it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.48 - train acc: 0.95 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:06,  3.37it/s]\n",
      "Epoch 10: - train loss: 0.52 val loss: 0.38 - train acc: 0.94 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:07,  2.97it/s]\n",
      "Epoch 10: - train loss: 0.51 val loss: 0.56 - train acc: 0.93 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:08,  2.68it/s]\n",
      "Epoch 10: - train loss: 0.51 val loss: 0.56 - train acc: 0.93 val acc: 0.91:  33%|███▎      | 10/30 [00:02<00:05,  3.35it/s]\n",
      "Epoch 10: - train loss: 0.57 val loss: 0.50 - train acc: 0.91 val acc: 0.93:  33%|███▎      | 10/30 [00:03<00:06,  3.03it/s]\n",
      "Epoch 10: - train loss: 0.47 val loss: 0.43 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:07,  2.79it/s]\n",
      "Epoch 10: - train loss: 0.47 val loss: 0.43 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.34it/s]\n",
      "Epoch 10: - train loss: 0.53 val loss: 0.53 - train acc: 0.93 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.09it/s]\n",
      "Epoch 10: - train loss: 0.49 val loss: 0.55 - train acc: 0.96 val acc: 0.91:  40%|████      | 12/30 [00:04<00:06,  2.87it/s]\n",
      "Epoch 10: - train loss: 0.49 val loss: 0.55 - train acc: 0.96 val acc: 0.91:  47%|████▋     | 14/30 [00:04<00:04,  3.35it/s]\n",
      "Epoch 10: - train loss: 0.54 val loss: 0.47 - train acc: 0.91 val acc: 0.93:  47%|████▋     | 14/30 [00:04<00:05,  3.13it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.52 - train acc: 0.92 val acc: 0.93:  47%|████▋     | 14/30 [00:04<00:05,  2.94it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.52 - train acc: 0.92 val acc: 0.93:  53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s]\n",
      "Epoch 10: - train loss: 0.44 val loss: 0.52 - train acc: 0.95 val acc: 0.93:  53%|█████▎    | 16/30 [00:05<00:04,  3.17it/s]\n",
      "Epoch 10: - train loss: 0.53 val loss: 0.49 - train acc: 0.91 val acc: 0.92:  53%|█████▎    | 16/30 [00:05<00:04,  2.99it/s]\n",
      "Epoch 10: - train loss: 0.53 val loss: 0.49 - train acc: 0.91 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 10: - train loss: 0.42 val loss: 0.52 - train acc: 0.96 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.47 - train acc: 0.91 val acc: 0.93:  60%|██████    | 18/30 [00:05<00:03,  3.04it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.47 - train acc: 0.91 val acc: 0.93:  67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s]\n",
      "Epoch 10: - train loss: 0.44 val loss: 0.45 - train acc: 0.94 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 10: - train loss: 0.47 val loss: 0.51 - train acc: 0.93 val acc: 0.92:  67%|██████▋   | 20/30 [00:06<00:03,  3.06it/s]\n",
      "Epoch 10: - train loss: 0.47 val loss: 0.51 - train acc: 0.93 val acc: 0.92:  73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s]\n",
      "Epoch 10: - train loss: 0.54 val loss: 0.52 - train acc: 0.90 val acc: 0.89:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 10: - train loss: 0.45 val loss: 0.48 - train acc: 0.92 val acc: 0.91:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 10: - train loss: 0.45 val loss: 0.48 - train acc: 0.92 val acc: 0.91:  80%|████████  | 24/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 10: - train loss: 0.51 val loss: 0.47 - train acc: 0.91 val acc: 0.93:  80%|████████  | 24/30 [00:07<00:01,  3.22it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.50 - train acc: 0.92 val acc: 0.91:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 10: - train loss: 0.50 val loss: 0.50 - train acc: 0.92 val acc: 0.91:  87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 10: - train loss: 0.51 val loss: 0.51 - train acc: 0.95 val acc: 0.91:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 10: - train loss: 0.43 val loss: 0.48 - train acc: 0.95 val acc: 0.94:  87%|████████▋ | 26/30 [00:08<00:01,  3.12it/s]\n",
      "Epoch 10: - train loss: 0.43 val loss: 0.48 - train acc: 0.95 val acc: 0.94:  93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s]\n",
      "Epoch 10: - train loss: 0.42 val loss: 0.45 - train acc: 0.97 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s]\n",
      "Epoch 10: - train loss: 0.52 val loss: 0.48 - train acc: 0.92 val acc: 0.91:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 10: - train loss: 0.52 val loss: 0.48 - train acc: 0.92 val acc: 0.91: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  37%|███▋      | 11/30 [01:41<02:55,  9.24s/it]\n",
      "Epoch 11:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 11: - train loss: 0.41 val loss: 0.46 - train acc: 0.96 val acc: 0.94:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.46 - train acc: 0.93 val acc: 0.93:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.46 - train acc: 0.93 val acc: 0.93:   7%|▋         | 2/30 [00:00<00:08,  3.28it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.43 - train acc: 0.91 val acc: 0.94:   7%|▋         | 2/30 [00:00<00:12,  2.22it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.48 - train acc: 0.91 val acc: 0.93:   7%|▋         | 2/30 [00:01<00:16,  1.68it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.48 - train acc: 0.91 val acc: 0.93:  13%|█▎        | 4/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 11: - train loss: 0.46 val loss: 0.44 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.69it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.40 - train acc: 0.92 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:11,  2.25it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.40 - train acc: 0.92 val acc: 0.98:  20%|██        | 6/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 11: - train loss: 0.43 val loss: 0.41 - train acc: 0.94 val acc: 0.95:  20%|██        | 6/30 [00:02<00:08,  2.89it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.42 - train acc: 0.91 val acc: 0.94:  20%|██        | 6/30 [00:02<00:09,  2.53it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.42 - train acc: 0.91 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:06,  3.37it/s]\n",
      "Epoch 11: - train loss: 0.39 val loss: 0.45 - train acc: 0.97 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:07,  2.98it/s]\n",
      "Epoch 11: - train loss: 0.43 val loss: 0.38 - train acc: 0.94 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:08,  2.68it/s]\n",
      "Epoch 11: - train loss: 0.43 val loss: 0.38 - train acc: 0.94 val acc: 0.95:  33%|███▎      | 10/30 [00:02<00:05,  3.35it/s]\n",
      "Epoch 11: - train loss: 0.40 val loss: 0.44 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:06,  3.03it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.43 - train acc: 0.92 val acc: 0.94:  33%|███▎      | 10/30 [00:03<00:07,  2.76it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.43 - train acc: 0.92 val acc: 0.94:  40%|████      | 12/30 [00:03<00:05,  3.32it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.52 - train acc: 0.94 val acc: 0.86:  40%|████      | 12/30 [00:03<00:05,  3.07it/s]\n",
      "Epoch 11: - train loss: 0.38 val loss: 0.44 - train acc: 0.97 val acc: 0.92:  40%|████      | 12/30 [00:04<00:06,  2.84it/s]\n",
      "Epoch 11: - train loss: 0.38 val loss: 0.44 - train acc: 0.97 val acc: 0.92:  47%|████▋     | 14/30 [00:04<00:04,  3.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: - train loss: 0.48 val loss: 0.43 - train acc: 0.95 val acc: 0.92:  47%|████▋     | 14/30 [00:04<00:05,  3.10it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.36 - train acc: 0.94 val acc: 0.97:  47%|████▋     | 14/30 [00:04<00:05,  2.91it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.36 - train acc: 0.94 val acc: 0.97:  53%|█████▎    | 16/30 [00:04<00:04,  3.33it/s]\n",
      "Epoch 11: - train loss: 0.51 val loss: 0.38 - train acc: 0.90 val acc: 0.97:  53%|█████▎    | 16/30 [00:05<00:04,  3.14it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.39 - train acc: 0.92 val acc: 0.94:  53%|█████▎    | 16/30 [00:05<00:04,  2.96it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.39 - train acc: 0.92 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.32it/s]\n",
      "Epoch 11: - train loss: 0.45 val loss: 0.42 - train acc: 0.92 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.16it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.42 - train acc: 0.91 val acc: 0.93:  60%|██████    | 18/30 [00:05<00:03,  3.00it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.42 - train acc: 0.91 val acc: 0.93:  67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.44 - train acc: 0.94 val acc: 0.92:  67%|██████▋   | 20/30 [00:06<00:03,  3.18it/s]\n",
      "Epoch 11: - train loss: 0.36 val loss: 0.41 - train acc: 0.97 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.03it/s]\n",
      "Epoch 11: - train loss: 0.36 val loss: 0.41 - train acc: 0.97 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.33it/s]\n",
      "Epoch 11: - train loss: 0.44 val loss: 0.35 - train acc: 0.91 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.18it/s]\n",
      "Epoch 11: - train loss: 0.41 val loss: 0.43 - train acc: 0.95 val acc: 0.94:  73%|███████▎  | 22/30 [00:07<00:02,  3.05it/s]\n",
      "Epoch 11: - train loss: 0.41 val loss: 0.43 - train acc: 0.95 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.33it/s]\n",
      "Epoch 11: - train loss: 0.42 val loss: 0.44 - train acc: 0.95 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.20it/s]\n",
      "Epoch 11: - train loss: 0.49 val loss: 0.37 - train acc: 0.91 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.08it/s]\n",
      "Epoch 11: - train loss: 0.49 val loss: 0.37 - train acc: 0.91 val acc: 0.97:  87%|████████▋ | 26/30 [00:07<00:01,  3.34it/s]\n",
      "Epoch 11: - train loss: 0.46 val loss: 0.45 - train acc: 0.91 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.22it/s]\n",
      "Epoch 11: - train loss: 0.40 val loss: 0.44 - train acc: 0.96 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.11it/s]\n",
      "Epoch 11: - train loss: 0.40 val loss: 0.44 - train acc: 0.96 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s]\n",
      "Epoch 11: - train loss: 0.42 val loss: 0.39 - train acc: 0.94 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.43 - train acc: 0.88 val acc: 0.91:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 11: - train loss: 0.48 val loss: 0.43 - train acc: 0.88 val acc: 0.91: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:  40%|████      | 12/30 [01:50<02:45,  9.21s/it]\n",
      "Epoch 12:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 12: - train loss: 0.42 val loss: 0.41 - train acc: 0.95 val acc: 0.92:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.43 - train acc: 0.97 val acc: 0.90:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.43 - train acc: 0.97 val acc: 0.90:   7%|▋         | 2/30 [00:00<00:08,  3.29it/s]\n",
      "Epoch 12: - train loss: 0.44 val loss: 0.44 - train acc: 0.93 val acc: 0.93:   7%|▋         | 2/30 [00:00<00:12,  2.16it/s]\n",
      "Epoch 12: - train loss: 0.37 val loss: 0.44 - train acc: 0.96 val acc: 0.94:   7%|▋         | 2/30 [00:01<00:17,  1.65it/s]\n",
      "Epoch 12: - train loss: 0.37 val loss: 0.44 - train acc: 0.96 val acc: 0.94:  13%|█▎        | 4/30 [00:01<00:07,  3.28it/s]\n",
      "Epoch 12: - train loss: 0.30 val loss: 0.33 - train acc: 0.99 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:09,  2.66it/s]\n",
      "Epoch 12: - train loss: 0.42 val loss: 0.40 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.20it/s]\n",
      "Epoch 12: - train loss: 0.42 val loss: 0.40 - train acc: 0.95 val acc: 0.95:  20%|██        | 6/30 [00:01<00:07,  3.30it/s]\n",
      "Epoch 12: - train loss: 0.39 val loss: 0.43 - train acc: 0.95 val acc: 0.93:  20%|██        | 6/30 [00:02<00:08,  2.84it/s]\n",
      "Epoch 12: - train loss: 0.43 val loss: 0.37 - train acc: 0.91 val acc: 0.94:  20%|██        | 6/30 [00:02<00:09,  2.50it/s]\n",
      "Epoch 12: - train loss: 0.43 val loss: 0.37 - train acc: 0.91 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:06,  3.33it/s]\n",
      "Epoch 12: - train loss: 0.41 val loss: 0.45 - train acc: 0.93 val acc: 0.91:  27%|██▋       | 8/30 [00:02<00:07,  2.97it/s]\n",
      "Epoch 12: - train loss: 0.37 val loss: 0.40 - train acc: 0.95 val acc: 0.93:  27%|██▋       | 8/30 [00:02<00:08,  2.68it/s]\n",
      "Epoch 12: - train loss: 0.37 val loss: 0.40 - train acc: 0.95 val acc: 0.93:  33%|███▎      | 10/30 [00:02<00:05,  3.35it/s]\n",
      "Epoch 12: - train loss: 0.42 val loss: 0.38 - train acc: 0.92 val acc: 0.94:  33%|███▎      | 10/30 [00:03<00:06,  3.06it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.38 - train acc: 0.94 val acc: 0.92:  33%|███▎      | 10/30 [00:03<00:07,  2.81it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.38 - train acc: 0.94 val acc: 0.92:  40%|████      | 12/30 [00:03<00:05,  3.36it/s]\n",
      "Epoch 12: - train loss: 0.50 val loss: 0.40 - train acc: 0.88 val acc: 0.92:  40%|████      | 12/30 [00:03<00:05,  3.11it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.36 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:04<00:06,  2.89it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.36 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 12: - train loss: 0.39 val loss: 0.41 - train acc: 0.93 val acc: 0.93:  47%|████▋     | 14/30 [00:04<00:05,  3.15it/s]\n",
      "Epoch 12: - train loss: 0.42 val loss: 0.31 - train acc: 0.92 val acc: 0.97:  47%|████▋     | 14/30 [00:04<00:05,  2.96it/s]\n",
      "Epoch 12: - train loss: 0.42 val loss: 0.31 - train acc: 0.92 val acc: 0.97:  53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 12: - train loss: 0.43 val loss: 0.36 - train acc: 0.94 val acc: 0.94:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 12: - train loss: 0.46 val loss: 0.39 - train acc: 0.89 val acc: 0.92:  53%|█████▎    | 16/30 [00:05<00:04,  3.00it/s]\n",
      "Epoch 12: - train loss: 0.46 val loss: 0.39 - train acc: 0.89 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.37it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.38 - train acc: 0.95 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.20it/s]\n",
      "Epoch 12: - train loss: 0.45 val loss: 0.35 - train acc: 0.91 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.04it/s]\n",
      "Epoch 12: - train loss: 0.45 val loss: 0.35 - train acc: 0.91 val acc: 0.95:  67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s]\n",
      "Epoch 12: - train loss: 0.36 val loss: 0.30 - train acc: 0.95 val acc: 0.96:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 12: - train loss: 0.47 val loss: 0.46 - train acc: 0.88 val acc: 0.90:  67%|██████▋   | 20/30 [00:06<00:03,  3.06it/s]\n",
      "Epoch 12: - train loss: 0.47 val loss: 0.46 - train acc: 0.88 val acc: 0.90:  73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s]\n",
      "Epoch 12: - train loss: 0.38 val loss: 0.43 - train acc: 0.95 val acc: 0.93:  73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s]\n",
      "Epoch 12: - train loss: 0.37 val loss: 0.35 - train acc: 0.97 val acc: 0.95:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 12: - train loss: 0.37 val loss: 0.35 - train acc: 0.97 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 12: - train loss: 0.40 val loss: 0.42 - train acc: 0.91 val acc: 0.93:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 12: - train loss: 0.36 val loss: 0.40 - train acc: 0.94 val acc: 0.93:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 12: - train loss: 0.36 val loss: 0.40 - train acc: 0.94 val acc: 0.93:  87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 12: - train loss: 0.38 val loss: 0.40 - train acc: 0.95 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: - train loss: 0.38 val loss: 0.43 - train acc: 0.95 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.12it/s]\n",
      "Epoch 12: - train loss: 0.38 val loss: 0.43 - train acc: 0.95 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s]\n",
      "Epoch 12: - train loss: 0.38 val loss: 0.30 - train acc: 0.95 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s]\n",
      "Epoch 12: - train loss: 0.41 val loss: 0.39 - train acc: 0.92 val acc: 0.94:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 12: - train loss: 0.41 val loss: 0.39 - train acc: 0.92 val acc: 0.94: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:  43%|████▎     | 13/30 [01:59<02:36,  9.19s/it]\n",
      "Epoch 13:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 13: - train loss: 0.42 val loss: 0.33 - train acc: 0.93 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 13: - train loss: 0.32 val loss: 0.34 - train acc: 0.97 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 13: - train loss: 0.32 val loss: 0.34 - train acc: 0.97 val acc: 0.96:   7%|▋         | 2/30 [00:00<00:08,  3.43it/s]\n",
      "Epoch 13: - train loss: 0.41 val loss: 0.36 - train acc: 0.95 val acc: 0.93:   7%|▋         | 2/30 [00:00<00:12,  2.28it/s]\n",
      "Epoch 13: - train loss: 0.41 val loss: 0.32 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:16,  1.72it/s]\n",
      "Epoch 13: - train loss: 0.41 val loss: 0.32 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:07,  3.43it/s]\n",
      "Epoch 13: - train loss: 0.36 val loss: 0.36 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.75it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.40 - train acc: 0.97 val acc: 0.93:  13%|█▎        | 4/30 [00:01<00:11,  2.29it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.40 - train acc: 0.97 val acc: 0.93:  20%|██        | 6/30 [00:01<00:06,  3.43it/s]\n",
      "Epoch 13: - train loss: 0.30 val loss: 0.40 - train acc: 0.96 val acc: 0.91:  20%|██        | 6/30 [00:02<00:08,  2.94it/s]\n",
      "Epoch 13: - train loss: 0.40 val loss: 0.32 - train acc: 0.93 val acc: 0.96:  20%|██        | 6/30 [00:02<00:09,  2.58it/s]\n",
      "Epoch 13: - train loss: 0.40 val loss: 0.32 - train acc: 0.93 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:06,  3.43it/s]\n",
      "Epoch 13: - train loss: 0.32 val loss: 0.34 - train acc: 0.96 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:07,  3.05it/s]\n",
      "Epoch 13: - train loss: 0.44 val loss: 0.32 - train acc: 0.91 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:08,  2.75it/s]\n",
      "Epoch 13: - train loss: 0.44 val loss: 0.32 - train acc: 0.91 val acc: 0.95:  33%|███▎      | 10/30 [00:02<00:05,  3.43it/s]\n",
      "Epoch 13: - train loss: 0.27 val loss: 0.34 - train acc: 0.97 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:06,  3.12it/s]\n",
      "Epoch 13: - train loss: 0.33 val loss: 0.39 - train acc: 0.95 val acc: 0.92:  33%|███▎      | 10/30 [00:03<00:06,  2.86it/s]\n",
      "Epoch 13: - train loss: 0.33 val loss: 0.39 - train acc: 0.95 val acc: 0.92:  40%|████      | 12/30 [00:03<00:05,  3.43it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.46 - train acc: 0.95 val acc: 0.90:  40%|████      | 12/30 [00:03<00:05,  3.15it/s]\n",
      "Epoch 13: - train loss: 0.36 val loss: 0.36 - train acc: 0.95 val acc: 0.94:  40%|████      | 12/30 [00:04<00:06,  2.92it/s]\n",
      "Epoch 13: - train loss: 0.36 val loss: 0.36 - train acc: 0.95 val acc: 0.94:  47%|████▋     | 14/30 [00:04<00:04,  3.41it/s]\n",
      "Epoch 13: - train loss: 0.31 val loss: 0.28 - train acc: 0.94 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:05,  3.18it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.33 - train acc: 0.97 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.99it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.33 - train acc: 0.97 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.41it/s]\n",
      "Epoch 13: - train loss: 0.40 val loss: 0.33 - train acc: 0.91 val acc: 0.97:  53%|█████▎    | 16/30 [00:04<00:04,  3.21it/s]\n",
      "Epoch 13: - train loss: 0.39 val loss: 0.37 - train acc: 0.93 val acc: 0.93:  53%|█████▎    | 16/30 [00:05<00:04,  3.03it/s]\n",
      "Epoch 13: - train loss: 0.39 val loss: 0.37 - train acc: 0.93 val acc: 0.93:  60%|██████    | 18/30 [00:05<00:03,  3.41it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.32 - train acc: 0.96 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.23it/s]\n",
      "Epoch 13: - train loss: 0.31 val loss: 0.35 - train acc: 0.97 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.07it/s]\n",
      "Epoch 13: - train loss: 0.31 val loss: 0.35 - train acc: 0.97 val acc: 0.95:  67%|██████▋   | 20/30 [00:05<00:02,  3.41it/s]\n",
      "Epoch 13: - train loss: 0.35 val loss: 0.32 - train acc: 0.95 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.24it/s]\n",
      "Epoch 13: - train loss: 0.39 val loss: 0.35 - train acc: 0.91 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.09it/s]\n",
      "Epoch 13: - train loss: 0.39 val loss: 0.35 - train acc: 0.91 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.40it/s]\n",
      "Epoch 13: - train loss: 0.40 val loss: 0.36 - train acc: 0.92 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s]\n",
      "Epoch 13: - train loss: 0.33 val loss: 0.36 - train acc: 0.95 val acc: 0.95:  73%|███████▎  | 22/30 [00:07<00:02,  3.12it/s]\n",
      "Epoch 13: - train loss: 0.33 val loss: 0.36 - train acc: 0.95 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.40it/s]\n",
      "Epoch 13: - train loss: 0.34 val loss: 0.33 - train acc: 0.94 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.27it/s]\n",
      "Epoch 13: - train loss: 0.40 val loss: 0.33 - train acc: 0.95 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.15it/s]\n",
      "Epoch 13: - train loss: 0.40 val loss: 0.33 - train acc: 0.95 val acc: 0.96:  87%|████████▋ | 26/30 [00:07<00:01,  3.41it/s]\n",
      "Epoch 13: - train loss: 0.39 val loss: 0.37 - train acc: 0.90 val acc: 0.93:  87%|████████▋ | 26/30 [00:07<00:01,  3.28it/s]\n",
      "Epoch 13: - train loss: 0.38 val loss: 0.37 - train acc: 0.93 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.17it/s]\n",
      "Epoch 13: - train loss: 0.38 val loss: 0.37 - train acc: 0.93 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.41it/s]\n",
      "Epoch 13: - train loss: 0.35 val loss: 0.37 - train acc: 0.93 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.29it/s]\n",
      "Epoch 13: - train loss: 0.23 val loss: 0.39 - train acc: 0.98 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.19it/s]\n",
      "Epoch 13: - train loss: 0.23 val loss: 0.39 - train acc: 0.98 val acc: 0.93: 100%|██████████| 30/30 [00:08<00:00,  3.41it/s]\n",
      "Training progress:  47%|████▋     | 14/30 [02:08<02:26,  9.17s/it]\n",
      "Epoch 14:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 14: - train loss: 0.40 val loss: 0.30 - train acc: 0.92 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 14: - train loss: 0.45 val loss: 0.37 - train acc: 0.89 val acc: 0.94:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 14: - train loss: 0.45 val loss: 0.37 - train acc: 0.89 val acc: 0.94:   7%|▋         | 2/30 [00:00<00:08,  3.32it/s]\n",
      "Epoch 14: - train loss: 0.35 val loss: 0.28 - train acc: 0.93 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.24it/s]\n",
      "Epoch 14: - train loss: 0.31 val loss: 0.38 - train acc: 0.97 val acc: 0.90:   7%|▋         | 2/30 [00:01<00:16,  1.69it/s]\n",
      "Epoch 14: - train loss: 0.31 val loss: 0.38 - train acc: 0.97 val acc: 0.90:  13%|█▎        | 4/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 14: - train loss: 0.46 val loss: 0.35 - train acc: 0.90 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.67it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.38 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.24it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.38 - train acc: 0.95 val acc: 0.95:  20%|██        | 6/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 14: - train loss: 0.39 val loss: 0.32 - train acc: 0.91 val acc: 0.93:  20%|██        | 6/30 [00:02<00:08,  2.85it/s]\n",
      "Epoch 14: - train loss: 0.37 val loss: 0.40 - train acc: 0.92 val acc: 0.90:  20%|██        | 6/30 [00:02<00:09,  2.48it/s]\n",
      "Epoch 14: - train loss: 0.37 val loss: 0.40 - train acc: 0.92 val acc: 0.90:  27%|██▋       | 8/30 [00:02<00:06,  3.30it/s]\n",
      "Epoch 14: - train loss: 0.35 val loss: 0.32 - train acc: 0.96 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:07,  2.95it/s]\n",
      "Epoch 14: - train loss: 0.36 val loss: 0.33 - train acc: 0.96 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:08,  2.67it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: - train loss: 0.36 val loss: 0.33 - train acc: 0.96 val acc: 0.97:  33%|███▎      | 10/30 [00:03<00:06,  3.33it/s]\n",
      "Epoch 14: - train loss: 0.27 val loss: 0.39 - train acc: 0.97 val acc: 0.90:  33%|███▎      | 10/30 [00:03<00:06,  3.04it/s]\n",
      "Epoch 14: - train loss: 0.31 val loss: 0.37 - train acc: 0.95 val acc: 0.94:  33%|███▎      | 10/30 [00:03<00:07,  2.80it/s]\n",
      "Epoch 14: - train loss: 0.31 val loss: 0.37 - train acc: 0.95 val acc: 0.94:  40%|████      | 12/30 [00:03<00:05,  3.35it/s]\n",
      "Epoch 14: - train loss: 0.27 val loss: 0.32 - train acc: 0.96 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.10it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.35 - train acc: 0.93 val acc: 0.96:  40%|████      | 12/30 [00:04<00:06,  2.88it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.35 - train acc: 0.93 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:04,  3.36it/s]\n",
      "Epoch 14: - train loss: 0.35 val loss: 0.32 - train acc: 0.94 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  3.15it/s]\n",
      "Epoch 14: - train loss: 0.28 val loss: 0.30 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.95it/s]\n",
      "Epoch 14: - train loss: 0.28 val loss: 0.30 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 14: - train loss: 0.33 val loss: 0.29 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.40 - train acc: 0.92 val acc: 0.91:  53%|█████▎    | 16/30 [00:05<00:04,  2.99it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.40 - train acc: 0.92 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 14: - train loss: 0.30 val loss: 0.35 - train acc: 0.94 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 14: - train loss: 0.36 val loss: 0.33 - train acc: 0.93 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 14: - train loss: 0.36 val loss: 0.33 - train acc: 0.93 val acc: 0.95:  67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.32 - train acc: 0.95 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.20it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.36 - train acc: 0.91 val acc: 0.91:  67%|██████▋   | 20/30 [00:06<00:03,  3.05it/s]\n",
      "Epoch 14: - train loss: 0.34 val loss: 0.36 - train acc: 0.91 val acc: 0.91:  73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s]\n",
      "Epoch 14: - train loss: 0.32 val loss: 0.35 - train acc: 0.95 val acc: 0.92:  73%|███████▎  | 22/30 [00:06<00:02,  3.21it/s]\n",
      "Epoch 14: - train loss: 0.42 val loss: 0.35 - train acc: 0.91 val acc: 0.94:  73%|███████▎  | 22/30 [00:07<00:02,  3.08it/s]\n",
      "Epoch 14: - train loss: 0.42 val loss: 0.35 - train acc: 0.91 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 14: - train loss: 0.32 val loss: 0.30 - train acc: 0.95 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.22it/s]\n",
      "Epoch 14: - train loss: 0.32 val loss: 0.27 - train acc: 0.96 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.08it/s]\n",
      "Epoch 14: - train loss: 0.32 val loss: 0.27 - train acc: 0.96 val acc: 0.96:  87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s]\n",
      "Epoch 14: - train loss: 0.28 val loss: 0.37 - train acc: 0.95 val acc: 0.91:  87%|████████▋ | 26/30 [00:08<00:01,  3.20it/s]\n",
      "Epoch 14: - train loss: 0.32 val loss: 0.30 - train acc: 0.95 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.07it/s]\n",
      "Epoch 14: - train loss: 0.32 val loss: 0.30 - train acc: 0.95 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s]\n",
      "Epoch 14: - train loss: 0.42 val loss: 0.35 - train acc: 0.91 val acc: 0.94:  93%|█████████▎| 28/30 [00:08<00:00,  3.19it/s]\n",
      "Epoch 14: - train loss: 0.29 val loss: 0.26 - train acc: 0.95 val acc: 0.98:  93%|█████████▎| 28/30 [00:09<00:00,  3.09it/s]\n",
      "Epoch 14: - train loss: 0.29 val loss: 0.26 - train acc: 0.95 val acc: 0.98: 100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "Training progress:  50%|█████     | 15/30 [02:17<02:17,  9.16s/it]\n",
      "Epoch 15:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 15: - train loss: 0.41 val loss: 0.30 - train acc: 0.91 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 15: - train loss: 0.36 val loss: 0.30 - train acc: 0.93 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 15: - train loss: 0.36 val loss: 0.30 - train acc: 0.93 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.14it/s]\n",
      "Epoch 15: - train loss: 0.40 val loss: 0.30 - train acc: 0.90 val acc: 0.96:   7%|▋         | 2/30 [00:00<00:13,  2.15it/s]\n",
      "Epoch 15: - train loss: 0.39 val loss: 0.27 - train acc: 0.92 val acc: 0.97:   7%|▋         | 2/30 [00:01<00:17,  1.64it/s]\n",
      "Epoch 15: - train loss: 0.39 val loss: 0.27 - train acc: 0.92 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:07,  3.27it/s]\n",
      "Epoch 15: - train loss: 0.35 val loss: 0.29 - train acc: 0.93 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:09,  2.63it/s]\n",
      "Epoch 15: - train loss: 0.36 val loss: 0.29 - train acc: 0.91 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:11,  2.18it/s]\n",
      "Epoch 15: - train loss: 0.36 val loss: 0.29 - train acc: 0.91 val acc: 0.97:  20%|██        | 6/30 [00:01<00:07,  3.27it/s]\n",
      "Epoch 15: - train loss: 0.36 val loss: 0.31 - train acc: 0.93 val acc: 0.96:  20%|██        | 6/30 [00:02<00:08,  2.82it/s]\n",
      "Epoch 15: - train loss: 0.39 val loss: 0.26 - train acc: 0.91 val acc: 0.95:  20%|██        | 6/30 [00:02<00:09,  2.48it/s]\n",
      "Epoch 15: - train loss: 0.39 val loss: 0.26 - train acc: 0.91 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:06,  3.30it/s]\n",
      "Epoch 15: - train loss: 0.30 val loss: 0.33 - train acc: 0.96 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:07,  2.94it/s]\n",
      "Epoch 15: - train loss: 0.34 val loss: 0.28 - train acc: 0.93 val acc: 0.95:  27%|██▋       | 8/30 [00:03<00:08,  2.63it/s]\n",
      "Epoch 15: - train loss: 0.34 val loss: 0.28 - train acc: 0.93 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:06,  3.29it/s]\n",
      "Epoch 15: - train loss: 0.31 val loss: 0.25 - train acc: 0.94 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:06,  2.99it/s]\n",
      "Epoch 15: - train loss: 0.28 val loss: 0.27 - train acc: 0.96 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:07,  2.75it/s]\n",
      "Epoch 15: - train loss: 0.28 val loss: 0.27 - train acc: 0.96 val acc: 0.98:  40%|████      | 12/30 [00:03<00:05,  3.30it/s]\n",
      "Epoch 15: - train loss: 0.27 val loss: 0.26 - train acc: 0.96 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.05it/s]\n",
      "Epoch 15: - train loss: 0.27 val loss: 0.47 - train acc: 0.96 val acc: 0.91:  40%|████      | 12/30 [00:04<00:06,  2.83it/s]\n",
      "Epoch 15: - train loss: 0.27 val loss: 0.47 - train acc: 0.96 val acc: 0.91:  47%|████▋     | 14/30 [00:04<00:04,  3.29it/s]\n",
      "Epoch 15: - train loss: 0.34 val loss: 0.30 - train acc: 0.91 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  3.06it/s]\n",
      "Epoch 15: - train loss: 0.31 val loss: 0.34 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.88it/s]\n",
      "Epoch 15: - train loss: 0.31 val loss: 0.34 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.29it/s]\n",
      "Epoch 15: - train loss: 0.22 val loss: 0.31 - train acc: 0.98 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.11it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.27 - train acc: 0.94 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  2.94it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.27 - train acc: 0.94 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.31it/s]\n",
      "Epoch 15: - train loss: 0.31 val loss: 0.28 - train acc: 0.95 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.14it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.24 - train acc: 0.95 val acc: 0.98:  60%|██████    | 18/30 [00:06<00:04,  2.98it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.24 - train acc: 0.95 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.30it/s]\n",
      "Epoch 15: - train loss: 0.33 val loss: 0.24 - train acc: 0.94 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.15it/s]\n",
      "Epoch 15: - train loss: 0.29 val loss: 0.28 - train acc: 0.96 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.01it/s]\n",
      "Epoch 15: - train loss: 0.29 val loss: 0.28 - train acc: 0.96 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: - train loss: 0.30 val loss: 0.23 - train acc: 0.95 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.17it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.29 - train acc: 0.95 val acc: 0.94:  73%|███████▎  | 22/30 [00:07<00:02,  3.03it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.29 - train acc: 0.95 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.31it/s]\n",
      "Epoch 15: - train loss: 0.38 val loss: 0.25 - train acc: 0.93 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.18it/s]\n",
      "Epoch 15: - train loss: 0.28 val loss: 0.27 - train acc: 0.95 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.06it/s]\n",
      "Epoch 15: - train loss: 0.28 val loss: 0.27 - train acc: 0.95 val acc: 0.97:  87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s]\n",
      "Epoch 15: - train loss: 0.32 val loss: 0.24 - train acc: 0.92 val acc: 0.97:  87%|████████▋ | 26/30 [00:08<00:01,  3.19it/s]\n",
      "Epoch 15: - train loss: 0.41 val loss: 0.31 - train acc: 0.93 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.08it/s]\n",
      "Epoch 15: - train loss: 0.41 val loss: 0.31 - train acc: 0.93 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.31it/s]\n",
      "Epoch 15: - train loss: 0.34 val loss: 0.26 - train acc: 0.92 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.20it/s]\n",
      "Epoch 15: - train loss: 0.29 val loss: 0.27 - train acc: 0.95 val acc: 0.97:  93%|█████████▎| 28/30 [00:09<00:00,  3.09it/s]\n",
      "Epoch 15: - train loss: 0.29 val loss: 0.27 - train acc: 0.95 val acc: 0.97: 100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "Training progress:  53%|█████▎    | 16/30 [02:26<02:08,  9.15s/it]\n",
      "Epoch 16:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.32 - train acc: 0.95 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 16: - train loss: 0.28 val loss: 0.33 - train acc: 0.98 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 16: - train loss: 0.28 val loss: 0.33 - train acc: 0.98 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.41it/s]\n",
      "Epoch 16: - train loss: 0.36 val loss: 0.28 - train acc: 0.92 val acc: 0.96:   7%|▋         | 2/30 [00:00<00:12,  2.21it/s]\n",
      "Epoch 16: - train loss: 0.30 val loss: 0.30 - train acc: 0.95 val acc: 0.94:   7%|▋         | 2/30 [00:01<00:17,  1.64it/s]\n",
      "Epoch 16: - train loss: 0.30 val loss: 0.30 - train acc: 0.95 val acc: 0.94:  13%|█▎        | 4/30 [00:01<00:07,  3.27it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.25 - train acc: 0.94 val acc: 0.96:  13%|█▎        | 4/30 [00:01<00:10,  2.60it/s]\n",
      "Epoch 16: - train loss: 0.26 val loss: 0.30 - train acc: 0.97 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.18it/s]\n",
      "Epoch 16: - train loss: 0.26 val loss: 0.30 - train acc: 0.97 val acc: 0.95:  20%|██        | 6/30 [00:01<00:07,  3.27it/s]\n",
      "Epoch 16: - train loss: 0.35 val loss: 0.26 - train acc: 0.95 val acc: 0.97:  20%|██        | 6/30 [00:02<00:08,  2.83it/s]\n",
      "Epoch 16: - train loss: 0.30 val loss: 0.26 - train acc: 0.92 val acc: 0.97:  20%|██        | 6/30 [00:02<00:09,  2.48it/s]\n",
      "Epoch 16: - train loss: 0.30 val loss: 0.26 - train acc: 0.92 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:06,  3.31it/s]\n",
      "Epoch 16: - train loss: 0.26 val loss: 0.20 - train acc: 0.96 val acc: 0.99:  27%|██▋       | 8/30 [00:02<00:07,  2.92it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.23 - train acc: 0.94 val acc: 0.98:  27%|██▋       | 8/30 [00:03<00:08,  2.64it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.23 - train acc: 0.94 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:06,  3.30it/s]\n",
      "Epoch 16: - train loss: 0.27 val loss: 0.28 - train acc: 0.96 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:06,  3.01it/s]\n",
      "Epoch 16: - train loss: 0.29 val loss: 0.33 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:07,  2.77it/s]\n",
      "Epoch 16: - train loss: 0.29 val loss: 0.33 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.32it/s]\n",
      "Epoch 16: - train loss: 0.20 val loss: 0.25 - train acc: 0.98 val acc: 0.97:  40%|████      | 12/30 [00:03<00:05,  3.07it/s]\n",
      "Epoch 16: - train loss: 0.27 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:04<00:06,  2.86it/s]\n",
      "Epoch 16: - train loss: 0.27 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:04,  3.33it/s]\n",
      "Epoch 16: - train loss: 0.28 val loss: 0.29 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  3.11it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.25 - train acc: 0.93 val acc: 0.97:  47%|████▋     | 14/30 [00:04<00:05,  2.92it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.25 - train acc: 0.93 val acc: 0.97:  53%|█████▎    | 16/30 [00:04<00:04,  3.34it/s]\n",
      "Epoch 16: - train loss: 0.32 val loss: 0.25 - train acc: 0.94 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  3.15it/s]\n",
      "Epoch 16: - train loss: 0.31 val loss: 0.32 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  2.98it/s]\n",
      "Epoch 16: - train loss: 0.31 val loss: 0.32 - train acc: 0.95 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.35it/s]\n",
      "Epoch 16: - train loss: 0.29 val loss: 0.29 - train acc: 0.93 val acc: 0.96:  60%|██████    | 18/30 [00:05<00:03,  3.17it/s]\n",
      "Epoch 16: - train loss: 0.22 val loss: 0.27 - train acc: 0.98 val acc: 0.96:  60%|██████    | 18/30 [00:05<00:03,  3.01it/s]\n",
      "Epoch 16: - train loss: 0.22 val loss: 0.27 - train acc: 0.98 val acc: 0.96:  67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s]\n",
      "Epoch 16: - train loss: 0.34 val loss: 0.23 - train acc: 0.92 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.17it/s]\n",
      "Epoch 16: - train loss: 0.24 val loss: 0.31 - train acc: 0.97 val acc: 0.93:  67%|██████▋   | 20/30 [00:06<00:03,  3.02it/s]\n",
      "Epoch 16: - train loss: 0.24 val loss: 0.31 - train acc: 0.97 val acc: 0.93:  73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s]\n",
      "Epoch 16: - train loss: 0.23 val loss: 0.30 - train acc: 0.97 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.18it/s]\n",
      "Epoch 16: - train loss: 0.30 val loss: 0.25 - train acc: 0.93 val acc: 0.97:  73%|███████▎  | 22/30 [00:07<00:02,  3.05it/s]\n",
      "Epoch 16: - train loss: 0.30 val loss: 0.25 - train acc: 0.93 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.33it/s]\n",
      "Epoch 16: - train loss: 0.33 val loss: 0.31 - train acc: 0.95 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.20it/s]\n",
      "Epoch 16: - train loss: 0.23 val loss: 0.25 - train acc: 0.96 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.07it/s]\n",
      "Epoch 16: - train loss: 0.23 val loss: 0.25 - train acc: 0.96 val acc: 0.97:  87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s]\n",
      "Epoch 16: - train loss: 0.22 val loss: 0.44 - train acc: 0.98 val acc: 0.88:  87%|████████▋ | 26/30 [00:08<00:01,  3.21it/s]\n",
      "Epoch 16: - train loss: 0.27 val loss: 0.23 - train acc: 0.95 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.10it/s]\n",
      "Epoch 16: - train loss: 0.27 val loss: 0.23 - train acc: 0.95 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s]\n",
      "Epoch 16: - train loss: 0.27 val loss: 0.33 - train acc: 0.96 val acc: 0.91:  93%|█████████▎| 28/30 [00:08<00:00,  3.22it/s]\n",
      "Epoch 16: - train loss: 0.24 val loss: 0.22 - train acc: 0.96 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.12it/s]\n",
      "Epoch 16: - train loss: 0.24 val loss: 0.22 - train acc: 0.96 val acc: 0.97: 100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
      "Training progress:  57%|█████▋    | 17/30 [02:35<01:58,  9.14s/it]\n",
      "Epoch 17:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 17: - train loss: 0.28 val loss: 0.22 - train acc: 0.95 val acc: 0.99:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 17: - train loss: 0.25 val loss: 0.27 - train acc: 0.97 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 17: - train loss: 0.25 val loss: 0.27 - train acc: 0.97 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.45it/s]\n",
      "Epoch 17: - train loss: 0.26 val loss: 0.27 - train acc: 0.94 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.31it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.29 - train acc: 0.92 val acc: 0.92:   7%|▋         | 2/30 [00:01<00:16,  1.73it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.29 - train acc: 0.92 val acc: 0.92:  13%|█▎        | 4/30 [00:01<00:07,  3.45it/s]\n",
      "Epoch 17: - train loss: 0.35 val loss: 0.27 - train acc: 0.92 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: - train loss: 0.24 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.30it/s]\n",
      "Epoch 17: - train loss: 0.24 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  20%|██        | 6/30 [00:01<00:06,  3.45it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.23 - train acc: 0.94 val acc: 0.96:  20%|██        | 6/30 [00:02<00:08,  2.92it/s]\n",
      "Epoch 17: - train loss: 0.24 val loss: 0.29 - train acc: 0.95 val acc: 0.96:  20%|██        | 6/30 [00:02<00:09,  2.56it/s]\n",
      "Epoch 17: - train loss: 0.24 val loss: 0.29 - train acc: 0.95 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:06,  3.40it/s]\n",
      "Epoch 17: - train loss: 0.19 val loss: 0.25 - train acc: 0.99 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:07,  3.00it/s]\n",
      "Epoch 17: - train loss: 0.36 val loss: 0.29 - train acc: 0.91 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:08,  2.71it/s]\n",
      "Epoch 17: - train loss: 0.36 val loss: 0.29 - train acc: 0.91 val acc: 0.96:  33%|███▎      | 10/30 [00:02<00:05,  3.38it/s]\n",
      "Epoch 17: - train loss: 0.32 val loss: 0.28 - train acc: 0.96 val acc: 0.93:  33%|███▎      | 10/30 [00:03<00:06,  3.08it/s]\n",
      "Epoch 17: - train loss: 0.29 val loss: 0.29 - train acc: 0.95 val acc: 0.96:  33%|███▎      | 10/30 [00:03<00:07,  2.80it/s]\n",
      "Epoch 17: - train loss: 0.29 val loss: 0.29 - train acc: 0.95 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.36it/s]\n",
      "Epoch 17: - train loss: 0.23 val loss: 0.23 - train acc: 0.97 val acc: 0.98:  40%|████      | 12/30 [00:03<00:05,  3.11it/s]\n",
      "Epoch 17: - train loss: 0.32 val loss: 0.29 - train acc: 0.93 val acc: 0.93:  40%|████      | 12/30 [00:04<00:06,  2.90it/s]\n",
      "Epoch 17: - train loss: 0.32 val loss: 0.29 - train acc: 0.93 val acc: 0.93:  47%|████▋     | 14/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 17: - train loss: 0.24 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  3.14it/s]\n",
      "Epoch 17: - train loss: 0.34 val loss: 0.30 - train acc: 0.93 val acc: 0.92:  47%|████▋     | 14/30 [00:04<00:05,  2.93it/s]\n",
      "Epoch 17: - train loss: 0.34 val loss: 0.30 - train acc: 0.93 val acc: 0.92:  53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.26 - train acc: 0.91 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  3.16it/s]\n",
      "Epoch 17: - train loss: 0.29 val loss: 0.24 - train acc: 0.94 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  2.99it/s]\n",
      "Epoch 17: - train loss: 0.29 val loss: 0.24 - train acc: 0.94 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 17: - train loss: 0.29 val loss: 0.28 - train acc: 0.95 val acc: 0.96:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 17: - train loss: 0.33 val loss: 0.28 - train acc: 0.92 val acc: 0.93:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 17: - train loss: 0.33 val loss: 0.28 - train acc: 0.92 val acc: 0.93:  67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s]\n",
      "Epoch 17: - train loss: 0.31 val loss: 0.26 - train acc: 0.93 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.23 - train acc: 0.94 val acc: 0.96:  67%|██████▋   | 20/30 [00:06<00:03,  3.07it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.23 - train acc: 0.94 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s]\n",
      "Epoch 17: - train loss: 0.24 val loss: 0.28 - train acc: 0.97 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 17: - train loss: 0.25 val loss: 0.25 - train acc: 0.97 val acc: 0.95:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 17: - train loss: 0.25 val loss: 0.25 - train acc: 0.97 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 17: - train loss: 0.32 val loss: 0.23 - train acc: 0.91 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.22it/s]\n",
      "Epoch 17: - train loss: 0.26 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 17: - train loss: 0.26 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 17: - train loss: 0.21 val loss: 0.31 - train acc: 0.98 val acc: 0.94:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 17: - train loss: 0.20 val loss: 0.28 - train acc: 0.97 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 17: - train loss: 0.20 val loss: 0.28 - train acc: 0.97 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 17: - train loss: 0.30 val loss: 0.23 - train acc: 0.94 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s]\n",
      "Epoch 17: - train loss: 0.33 val loss: 0.21 - train acc: 0.92 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 17: - train loss: 0.33 val loss: 0.21 - train acc: 0.92 val acc: 0.97: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:  60%|██████    | 18/30 [02:44<01:49,  9.13s/it]\n",
      "Epoch 18:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 18: - train loss: 0.20 val loss: 0.28 - train acc: 0.97 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 18: - train loss: 0.25 val loss: 0.24 - train acc: 0.98 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 18: - train loss: 0.25 val loss: 0.24 - train acc: 0.98 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.42it/s]\n",
      "Epoch 18: - train loss: 0.23 val loss: 0.23 - train acc: 0.94 val acc: 0.97:   7%|▋         | 2/30 [00:00<00:12,  2.29it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.23 - train acc: 0.95 val acc: 0.97:   7%|▋         | 2/30 [00:01<00:16,  1.68it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.23 - train acc: 0.95 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:07,  3.36it/s]\n",
      "Epoch 18: - train loss: 0.25 val loss: 0.26 - train acc: 0.95 val acc: 0.94:  13%|█▎        | 4/30 [00:01<00:09,  2.70it/s]\n",
      "Epoch 18: - train loss: 0.32 val loss: 0.19 - train acc: 0.92 val acc: 0.96:  13%|█▎        | 4/30 [00:01<00:11,  2.25it/s]\n",
      "Epoch 18: - train loss: 0.32 val loss: 0.19 - train acc: 0.92 val acc: 0.96:  20%|██        | 6/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.19 - train acc: 0.97 val acc: 0.97:  20%|██        | 6/30 [00:02<00:08,  2.90it/s]\n",
      "Epoch 18: - train loss: 0.24 val loss: 0.30 - train acc: 0.97 val acc: 0.95:  20%|██        | 6/30 [00:02<00:09,  2.55it/s]\n",
      "Epoch 18: - train loss: 0.24 val loss: 0.30 - train acc: 0.97 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:06,  3.39it/s]\n",
      "Epoch 18: - train loss: 0.25 val loss: 0.28 - train acc: 0.93 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:07,  3.02it/s]\n",
      "Epoch 18: - train loss: 0.27 val loss: 0.30 - train acc: 0.97 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:08,  2.72it/s]\n",
      "Epoch 18: - train loss: 0.27 val loss: 0.30 - train acc: 0.97 val acc: 0.95:  33%|███▎      | 10/30 [00:02<00:05,  3.40it/s]\n",
      "Epoch 18: - train loss: 0.19 val loss: 0.27 - train acc: 0.96 val acc: 0.94:  33%|███▎      | 10/30 [00:03<00:06,  3.09it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.24 - train acc: 0.93 val acc: 0.97:  33%|███▎      | 10/30 [00:03<00:07,  2.82it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.24 - train acc: 0.93 val acc: 0.97:  40%|████      | 12/30 [00:03<00:05,  3.38it/s]\n",
      "Epoch 18: - train loss: 0.24 val loss: 0.27 - train acc: 0.95 val acc: 0.94:  40%|████      | 12/30 [00:03<00:05,  3.12it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.27 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:04<00:06,  2.90it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.27 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:04,  3.39it/s]\n",
      "Epoch 18: - train loss: 0.33 val loss: 0.24 - train acc: 0.95 val acc: 0.94:  47%|████▋     | 14/30 [00:04<00:05,  3.14it/s]\n",
      "Epoch 18: - train loss: 0.30 val loss: 0.26 - train acc: 0.94 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.95it/s]\n",
      "Epoch 18: - train loss: 0.30 val loss: 0.26 - train acc: 0.94 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 18: - train loss: 0.27 val loss: 0.18 - train acc: 0.94 val acc: 0.99:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 18: - train loss: 0.24 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: - train loss: 0.24 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.38it/s]\n",
      "Epoch 18: - train loss: 0.22 val loss: 0.21 - train acc: 0.96 val acc: 0.97:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.23 - train acc: 0.94 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.02it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.23 - train acc: 0.94 val acc: 0.98:  67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s]\n",
      "Epoch 18: - train loss: 0.28 val loss: 0.22 - train acc: 0.95 val acc: 0.97:  67%|██████▋   | 20/30 [00:06<00:03,  3.20it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.19 - train acc: 0.94 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.06it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.19 - train acc: 0.94 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s]\n",
      "Epoch 18: - train loss: 0.24 val loss: 0.19 - train acc: 0.92 val acc: 0.97:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  73%|███████▎  | 22/30 [00:07<00:02,  3.08it/s]\n",
      "Epoch 18: - train loss: 0.26 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 18: - train loss: 0.23 val loss: 0.22 - train acc: 0.96 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 18: - train loss: 0.27 val loss: 0.18 - train acc: 0.95 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.11it/s]\n",
      "Epoch 18: - train loss: 0.27 val loss: 0.18 - train acc: 0.95 val acc: 0.97:  87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 18: - train loss: 0.25 val loss: 0.28 - train acc: 0.95 val acc: 0.93:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 18: - train loss: 0.22 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 18: - train loss: 0.22 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 18: - train loss: 0.30 val loss: 0.21 - train acc: 0.92 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s]\n",
      "Epoch 18: - train loss: 0.33 val loss: 0.17 - train acc: 0.93 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.14it/s]\n",
      "Epoch 18: - train loss: 0.33 val loss: 0.17 - train acc: 0.93 val acc: 0.97: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  63%|██████▎   | 19/30 [02:53<01:40,  9.12s/it]\n",
      "Epoch 19:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 19: - train loss: 0.22 val loss: 0.26 - train acc: 0.97 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.27 - train acc: 0.93 val acc: 0.92:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.27 - train acc: 0.93 val acc: 0.92:   7%|▋         | 2/30 [00:00<00:08,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.20 val loss: 0.24 - train acc: 0.98 val acc: 0.97:   7%|▋         | 2/30 [00:00<00:12,  2.28it/s]\n",
      "Epoch 19: - train loss: 0.26 val loss: 0.23 - train acc: 0.96 val acc: 0.96:   7%|▋         | 2/30 [00:01<00:16,  1.71it/s]\n",
      "Epoch 19: - train loss: 0.26 val loss: 0.23 - train acc: 0.96 val acc: 0.96:  13%|█▎        | 4/30 [00:01<00:07,  3.42it/s]\n",
      "Epoch 19: - train loss: 0.23 val loss: 0.20 - train acc: 0.96 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:09,  2.74it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.25 - train acc: 0.96 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.28it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.25 - train acc: 0.96 val acc: 0.95:  20%|██        | 6/30 [00:01<00:07,  3.42it/s]\n",
      "Epoch 19: - train loss: 0.20 val loss: 0.31 - train acc: 0.98 val acc: 0.93:  20%|██        | 6/30 [00:02<00:08,  2.94it/s]\n",
      "Epoch 19: - train loss: 0.24 val loss: 0.19 - train acc: 0.96 val acc: 0.98:  20%|██        | 6/30 [00:02<00:09,  2.57it/s]\n",
      "Epoch 19: - train loss: 0.24 val loss: 0.19 - train acc: 0.96 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:06,  3.42it/s]\n",
      "Epoch 19: - train loss: 0.27 val loss: 0.28 - train acc: 0.92 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:07,  3.05it/s]\n",
      "Epoch 19: - train loss: 0.26 val loss: 0.23 - train acc: 0.95 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:08,  2.72it/s]\n",
      "Epoch 19: - train loss: 0.26 val loss: 0.23 - train acc: 0.95 val acc: 0.97:  33%|███▎      | 10/30 [00:02<00:05,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.24 val loss: 0.28 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:06,  3.09it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.25 - train acc: 0.96 val acc: 0.93:  33%|███▎      | 10/30 [00:03<00:07,  2.84it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.25 - train acc: 0.96 val acc: 0.93:  40%|████      | 12/30 [00:03<00:05,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.27 val loss: 0.20 - train acc: 0.95 val acc: 0.97:  40%|████      | 12/30 [00:03<00:05,  3.14it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.23 - train acc: 0.97 val acc: 0.94:  40%|████      | 12/30 [00:04<00:06,  2.91it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.23 - train acc: 0.97 val acc: 0.94:  47%|████▋     | 14/30 [00:04<00:04,  3.39it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.21 - train acc: 0.96 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  3.17it/s]\n",
      "Epoch 19: - train loss: 0.20 val loss: 0.31 - train acc: 0.98 val acc: 0.91:  47%|████▋     | 14/30 [00:04<00:05,  2.97it/s]\n",
      "Epoch 19: - train loss: 0.20 val loss: 0.31 - train acc: 0.98 val acc: 0.91:  53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.30 val loss: 0.18 - train acc: 0.93 val acc: 0.99:  53%|█████▎    | 16/30 [00:05<00:04,  3.20it/s]\n",
      "Epoch 19: - train loss: 0.22 val loss: 0.22 - train acc: 0.96 val acc: 0.94:  53%|█████▎    | 16/30 [00:05<00:04,  3.02it/s]\n",
      "Epoch 19: - train loss: 0.22 val loss: 0.22 - train acc: 0.96 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.21 - train acc: 0.94 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.22it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.24 - train acc: 0.93 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.05it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.24 - train acc: 0.93 val acc: 0.95:  67%|██████▋   | 20/30 [00:05<00:02,  3.39it/s]\n",
      "Epoch 19: - train loss: 0.33 val loss: 0.30 - train acc: 0.91 val acc: 0.94:  67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.23 - train acc: 0.95 val acc: 0.94:  67%|██████▋   | 20/30 [00:06<00:03,  3.08it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.23 - train acc: 0.95 val acc: 0.94:  73%|███████▎  | 22/30 [00:06<00:02,  3.39it/s]\n",
      "Epoch 19: - train loss: 0.22 val loss: 0.24 - train acc: 0.97 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.20 - train acc: 0.96 val acc: 0.95:  73%|███████▎  | 22/30 [00:07<00:02,  3.11it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.20 - train acc: 0.96 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.29 - train acc: 0.95 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.26it/s]\n",
      "Epoch 19: - train loss: 0.27 val loss: 0.20 - train acc: 0.95 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.14it/s]\n",
      "Epoch 19: - train loss: 0.27 val loss: 0.20 - train acc: 0.95 val acc: 0.98:  87%|████████▋ | 26/30 [00:07<00:01,  3.40it/s]\n",
      "Epoch 19: - train loss: 0.22 val loss: 0.23 - train acc: 0.97 val acc: 0.96:  87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.22 - train acc: 0.93 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.15it/s]\n",
      "Epoch 19: - train loss: 0.29 val loss: 0.22 - train acc: 0.93 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.39it/s]\n",
      "Epoch 19: - train loss: 0.21 val loss: 0.25 - train acc: 0.95 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.25 - train acc: 0.96 val acc: 0.94:  93%|█████████▎| 28/30 [00:08<00:00,  3.16it/s]\n",
      "Epoch 19: - train loss: 0.25 val loss: 0.25 - train acc: 0.96 val acc: 0.94: 100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n",
      "Training progress:  67%|██████▋   | 20/30 [03:02<01:31,  9.11s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 20: - train loss: 0.25 val loss: 0.25 - train acc: 0.95 val acc: 0.94:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 20: - train loss: 0.21 val loss: 0.23 - train acc: 0.97 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 20: - train loss: 0.21 val loss: 0.23 - train acc: 0.97 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.32it/s]\n",
      "Epoch 20: - train loss: 0.22 val loss: 0.19 - train acc: 0.95 val acc: 0.98:   7%|▋         | 2/30 [00:00<00:12,  2.24it/s]\n",
      "Epoch 20: - train loss: 0.23 val loss: 0.25 - train acc: 0.98 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:16,  1.68it/s]\n",
      "Epoch 20: - train loss: 0.23 val loss: 0.25 - train acc: 0.98 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 20: - train loss: 0.19 val loss: 0.18 - train acc: 0.98 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:09,  2.69it/s]\n",
      "Epoch 20: - train loss: 0.26 val loss: 0.20 - train acc: 0.94 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:11,  2.25it/s]\n",
      "Epoch 20: - train loss: 0.26 val loss: 0.20 - train acc: 0.94 val acc: 0.97:  20%|██        | 6/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 20: - train loss: 0.35 val loss: 0.19 - train acc: 0.93 val acc: 0.97:  20%|██        | 6/30 [00:02<00:08,  2.86it/s]\n",
      "Epoch 20: - train loss: 0.23 val loss: 0.23 - train acc: 0.95 val acc: 0.95:  20%|██        | 6/30 [00:02<00:09,  2.52it/s]\n",
      "Epoch 20: - train loss: 0.23 val loss: 0.23 - train acc: 0.95 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:06,  3.35it/s]\n",
      "Epoch 20: - train loss: 0.32 val loss: 0.26 - train acc: 0.90 val acc: 0.93:  27%|██▋       | 8/30 [00:02<00:07,  2.99it/s]\n",
      "Epoch 20: - train loss: 0.24 val loss: 0.19 - train acc: 0.94 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:08,  2.70it/s]\n",
      "Epoch 20: - train loss: 0.24 val loss: 0.19 - train acc: 0.94 val acc: 0.96:  33%|███▎      | 10/30 [00:02<00:05,  3.37it/s]\n",
      "Epoch 20: - train loss: 0.22 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  33%|███▎      | 10/30 [00:03<00:06,  3.07it/s]\n",
      "Epoch 20: - train loss: 0.24 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:07,  2.82it/s]\n",
      "Epoch 20: - train loss: 0.24 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.38it/s]\n",
      "Epoch 20: - train loss: 0.27 val loss: 0.25 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.13it/s]\n",
      "Epoch 20: - train loss: 0.21 val loss: 0.16 - train acc: 0.97 val acc: 0.99:  40%|████      | 12/30 [00:04<00:06,  2.91it/s]\n",
      "Epoch 20: - train loss: 0.21 val loss: 0.16 - train acc: 0.97 val acc: 0.99:  47%|████▋     | 14/30 [00:04<00:04,  3.39it/s]\n",
      "Epoch 20: - train loss: 0.25 val loss: 0.20 - train acc: 0.96 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  3.15it/s]\n",
      "Epoch 20: - train loss: 0.28 val loss: 0.22 - train acc: 0.94 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  2.95it/s]\n",
      "Epoch 20: - train loss: 0.28 val loss: 0.22 - train acc: 0.94 val acc: 0.98:  53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 20: - train loss: 0.26 val loss: 0.24 - train acc: 0.92 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 20: - train loss: 0.15 val loss: 0.27 - train acc: 0.99 val acc: 0.94:  53%|█████▎    | 16/30 [00:05<00:04,  2.99it/s]\n",
      "Epoch 20: - train loss: 0.15 val loss: 0.27 - train acc: 0.99 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 20: - train loss: 0.23 val loss: 0.20 - train acc: 0.95 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 20: - train loss: 0.22 val loss: 0.16 - train acc: 0.96 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 20: - train loss: 0.22 val loss: 0.16 - train acc: 0.96 val acc: 0.98:  67%|██████▋   | 20/30 [00:05<00:02,  3.37it/s]\n",
      "Epoch 20: - train loss: 0.30 val loss: 0.23 - train acc: 0.94 val acc: 0.96:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 20: - train loss: 0.29 val loss: 0.21 - train acc: 0.91 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.07it/s]\n",
      "Epoch 20: - train loss: 0.29 val loss: 0.21 - train acc: 0.91 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s]\n",
      "Epoch 20: - train loss: 0.30 val loss: 0.16 - train acc: 0.94 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.23it/s]\n",
      "Epoch 20: - train loss: 0.26 val loss: 0.19 - train acc: 0.95 val acc: 0.97:  73%|███████▎  | 22/30 [00:07<00:02,  3.10it/s]\n",
      "Epoch 20: - train loss: 0.26 val loss: 0.19 - train acc: 0.95 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.38it/s]\n",
      "Epoch 20: - train loss: 0.27 val loss: 0.21 - train acc: 0.94 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.24it/s]\n",
      "Epoch 20: - train loss: 0.25 val loss: 0.20 - train acc: 0.96 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.12it/s]\n",
      "Epoch 20: - train loss: 0.25 val loss: 0.20 - train acc: 0.96 val acc: 0.98:  87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 20: - train loss: 0.24 val loss: 0.15 - train acc: 0.95 val acc: 0.98:  87%|████████▋ | 26/30 [00:07<00:01,  3.25it/s]\n",
      "Epoch 20: - train loss: 0.22 val loss: 0.19 - train acc: 0.97 val acc: 0.99:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 20: - train loss: 0.22 val loss: 0.19 - train acc: 0.97 val acc: 0.99:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 20: - train loss: 0.25 val loss: 0.26 - train acc: 0.93 val acc: 0.93:  93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s]\n",
      "Epoch 20: - train loss: 0.29 val loss: 0.27 - train acc: 0.94 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.15it/s]\n",
      "Epoch 20: - train loss: 0.29 val loss: 0.27 - train acc: 0.94 val acc: 0.95: 100%|██████████| 30/30 [00:08<00:00,  3.37it/s]\n",
      "Training progress:  70%|███████   | 21/30 [03:11<01:21,  9.10s/it]\n",
      "Epoch 21:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 21: - train loss: 0.34 val loss: 0.27 - train acc: 0.92 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.21 - train acc: 0.95 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.21 - train acc: 0.95 val acc: 0.97:   7%|▋         | 2/30 [00:00<00:08,  3.29it/s]\n",
      "Epoch 21: - train loss: 0.18 val loss: 0.26 - train acc: 0.98 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.23it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.23 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:16,  1.69it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.23 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:07,  3.37it/s]\n",
      "Epoch 21: - train loss: 0.26 val loss: 0.15 - train acc: 0.94 val acc: 1.00:  13%|█▎        | 4/30 [00:01<00:09,  2.70it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.19 - train acc: 0.95 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:11,  2.26it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.19 - train acc: 0.95 val acc: 0.98:  20%|██        | 6/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.30 - train acc: 0.94 val acc: 0.95:  20%|██        | 6/30 [00:02<00:08,  2.91it/s]\n",
      "Epoch 21: - train loss: 0.19 val loss: 0.20 - train acc: 0.97 val acc: 0.98:  20%|██        | 6/30 [00:02<00:09,  2.55it/s]\n",
      "Epoch 21: - train loss: 0.19 val loss: 0.20 - train acc: 0.97 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:06,  3.40it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.17 - train acc: 0.95 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:07,  3.02it/s]\n",
      "Epoch 21: - train loss: 0.27 val loss: 0.18 - train acc: 0.95 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:08,  2.72it/s]\n",
      "Epoch 21: - train loss: 0.27 val loss: 0.18 - train acc: 0.95 val acc: 0.96:  33%|███▎      | 10/30 [00:02<00:05,  3.40it/s]\n",
      "Epoch 21: - train loss: 0.27 val loss: 0.18 - train acc: 0.95 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:06,  3.10it/s]\n",
      "Epoch 21: - train loss: 0.29 val loss: 0.17 - train acc: 0.94 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:07,  2.84it/s]\n",
      "Epoch 21: - train loss: 0.29 val loss: 0.17 - train acc: 0.94 val acc: 0.98:  40%|████      | 12/30 [00:03<00:05,  3.41it/s]\n",
      "Epoch 21: - train loss: 0.23 val loss: 0.17 - train acc: 0.96 val acc: 0.97:  40%|████      | 12/30 [00:03<00:05,  3.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: - train loss: 0.21 val loss: 0.22 - train acc: 0.96 val acc: 0.96:  40%|████      | 12/30 [00:04<00:06,  2.91it/s]\n",
      "Epoch 21: - train loss: 0.21 val loss: 0.22 - train acc: 0.96 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:04,  3.39it/s]\n",
      "Epoch 21: - train loss: 0.28 val loss: 0.24 - train acc: 0.95 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:05,  3.17it/s]\n",
      "Epoch 21: - train loss: 0.24 val loss: 0.23 - train acc: 0.97 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:05,  2.98it/s]\n",
      "Epoch 21: - train loss: 0.24 val loss: 0.23 - train acc: 0.97 val acc: 0.96:  53%|█████▎    | 16/30 [00:04<00:04,  3.40it/s]\n",
      "Epoch 21: - train loss: 0.20 val loss: 0.20 - train acc: 0.95 val acc: 0.98:  53%|█████▎    | 16/30 [00:04<00:04,  3.20it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.19 - train acc: 0.93 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.03it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.19 - train acc: 0.93 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.41it/s]\n",
      "Epoch 21: - train loss: 0.20 val loss: 0.25 - train acc: 0.96 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.23it/s]\n",
      "Epoch 21: - train loss: 0.20 val loss: 0.13 - train acc: 0.96 val acc: 0.97:  60%|██████    | 18/30 [00:05<00:03,  3.06it/s]\n",
      "Epoch 21: - train loss: 0.20 val loss: 0.13 - train acc: 0.96 val acc: 0.97:  67%|██████▋   | 20/30 [00:05<00:02,  3.39it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.29 - train acc: 0.94 val acc: 0.91:  67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.22 - train acc: 0.93 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.09it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.22 - train acc: 0.93 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.40it/s]\n",
      "Epoch 21: - train loss: 0.25 val loss: 0.23 - train acc: 0.92 val acc: 0.95:  73%|███████▎  | 22/30 [00:06<00:02,  3.25it/s]\n",
      "Epoch 21: - train loss: 0.34 val loss: 0.25 - train acc: 0.91 val acc: 0.94:  73%|███████▎  | 22/30 [00:07<00:02,  3.11it/s]\n",
      "Epoch 21: - train loss: 0.34 val loss: 0.25 - train acc: 0.91 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.40it/s]\n",
      "Epoch 21: - train loss: 0.22 val loss: 0.26 - train acc: 0.96 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.25it/s]\n",
      "Epoch 21: - train loss: 0.23 val loss: 0.17 - train acc: 0.95 val acc: 0.99:  80%|████████  | 24/30 [00:07<00:01,  3.12it/s]\n",
      "Epoch 21: - train loss: 0.23 val loss: 0.17 - train acc: 0.95 val acc: 0.99:  87%|████████▋ | 26/30 [00:07<00:01,  3.38it/s]\n",
      "Epoch 21: - train loss: 0.22 val loss: 0.27 - train acc: 0.94 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.26it/s]\n",
      "Epoch 21: - train loss: 0.22 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 21: - train loss: 0.22 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 21: - train loss: 0.20 val loss: 0.24 - train acc: 0.98 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.26it/s]\n",
      "Epoch 21: - train loss: 0.23 val loss: 0.25 - train acc: 0.97 val acc: 0.92:  93%|█████████▎| 28/30 [00:08<00:00,  3.15it/s]\n",
      "Epoch 21: - train loss: 0.23 val loss: 0.25 - train acc: 0.97 val acc: 0.92: 100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n",
      "Training progress:  73%|███████▎  | 22/30 [03:19<01:12,  9.09s/it]\n",
      "Epoch 22:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 22: - train loss: 0.17 val loss: 0.13 - train acc: 0.98 val acc: 0.98:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 22: - train loss: 0.18 val loss: 0.23 - train acc: 0.98 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 22: - train loss: 0.18 val loss: 0.23 - train acc: 0.98 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.42it/s]\n",
      "Epoch 22: - train loss: 0.19 val loss: 0.26 - train acc: 0.96 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.23it/s]\n",
      "Epoch 22: - train loss: 0.21 val loss: 0.18 - train acc: 0.95 val acc: 0.98:   7%|▋         | 2/30 [00:01<00:16,  1.68it/s]\n",
      "Epoch 22: - train loss: 0.21 val loss: 0.18 - train acc: 0.95 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.20 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.70it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.19 - train acc: 0.95 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:11,  2.26it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.19 - train acc: 0.95 val acc: 0.97:  20%|██        | 6/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 22: - train loss: 0.25 val loss: 0.24 - train acc: 0.93 val acc: 0.95:  20%|██        | 6/30 [00:02<00:08,  2.88it/s]\n",
      "Epoch 22: - train loss: 0.24 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  20%|██        | 6/30 [00:02<00:09,  2.53it/s]\n",
      "Epoch 22: - train loss: 0.24 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:06,  3.37it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.19 - train acc: 0.95 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:07,  3.00it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.21 - train acc: 0.94 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:08,  2.69it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.21 - train acc: 0.94 val acc: 0.96:  33%|███▎      | 10/30 [00:02<00:05,  3.36it/s]\n",
      "Epoch 22: - train loss: 0.20 val loss: 0.23 - train acc: 0.95 val acc: 0.93:  33%|███▎      | 10/30 [00:03<00:06,  3.06it/s]\n",
      "Epoch 22: - train loss: 0.20 val loss: 0.21 - train acc: 0.95 val acc: 0.96:  33%|███▎      | 10/30 [00:03<00:07,  2.81it/s]\n",
      "Epoch 22: - train loss: 0.20 val loss: 0.21 - train acc: 0.95 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.36it/s]\n",
      "Epoch 22: - train loss: 0.14 val loss: 0.25 - train acc: 0.98 val acc: 0.93:  40%|████      | 12/30 [00:03<00:05,  3.11it/s]\n",
      "Epoch 22: - train loss: 0.29 val loss: 0.22 - train acc: 0.93 val acc: 0.93:  40%|████      | 12/30 [00:04<00:06,  2.89it/s]\n",
      "Epoch 22: - train loss: 0.29 val loss: 0.22 - train acc: 0.93 val acc: 0.93:  47%|████▋     | 14/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 22: - train loss: 0.28 val loss: 0.19 - train acc: 0.95 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:05,  3.15it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.12 - train acc: 0.95 val acc: 1.00:  47%|████▋     | 14/30 [00:04<00:05,  2.96it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.12 - train acc: 0.95 val acc: 1.00:  53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 22: - train loss: 0.16 val loss: 0.21 - train acc: 0.97 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 22: - train loss: 0.22 val loss: 0.24 - train acc: 0.94 val acc: 0.91:  53%|█████▎    | 16/30 [00:05<00:04,  3.01it/s]\n",
      "Epoch 22: - train loss: 0.22 val loss: 0.24 - train acc: 0.94 val acc: 0.91:  60%|██████    | 18/30 [00:05<00:03,  3.38it/s]\n",
      "Epoch 22: - train loss: 0.21 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.21it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.17 - train acc: 0.95 val acc: 0.97:  60%|██████    | 18/30 [00:05<00:03,  3.05it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.17 - train acc: 0.95 val acc: 0.97:  67%|██████▋   | 20/30 [00:05<00:02,  3.39it/s]\n",
      "Epoch 22: - train loss: 0.31 val loss: 0.18 - train acc: 0.90 val acc: 0.97:  67%|██████▋   | 20/30 [00:06<00:03,  3.23it/s]\n",
      "Epoch 22: - train loss: 0.22 val loss: 0.16 - train acc: 0.97 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.07it/s]\n",
      "Epoch 22: - train loss: 0.22 val loss: 0.16 - train acc: 0.97 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s]\n",
      "Epoch 22: - train loss: 0.20 val loss: 0.20 - train acc: 0.98 val acc: 0.94:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 22: - train loss: 0.16 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  73%|███████▎  | 22/30 [00:07<00:02,  3.09it/s]\n",
      "Epoch 22: - train loss: 0.16 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 22: - train loss: 0.14 val loss: 0.18 - train acc: 0.98 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.24it/s]\n",
      "Epoch 22: - train loss: 0.20 val loss: 0.22 - train acc: 0.96 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: - train loss: 0.20 val loss: 0.22 - train acc: 0.96 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.37it/s]\n",
      "Epoch 22: - train loss: 0.24 val loss: 0.25 - train acc: 0.96 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 22: - train loss: 0.21 val loss: 0.19 - train acc: 0.96 val acc: 0.98:  87%|████████▋ | 26/30 [00:08<00:01,  3.12it/s]\n",
      "Epoch 22: - train loss: 0.21 val loss: 0.19 - train acc: 0.96 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s]\n",
      "Epoch 22: - train loss: 0.20 val loss: 0.20 - train acc: 0.95 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.20 - train acc: 0.93 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.14it/s]\n",
      "Epoch 22: - train loss: 0.23 val loss: 0.20 - train acc: 0.93 val acc: 0.95: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  77%|███████▋  | 23/30 [03:28<01:03,  9.08s/it]\n",
      "Epoch 23:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.19 - train acc: 0.97 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.25 - train acc: 0.97 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.25 - train acc: 0.97 val acc: 0.97:   7%|▋         | 2/30 [00:00<00:08,  3.46it/s]\n",
      "Epoch 23: - train loss: 0.25 val loss: 0.22 - train acc: 0.95 val acc: 0.93:   7%|▋         | 2/30 [00:00<00:12,  2.31it/s]\n",
      "Epoch 23: - train loss: 0.17 val loss: 0.17 - train acc: 0.97 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:16,  1.70it/s]\n",
      "Epoch 23: - train loss: 0.17 val loss: 0.17 - train acc: 0.97 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.24 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.71it/s]\n",
      "Epoch 23: - train loss: 0.15 val loss: 0.20 - train acc: 0.99 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:11,  2.27it/s]\n",
      "Epoch 23: - train loss: 0.15 val loss: 0.20 - train acc: 0.99 val acc: 0.98:  20%|██        | 6/30 [00:01<00:07,  3.40it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.15 - train acc: 0.97 val acc: 0.98:  20%|██        | 6/30 [00:02<00:08,  2.92it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.16 - train acc: 0.96 val acc: 0.98:  20%|██        | 6/30 [00:02<00:09,  2.56it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.16 - train acc: 0.96 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:06,  3.41it/s]\n",
      "Epoch 23: - train loss: 0.21 val loss: 0.27 - train acc: 0.96 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:07,  3.03it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.21 - train acc: 0.95 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:08,  2.73it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.21 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:02<00:05,  3.41it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.27 - train acc: 0.95 val acc: 0.92:  33%|███▎      | 10/30 [00:03<00:06,  3.08it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.22 - train acc: 0.95 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:07,  2.81it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.22 - train acc: 0.95 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.37it/s]\n",
      "Epoch 23: - train loss: 0.19 val loss: 0.19 - train acc: 0.97 val acc: 0.97:  40%|████      | 12/30 [00:03<00:05,  3.12it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.18 - train acc: 0.95 val acc: 0.96:  40%|████      | 12/30 [00:04<00:06,  2.90it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.18 - train acc: 0.95 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.19 - train acc: 0.96 val acc: 0.97:  47%|████▋     | 14/30 [00:04<00:05,  3.14it/s]\n",
      "Epoch 23: - train loss: 0.25 val loss: 0.19 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.95it/s]\n",
      "Epoch 23: - train loss: 0.25 val loss: 0.19 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 23: - train loss: 0.15 val loss: 0.18 - train acc: 0.98 val acc: 0.97:  53%|█████▎    | 16/30 [00:05<00:04,  3.17it/s]\n",
      "Epoch 23: - train loss: 0.16 val loss: 0.17 - train acc: 0.97 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  2.99it/s]\n",
      "Epoch 23: - train loss: 0.16 val loss: 0.17 - train acc: 0.97 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.36it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.13 - train acc: 0.97 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.18it/s]\n",
      "Epoch 23: - train loss: 0.19 val loss: 0.20 - train acc: 0.95 val acc: 0.97:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 23: - train loss: 0.19 val loss: 0.20 - train acc: 0.95 val acc: 0.97:  67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s]\n",
      "Epoch 23: - train loss: 0.20 val loss: 0.16 - train acc: 0.96 val acc: 0.96:  67%|██████▋   | 20/30 [00:06<00:03,  3.20it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.16 - train acc: 0.95 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.06it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.16 - train acc: 0.95 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.37it/s]\n",
      "Epoch 23: - train loss: 0.23 val loss: 0.13 - train acc: 0.96 val acc: 0.99:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 23: - train loss: 0.24 val loss: 0.22 - train acc: 0.94 val acc: 0.93:  73%|███████▎  | 22/30 [00:07<00:02,  3.08it/s]\n",
      "Epoch 23: - train loss: 0.24 val loss: 0.22 - train acc: 0.94 val acc: 0.93:  80%|████████  | 24/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 23: - train loss: 0.23 val loss: 0.17 - train acc: 0.93 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.19 - train acc: 0.95 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 23: - train loss: 0.18 val loss: 0.19 - train acc: 0.95 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 23: - train loss: 0.22 val loss: 0.20 - train acc: 0.95 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.23it/s]\n",
      "Epoch 23: - train loss: 0.25 val loss: 0.21 - train acc: 0.93 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.12it/s]\n",
      "Epoch 23: - train loss: 0.25 val loss: 0.21 - train acc: 0.93 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.36it/s]\n",
      "Epoch 23: - train loss: 0.24 val loss: 0.20 - train acc: 0.95 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s]\n",
      "Epoch 23: - train loss: 0.19 val loss: 0.24 - train acc: 0.96 val acc: 0.94:  93%|█████████▎| 28/30 [00:08<00:00,  3.14it/s]\n",
      "Epoch 23: - train loss: 0.19 val loss: 0.24 - train acc: 0.96 val acc: 0.94: 100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "Training progress:  80%|████████  | 24/30 [03:37<00:54,  9.08s/it]\n",
      "Epoch 24:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.17 - train acc: 0.94 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.16 - train acc: 0.95 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.16 - train acc: 0.95 val acc: 0.97:   7%|▋         | 2/30 [00:00<00:08,  3.28it/s]\n",
      "Epoch 24: - train loss: 0.23 val loss: 0.20 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.22it/s]\n",
      "Epoch 24: - train loss: 0.19 val loss: 0.15 - train acc: 0.96 val acc: 0.98:   7%|▋         | 2/30 [00:01<00:16,  1.67it/s]\n",
      "Epoch 24: - train loss: 0.19 val loss: 0.15 - train acc: 0.96 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:07,  3.34it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.21 - train acc: 0.97 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:09,  2.64it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.16 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.21it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.16 - train acc: 0.95 val acc: 0.95:  20%|██        | 6/30 [00:01<00:07,  3.32it/s]\n",
      "Epoch 24: - train loss: 0.19 val loss: 0.17 - train acc: 0.96 val acc: 0.98:  20%|██        | 6/30 [00:02<00:08,  2.85it/s]\n",
      "Epoch 24: - train loss: 0.25 val loss: 0.18 - train acc: 0.94 val acc: 0.95:  20%|██        | 6/30 [00:02<00:09,  2.50it/s]\n",
      "Epoch 24: - train loss: 0.25 val loss: 0.18 - train acc: 0.94 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:06,  3.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: - train loss: 0.19 val loss: 0.21 - train acc: 0.95 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:07,  2.97it/s]\n",
      "Epoch 24: - train loss: 0.28 val loss: 0.20 - train acc: 0.94 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:08,  2.68it/s]\n",
      "Epoch 24: - train loss: 0.28 val loss: 0.20 - train acc: 0.94 val acc: 0.95:  33%|███▎      | 10/30 [00:02<00:05,  3.35it/s]\n",
      "Epoch 24: - train loss: 0.17 val loss: 0.15 - train acc: 0.97 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:06,  3.06it/s]\n",
      "Epoch 24: - train loss: 0.13 val loss: 0.18 - train acc: 0.99 val acc: 0.97:  33%|███▎      | 10/30 [00:03<00:07,  2.81it/s]\n",
      "Epoch 24: - train loss: 0.13 val loss: 0.18 - train acc: 0.99 val acc: 0.97:  40%|████      | 12/30 [00:03<00:05,  3.37it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.19 - train acc: 0.96 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.12it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.16 - train acc: 0.95 val acc: 0.98:  40%|████      | 12/30 [00:04<00:06,  2.88it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.16 - train acc: 0.95 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:04,  3.36it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.27 - train acc: 0.96 val acc: 0.94:  47%|████▋     | 14/30 [00:04<00:05,  3.12it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.18 - train acc: 0.96 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.93it/s]\n",
      "Epoch 24: - train loss: 0.22 val loss: 0.18 - train acc: 0.96 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.35it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.21 - train acc: 0.95 val acc: 0.96:  53%|█████▎    | 16/30 [00:05<00:04,  3.16it/s]\n",
      "Epoch 24: - train loss: 0.16 val loss: 0.16 - train acc: 0.98 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  2.97it/s]\n",
      "Epoch 24: - train loss: 0.16 val loss: 0.16 - train acc: 0.98 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.34it/s]\n",
      "Epoch 24: - train loss: 0.16 val loss: 0.15 - train acc: 0.97 val acc: 0.96:  60%|██████    | 18/30 [00:05<00:03,  3.17it/s]\n",
      "Epoch 24: - train loss: 0.26 val loss: 0.17 - train acc: 0.91 val acc: 0.96:  60%|██████    | 18/30 [00:05<00:03,  3.01it/s]\n",
      "Epoch 24: - train loss: 0.26 val loss: 0.17 - train acc: 0.91 val acc: 0.96:  67%|██████▋   | 20/30 [00:05<00:02,  3.34it/s]\n",
      "Epoch 24: - train loss: 0.16 val loss: 0.12 - train acc: 0.97 val acc: 0.99:  67%|██████▋   | 20/30 [00:06<00:03,  3.19it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.15 - train acc: 0.94 val acc: 0.97:  67%|██████▋   | 20/30 [00:06<00:03,  3.05it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.15 - train acc: 0.94 val acc: 0.97:  73%|███████▎  | 22/30 [00:06<00:02,  3.35it/s]\n",
      "Epoch 24: - train loss: 0.14 val loss: 0.21 - train acc: 0.98 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.21it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.25 - train acc: 0.95 val acc: 0.92:  73%|███████▎  | 22/30 [00:07<00:02,  3.08it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.25 - train acc: 0.95 val acc: 0.92:  80%|████████  | 24/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 24: - train loss: 0.23 val loss: 0.24 - train acc: 0.95 val acc: 0.92:  80%|████████  | 24/30 [00:07<00:01,  3.23it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.24 - train acc: 0.97 val acc: 0.93:  80%|████████  | 24/30 [00:07<00:01,  3.10it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.24 - train acc: 0.97 val acc: 0.93:  87%|████████▋ | 26/30 [00:07<00:01,  3.36it/s]\n",
      "Epoch 24: - train loss: 0.19 val loss: 0.21 - train acc: 0.95 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.24it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.16 - train acc: 0.95 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\n",
      "Epoch 24: - train loss: 0.20 val loss: 0.16 - train acc: 0.95 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.37it/s]\n",
      "Epoch 24: - train loss: 0.23 val loss: 0.15 - train acc: 0.95 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.25it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.14 - train acc: 0.95 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.15it/s]\n",
      "Epoch 24: - train loss: 0.18 val loss: 0.14 - train acc: 0.95 val acc: 0.97: 100%|██████████| 30/30 [00:08<00:00,  3.37it/s]\n",
      "Training progress:  83%|████████▎ | 25/30 [03:46<00:45,  9.07s/it]\n",
      "Epoch 25:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 25: - train loss: 0.19 val loss: 0.24 - train acc: 0.95 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 25: - train loss: 0.22 val loss: 0.18 - train acc: 0.95 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 25: - train loss: 0.22 val loss: 0.18 - train acc: 0.95 val acc: 0.96:   7%|▋         | 2/30 [00:00<00:08,  3.44it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.21 - train acc: 0.92 val acc: 0.96:   7%|▋         | 2/30 [00:00<00:12,  2.29it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.12 - train acc: 0.98 val acc: 0.98:   7%|▋         | 2/30 [00:01<00:16,  1.72it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.12 - train acc: 0.98 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:07,  3.43it/s]\n",
      "Epoch 25: - train loss: 0.20 val loss: 0.18 - train acc: 0.95 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:09,  2.75it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.20 - train acc: 0.96 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:11,  2.29it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.20 - train acc: 0.96 val acc: 0.95:  20%|██        | 6/30 [00:01<00:06,  3.43it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.15 - train acc: 0.94 val acc: 0.96:  20%|██        | 6/30 [00:02<00:08,  2.94it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.18 - train acc: 0.97 val acc: 0.95:  20%|██        | 6/30 [00:02<00:09,  2.57it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.18 - train acc: 0.97 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:06,  3.42it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.16 - train acc: 0.96 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:07,  3.02it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.13 - train acc: 0.95 val acc: 0.99:  27%|██▋       | 8/30 [00:02<00:08,  2.72it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.13 - train acc: 0.95 val acc: 0.99:  33%|███▎      | 10/30 [00:02<00:05,  3.39it/s]\n",
      "Epoch 25: - train loss: 0.16 val loss: 0.24 - train acc: 0.98 val acc: 0.94:  33%|███▎      | 10/30 [00:03<00:06,  3.09it/s]\n",
      "Epoch 25: - train loss: 0.20 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:07,  2.82it/s]\n",
      "Epoch 25: - train loss: 0.20 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.38it/s]\n",
      "Epoch 25: - train loss: 0.17 val loss: 0.14 - train acc: 0.97 val acc: 0.98:  40%|████      | 12/30 [00:03<00:05,  3.10it/s]\n",
      "Epoch 25: - train loss: 0.15 val loss: 0.17 - train acc: 0.98 val acc: 0.96:  40%|████      | 12/30 [00:04<00:06,  2.89it/s]\n",
      "Epoch 25: - train loss: 0.15 val loss: 0.17 - train acc: 0.98 val acc: 0.96:  47%|████▋     | 14/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 25: - train loss: 0.14 val loss: 0.12 - train acc: 0.98 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  3.15it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.22 - train acc: 0.95 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  2.95it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.22 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.20 - train acc: 0.95 val acc: 0.97:  53%|█████▎    | 16/30 [00:05<00:04,  3.18it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.17 - train acc: 0.95 val acc: 0.99:  53%|█████▎    | 16/30 [00:05<00:04,  3.01it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.17 - train acc: 0.95 val acc: 0.99:  60%|██████    | 18/30 [00:05<00:03,  3.38it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.14 - train acc: 0.95 val acc: 0.99:  60%|██████    | 18/30 [00:05<00:03,  3.19it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.18 - train acc: 0.94 val acc: 0.95:  60%|██████    | 18/30 [00:05<00:03,  3.02it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.18 - train acc: 0.94 val acc: 0.95:  67%|██████▋   | 20/30 [00:05<00:02,  3.35it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.19 - train acc: 0.95 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: - train loss: 0.16 val loss: 0.21 - train acc: 0.98 val acc: 0.94:  67%|██████▋   | 20/30 [00:06<00:03,  3.06it/s]\n",
      "Epoch 25: - train loss: 0.16 val loss: 0.21 - train acc: 0.98 val acc: 0.94:  73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.24 - train acc: 0.93 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.22it/s]\n",
      "Epoch 25: - train loss: 0.15 val loss: 0.15 - train acc: 0.98 val acc: 0.97:  73%|███████▎  | 22/30 [00:07<00:02,  3.07it/s]\n",
      "Epoch 25: - train loss: 0.15 val loss: 0.15 - train acc: 0.98 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 25: - train loss: 0.20 val loss: 0.19 - train acc: 0.95 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.21it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.09it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.23 - train acc: 0.97 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 25: - train loss: 0.18 val loss: 0.14 - train acc: 0.96 val acc: 0.98:  87%|████████▋ | 26/30 [00:08<00:01,  3.22it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.18 - train acc: 0.95 val acc: 0.98:  87%|████████▋ | 26/30 [00:08<00:01,  3.11it/s]\n",
      "Epoch 25: - train loss: 0.23 val loss: 0.18 - train acc: 0.95 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.34it/s]\n",
      "Epoch 25: - train loss: 0.22 val loss: 0.22 - train acc: 0.94 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.23it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.17 - train acc: 0.94 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\n",
      "Epoch 25: - train loss: 0.21 val loss: 0.17 - train acc: 0.94 val acc: 0.98: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:  87%|████████▋ | 26/30 [03:55<00:36,  9.07s/it]\n",
      "Epoch 26:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.17 - train acc: 0.98 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 26: - train loss: 0.11 val loss: 0.22 - train acc: 0.99 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 26: - train loss: 0.11 val loss: 0.22 - train acc: 0.99 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.26it/s]\n",
      "Epoch 26: - train loss: 0.22 val loss: 0.18 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.22it/s]\n",
      "Epoch 26: - train loss: 0.23 val loss: 0.23 - train acc: 0.95 val acc: 0.97:   7%|▋         | 2/30 [00:01<00:16,  1.68it/s]\n",
      "Epoch 26: - train loss: 0.23 val loss: 0.23 - train acc: 0.95 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 26: - train loss: 0.21 val loss: 0.13 - train acc: 0.95 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:09,  2.70it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.15 - train acc: 0.96 val acc: 0.97:  13%|█▎        | 4/30 [00:01<00:11,  2.26it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.15 - train acc: 0.96 val acc: 0.97:  20%|██        | 6/30 [00:01<00:07,  3.39it/s]\n",
      "Epoch 26: - train loss: 0.24 val loss: 0.18 - train acc: 0.93 val acc: 0.97:  20%|██        | 6/30 [00:02<00:08,  2.91it/s]\n",
      "Epoch 26: - train loss: 0.17 val loss: 0.18 - train acc: 0.95 val acc: 0.98:  20%|██        | 6/30 [00:02<00:09,  2.55it/s]\n",
      "Epoch 26: - train loss: 0.17 val loss: 0.18 - train acc: 0.95 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:06,  3.40it/s]\n",
      "Epoch 26: - train loss: 0.24 val loss: 0.15 - train acc: 0.95 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:07,  3.03it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.12 - train acc: 0.98 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:08,  2.71it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.12 - train acc: 0.98 val acc: 0.98:  33%|███▎      | 10/30 [00:02<00:05,  3.38it/s]\n",
      "Epoch 26: - train loss: 0.18 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:06,  3.08it/s]\n",
      "Epoch 26: - train loss: 0.20 val loss: 0.32 - train acc: 0.95 val acc: 0.91:  33%|███▎      | 10/30 [00:03<00:07,  2.83it/s]\n",
      "Epoch 26: - train loss: 0.20 val loss: 0.32 - train acc: 0.95 val acc: 0.91:  40%|████      | 12/30 [00:03<00:05,  3.39it/s]\n",
      "Epoch 26: - train loss: 0.21 val loss: 0.21 - train acc: 0.97 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.14it/s]\n",
      "Epoch 26: - train loss: 0.27 val loss: 0.11 - train acc: 0.93 val acc: 0.98:  40%|████      | 12/30 [00:04<00:06,  2.92it/s]\n",
      "Epoch 26: - train loss: 0.27 val loss: 0.11 - train acc: 0.93 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:04,  3.40it/s]\n",
      "Epoch 26: - train loss: 0.19 val loss: 0.16 - train acc: 0.96 val acc: 0.97:  47%|████▋     | 14/30 [00:04<00:05,  3.17it/s]\n",
      "Epoch 26: - train loss: 0.24 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  47%|████▋     | 14/30 [00:04<00:05,  2.96it/s]\n",
      "Epoch 26: - train loss: 0.24 val loss: 0.21 - train acc: 0.95 val acc: 0.97:  53%|█████▎    | 16/30 [00:04<00:04,  3.38it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.12 - train acc: 0.97 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  3.19it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.24 - train acc: 0.98 val acc: 0.92:  53%|█████▎    | 16/30 [00:05<00:04,  3.00it/s]\n",
      "Epoch 26: - train loss: 0.16 val loss: 0.24 - train acc: 0.98 val acc: 0.92:  60%|██████    | 18/30 [00:05<00:03,  3.37it/s]\n",
      "Epoch 26: - train loss: 0.25 val loss: 0.20 - train acc: 0.94 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.20it/s]\n",
      "Epoch 26: - train loss: 0.23 val loss: 0.16 - train acc: 0.93 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.04it/s]\n",
      "Epoch 26: - train loss: 0.23 val loss: 0.16 - train acc: 0.93 val acc: 0.98:  67%|██████▋   | 20/30 [00:05<00:02,  3.38it/s]\n",
      "Epoch 26: - train loss: 0.18 val loss: 0.19 - train acc: 0.98 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.22it/s]\n",
      "Epoch 26: - train loss: 0.18 val loss: 0.16 - train acc: 0.97 val acc: 0.97:  67%|██████▋   | 20/30 [00:06<00:03,  3.08it/s]\n",
      "Epoch 26: - train loss: 0.18 val loss: 0.16 - train acc: 0.97 val acc: 0.97:  73%|███████▎  | 22/30 [00:06<00:02,  3.38it/s]\n",
      "Epoch 26: - train loss: 0.25 val loss: 0.15 - train acc: 0.95 val acc: 0.96:  73%|███████▎  | 22/30 [00:06<00:02,  3.24it/s]\n",
      "Epoch 26: - train loss: 0.19 val loss: 0.12 - train acc: 0.93 val acc: 0.99:  73%|███████▎  | 22/30 [00:07<00:02,  3.11it/s]\n",
      "Epoch 26: - train loss: 0.19 val loss: 0.12 - train acc: 0.93 val acc: 0.99:  80%|████████  | 24/30 [00:07<00:01,  3.39it/s]\n",
      "Epoch 26: - train loss: 0.20 val loss: 0.15 - train acc: 0.97 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.26it/s]\n",
      "Epoch 26: - train loss: 0.18 val loss: 0.18 - train acc: 0.95 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.13it/s]\n",
      "Epoch 26: - train loss: 0.18 val loss: 0.18 - train acc: 0.95 val acc: 0.96:  87%|████████▋ | 26/30 [00:07<00:01,  3.39it/s]\n",
      "Epoch 26: - train loss: 0.21 val loss: 0.13 - train acc: 0.95 val acc: 0.98:  87%|████████▋ | 26/30 [00:07<00:01,  3.27it/s]\n",
      "Epoch 26: - train loss: 0.15 val loss: 0.15 - train acc: 0.96 val acc: 0.98:  87%|████████▋ | 26/30 [00:08<00:01,  3.14it/s]\n",
      "Epoch 26: - train loss: 0.15 val loss: 0.15 - train acc: 0.96 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.38it/s]\n",
      "Epoch 26: - train loss: 0.13 val loss: 0.18 - train acc: 0.98 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.27it/s]\n",
      "Epoch 26: - train loss: 0.20 val loss: 0.14 - train acc: 0.95 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.16it/s]\n",
      "Epoch 26: - train loss: 0.20 val loss: 0.14 - train acc: 0.95 val acc: 0.96: 100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n",
      "Training progress:  90%|█████████ | 27/30 [04:04<00:27,  9.06s/it]\n",
      "Epoch 27:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 27: - train loss: 0.14 val loss: 0.13 - train acc: 0.98 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.24 - train acc: 0.95 val acc: 0.95:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.24 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:08,  3.46it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.21 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:00<00:12,  2.31it/s]\n",
      "Epoch 27: - train loss: 0.20 val loss: 0.22 - train acc: 0.95 val acc: 0.95:   7%|▋         | 2/30 [00:01<00:16,  1.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: - train loss: 0.20 val loss: 0.22 - train acc: 0.95 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:07,  3.38it/s]\n",
      "Epoch 27: - train loss: 0.22 val loss: 0.21 - train acc: 0.95 val acc: 0.96:  13%|█▎        | 4/30 [00:01<00:09,  2.72it/s]\n",
      "Epoch 27: - train loss: 0.12 val loss: 0.18 - train acc: 0.98 val acc: 0.96:  13%|█▎        | 4/30 [00:01<00:11,  2.24it/s]\n",
      "Epoch 27: - train loss: 0.12 val loss: 0.18 - train acc: 0.98 val acc: 0.96:  20%|██        | 6/30 [00:01<00:07,  3.35it/s]\n",
      "Epoch 27: - train loss: 0.18 val loss: 0.22 - train acc: 0.97 val acc: 0.95:  20%|██        | 6/30 [00:02<00:08,  2.89it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.23 - train acc: 0.98 val acc: 0.95:  20%|██        | 6/30 [00:02<00:09,  2.53it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.23 - train acc: 0.98 val acc: 0.95:  27%|██▋       | 8/30 [00:02<00:06,  3.38it/s]\n",
      "Epoch 27: - train loss: 0.14 val loss: 0.24 - train acc: 0.97 val acc: 0.94:  27%|██▋       | 8/30 [00:02<00:07,  3.01it/s]\n",
      "Epoch 27: - train loss: 0.11 val loss: 0.18 - train acc: 0.99 val acc: 0.96:  27%|██▋       | 8/30 [00:02<00:08,  2.69it/s]\n",
      "Epoch 27: - train loss: 0.11 val loss: 0.18 - train acc: 0.99 val acc: 0.96:  33%|███▎      | 10/30 [00:02<00:05,  3.36it/s]\n",
      "Epoch 27: - train loss: 0.20 val loss: 0.20 - train acc: 0.96 val acc: 0.96:  33%|███▎      | 10/30 [00:03<00:06,  3.06it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.24 - train acc: 0.95 val acc: 0.93:  33%|███▎      | 10/30 [00:03<00:07,  2.81it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.24 - train acc: 0.95 val acc: 0.93:  40%|████      | 12/30 [00:03<00:05,  3.37it/s]\n",
      "Epoch 27: - train loss: 0.21 val loss: 0.22 - train acc: 0.94 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.11it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.14 - train acc: 0.98 val acc: 0.98:  40%|████      | 12/30 [00:04<00:06,  2.89it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.14 - train acc: 0.98 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:04,  3.37it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.21 - train acc: 0.96 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:05,  3.13it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.12 - train acc: 0.98 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  2.94it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.12 - train acc: 0.98 val acc: 0.98:  53%|█████▎    | 16/30 [00:04<00:04,  3.36it/s]\n",
      "Epoch 27: - train loss: 0.18 val loss: 0.23 - train acc: 0.96 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.17it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.15 - train acc: 0.96 val acc: 0.97:  53%|█████▎    | 16/30 [00:05<00:04,  3.00it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.15 - train acc: 0.96 val acc: 0.97:  60%|██████    | 18/30 [00:05<00:03,  3.37it/s]\n",
      "Epoch 27: - train loss: 0.14 val loss: 0.11 - train acc: 0.98 val acc: 1.00:  60%|██████    | 18/30 [00:05<00:03,  3.20it/s]\n",
      "Epoch 27: - train loss: 0.21 val loss: 0.19 - train acc: 0.95 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.03it/s]\n",
      "Epoch 27: - train loss: 0.21 val loss: 0.19 - train acc: 0.95 val acc: 0.94:  67%|██████▋   | 20/30 [00:05<00:02,  3.36it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.13 - train acc: 0.97 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.21it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.21 - train acc: 0.96 val acc: 0.94:  67%|██████▋   | 20/30 [00:06<00:03,  3.05it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.21 - train acc: 0.96 val acc: 0.94:  73%|███████▎  | 22/30 [00:06<00:02,  3.36it/s]\n",
      "Epoch 27: - train loss: 0.18 val loss: 0.15 - train acc: 0.97 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.20it/s]\n",
      "Epoch 27: - train loss: 0.17 val loss: 0.13 - train acc: 0.95 val acc: 0.98:  73%|███████▎  | 22/30 [00:07<00:02,  3.07it/s]\n",
      "Epoch 27: - train loss: 0.17 val loss: 0.13 - train acc: 0.95 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 27: - train loss: 0.17 val loss: 0.17 - train acc: 0.95 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.22it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.18 - train acc: 0.98 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.09it/s]\n",
      "Epoch 27: - train loss: 0.15 val loss: 0.18 - train acc: 0.98 val acc: 0.97:  87%|████████▋ | 26/30 [00:07<00:01,  3.35it/s]\n",
      "Epoch 27: - train loss: 0.13 val loss: 0.18 - train acc: 0.98 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.22it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.13 - train acc: 0.98 val acc: 0.97:  87%|████████▋ | 26/30 [00:08<00:01,  3.11it/s]\n",
      "Epoch 27: - train loss: 0.16 val loss: 0.13 - train acc: 0.98 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.35it/s]\n",
      "Epoch 27: - train loss: 0.21 val loss: 0.15 - train acc: 0.95 val acc: 0.97:  93%|█████████▎| 28/30 [00:08<00:00,  3.24it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.20 - train acc: 0.95 val acc: 0.95:  93%|█████████▎| 28/30 [00:08<00:00,  3.12it/s]\n",
      "Epoch 27: - train loss: 0.19 val loss: 0.20 - train acc: 0.95 val acc: 0.95: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "Training progress:  93%|█████████▎| 28/30 [04:13<00:18,  9.06s/it]\n",
      "Epoch 28:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 28: - train loss: 0.23 val loss: 0.21 - train acc: 0.95 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.14 - train acc: 0.98 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.14 - train acc: 0.98 val acc: 0.96:   7%|▋         | 2/30 [00:00<00:08,  3.33it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.21 - train acc: 0.95 val acc: 0.98:   7%|▋         | 2/30 [00:00<00:12,  2.25it/s]\n",
      "Epoch 28: - train loss: 0.14 val loss: 0.14 - train acc: 0.98 val acc: 0.98:   7%|▋         | 2/30 [00:01<00:16,  1.70it/s]\n",
      "Epoch 28: - train loss: 0.14 val loss: 0.14 - train acc: 0.98 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:07,  3.40it/s]\n",
      "Epoch 28: - train loss: 0.15 val loss: 0.17 - train acc: 0.97 val acc: 0.95:  13%|█▎        | 4/30 [00:01<00:09,  2.73it/s]\n",
      "Epoch 28: - train loss: 0.13 val loss: 0.14 - train acc: 0.97 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:11,  2.28it/s]\n",
      "Epoch 28: - train loss: 0.13 val loss: 0.14 - train acc: 0.97 val acc: 0.98:  20%|██        | 6/30 [00:01<00:07,  3.41it/s]\n",
      "Epoch 28: - train loss: 0.18 val loss: 0.15 - train acc: 0.95 val acc: 0.98:  20%|██        | 6/30 [00:02<00:08,  2.93it/s]\n",
      "Epoch 28: - train loss: 0.18 val loss: 0.16 - train acc: 0.96 val acc: 0.97:  20%|██        | 6/30 [00:02<00:09,  2.57it/s]\n",
      "Epoch 28: - train loss: 0.18 val loss: 0.16 - train acc: 0.96 val acc: 0.97:  27%|██▋       | 8/30 [00:02<00:06,  3.42it/s]\n",
      "Epoch 28: - train loss: 0.20 val loss: 0.14 - train acc: 0.95 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:07,  3.01it/s]\n",
      "Epoch 28: - train loss: 0.19 val loss: 0.12 - train acc: 0.94 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:08,  2.70it/s]\n",
      "Epoch 28: - train loss: 0.19 val loss: 0.12 - train acc: 0.94 val acc: 0.98:  33%|███▎      | 10/30 [00:02<00:05,  3.37it/s]\n",
      "Epoch 28: - train loss: 0.15 val loss: 0.12 - train acc: 0.96 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:06,  3.06it/s]\n",
      "Epoch 28: - train loss: 0.15 val loss: 0.22 - train acc: 0.97 val acc: 0.95:  33%|███▎      | 10/30 [00:03<00:07,  2.79it/s]\n",
      "Epoch 28: - train loss: 0.15 val loss: 0.22 - train acc: 0.97 val acc: 0.95:  40%|████      | 12/30 [00:03<00:05,  3.35it/s]\n",
      "Epoch 28: - train loss: 0.19 val loss: 0.13 - train acc: 0.98 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.08it/s]\n",
      "Epoch 28: - train loss: 0.15 val loss: 0.21 - train acc: 0.96 val acc: 0.95:  40%|████      | 12/30 [00:04<00:06,  2.87it/s]\n",
      "Epoch 28: - train loss: 0.15 val loss: 0.21 - train acc: 0.96 val acc: 0.95:  47%|████▋     | 14/30 [00:04<00:04,  3.34it/s]\n",
      "Epoch 28: - train loss: 0.24 val loss: 0.14 - train acc: 0.94 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  3.11it/s]\n",
      "Epoch 28: - train loss: 0.12 val loss: 0.14 - train acc: 0.98 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  2.90it/s]\n",
      "Epoch 28: - train loss: 0.12 val loss: 0.14 - train acc: 0.98 val acc: 0.98:  53%|█████▎    | 16/30 [00:04<00:04,  3.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: - train loss: 0.15 val loss: 0.13 - train acc: 0.98 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.13it/s]\n",
      "Epoch 28: - train loss: 0.16 val loss: 0.13 - train acc: 0.98 val acc: 0.98:  53%|█████▎    | 16/30 [00:05<00:04,  2.96it/s]\n",
      "Epoch 28: - train loss: 0.16 val loss: 0.13 - train acc: 0.98 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.33it/s]\n",
      "Epoch 28: - train loss: 0.16 val loss: 0.24 - train acc: 0.95 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.16it/s]\n",
      "Epoch 28: - train loss: 0.13 val loss: 0.28 - train acc: 0.98 val acc: 0.93:  60%|██████    | 18/30 [00:06<00:04,  2.99it/s]\n",
      "Epoch 28: - train loss: 0.13 val loss: 0.28 - train acc: 0.98 val acc: 0.93:  67%|██████▋   | 20/30 [00:06<00:03,  3.32it/s]\n",
      "Epoch 28: - train loss: 0.19 val loss: 0.16 - train acc: 0.95 val acc: 0.95:  67%|██████▋   | 20/30 [00:06<00:03,  3.16it/s]\n",
      "Epoch 28: - train loss: 0.10 val loss: 0.14 - train acc: 0.99 val acc: 0.97:  67%|██████▋   | 20/30 [00:06<00:03,  3.01it/s]\n",
      "Epoch 28: - train loss: 0.10 val loss: 0.14 - train acc: 0.99 val acc: 0.97:  73%|███████▎  | 22/30 [00:06<00:02,  3.31it/s]\n",
      "Epoch 28: - train loss: 0.10 val loss: 0.15 - train acc: 0.99 val acc: 0.97:  73%|███████▎  | 22/30 [00:06<00:02,  3.16it/s]\n",
      "Epoch 28: - train loss: 0.19 val loss: 0.23 - train acc: 0.96 val acc: 0.94:  73%|███████▎  | 22/30 [00:07<00:02,  3.03it/s]\n",
      "Epoch 28: - train loss: 0.19 val loss: 0.23 - train acc: 0.96 val acc: 0.94:  80%|████████  | 24/30 [00:07<00:01,  3.31it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.18 - train acc: 0.96 val acc: 0.96:  80%|████████  | 24/30 [00:07<00:01,  3.18it/s]\n",
      "Epoch 28: - train loss: 0.13 val loss: 0.20 - train acc: 0.98 val acc: 0.95:  80%|████████  | 24/30 [00:07<00:01,  3.06it/s]\n",
      "Epoch 28: - train loss: 0.13 val loss: 0.20 - train acc: 0.98 val acc: 0.95:  87%|████████▋ | 26/30 [00:07<00:01,  3.32it/s]\n",
      "Epoch 28: - train loss: 0.20 val loss: 0.20 - train acc: 0.95 val acc: 0.95:  87%|████████▋ | 26/30 [00:08<00:01,  3.20it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.17 - train acc: 0.97 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.09it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.17 - train acc: 0.97 val acc: 0.96:  93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s]\n",
      "Epoch 28: - train loss: 0.28 val loss: 0.14 - train acc: 0.93 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.21it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.15 - train acc: 0.98 val acc: 0.95:  93%|█████████▎| 28/30 [00:09<00:00,  3.11it/s]\n",
      "Epoch 28: - train loss: 0.17 val loss: 0.15 - train acc: 0.98 val acc: 0.95: 100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
      "Training progress:  97%|█████████▋| 29/30 [04:22<00:09,  9.06s/it]\n",
      "Epoch 29:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.18 - train acc: 0.96 val acc: 0.96:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.16 - train acc: 0.99 val acc: 0.97:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.16 - train acc: 0.99 val acc: 0.97:   7%|▋         | 2/30 [00:00<00:08,  3.30it/s]\n",
      "Epoch 29: - train loss: 0.19 val loss: 0.12 - train acc: 0.98 val acc: 0.98:   7%|▋         | 2/30 [00:00<00:12,  2.23it/s]\n",
      "Epoch 29: - train loss: 0.22 val loss: 0.13 - train acc: 0.95 val acc: 0.98:   7%|▋         | 2/30 [00:01<00:16,  1.65it/s]\n",
      "Epoch 29: - train loss: 0.22 val loss: 0.13 - train acc: 0.95 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:07,  3.29it/s]\n",
      "Epoch 29: - train loss: 0.23 val loss: 0.12 - train acc: 0.93 val acc: 0.98:  13%|█▎        | 4/30 [00:01<00:09,  2.65it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.22 - train acc: 0.96 val acc: 0.93:  13%|█▎        | 4/30 [00:01<00:11,  2.22it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.22 - train acc: 0.96 val acc: 0.93:  20%|██        | 6/30 [00:01<00:07,  3.32it/s]\n",
      "Epoch 29: - train loss: 0.11 val loss: 0.19 - train acc: 0.98 val acc: 0.96:  20%|██        | 6/30 [00:02<00:08,  2.83it/s]\n",
      "Epoch 29: - train loss: 0.17 val loss: 0.08 - train acc: 0.98 val acc: 1.00:  20%|██        | 6/30 [00:02<00:09,  2.49it/s]\n",
      "Epoch 29: - train loss: 0.17 val loss: 0.08 - train acc: 0.98 val acc: 1.00:  27%|██▋       | 8/30 [00:02<00:06,  3.31it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.11 - train acc: 0.96 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:07,  2.95it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.12 - train acc: 0.97 val acc: 0.98:  27%|██▋       | 8/30 [00:02<00:08,  2.67it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.12 - train acc: 0.97 val acc: 0.98:  33%|███▎      | 10/30 [00:02<00:05,  3.34it/s]\n",
      "Epoch 29: - train loss: 0.16 val loss: 0.12 - train acc: 0.97 val acc: 0.98:  33%|███▎      | 10/30 [00:03<00:06,  3.02it/s]\n",
      "Epoch 29: - train loss: 0.13 val loss: 0.21 - train acc: 0.98 val acc: 0.94:  33%|███▎      | 10/30 [00:03<00:07,  2.76it/s]\n",
      "Epoch 29: - train loss: 0.13 val loss: 0.21 - train acc: 0.98 val acc: 0.94:  40%|████      | 12/30 [00:03<00:05,  3.30it/s]\n",
      "Epoch 29: - train loss: 0.14 val loss: 0.17 - train acc: 0.95 val acc: 0.96:  40%|████      | 12/30 [00:03<00:05,  3.04it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.11 - train acc: 0.94 val acc: 0.98:  40%|████      | 12/30 [00:04<00:06,  2.81it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.11 - train acc: 0.94 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:04,  3.28it/s]\n",
      "Epoch 29: - train loss: 0.17 val loss: 0.21 - train acc: 0.95 val acc: 0.93:  47%|████▋     | 14/30 [00:04<00:05,  3.07it/s]\n",
      "Epoch 29: - train loss: 0.24 val loss: 0.12 - train acc: 0.93 val acc: 0.98:  47%|████▋     | 14/30 [00:04<00:05,  2.89it/s]\n",
      "Epoch 29: - train loss: 0.24 val loss: 0.12 - train acc: 0.93 val acc: 0.98:  53%|█████▎    | 16/30 [00:04<00:04,  3.30it/s]\n",
      "Epoch 29: - train loss: 0.20 val loss: 0.18 - train acc: 0.95 val acc: 0.95:  53%|█████▎    | 16/30 [00:05<00:04,  3.11it/s]\n",
      "Epoch 29: - train loss: 0.24 val loss: 0.17 - train acc: 0.94 val acc: 0.94:  53%|█████▎    | 16/30 [00:05<00:04,  2.95it/s]\n",
      "Epoch 29: - train loss: 0.24 val loss: 0.17 - train acc: 0.94 val acc: 0.94:  60%|██████    | 18/30 [00:05<00:03,  3.31it/s]\n",
      "Epoch 29: - train loss: 0.24 val loss: 0.14 - train acc: 0.95 val acc: 0.98:  60%|██████    | 18/30 [00:05<00:03,  3.14it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.11 - train acc: 0.95 val acc: 0.98:  60%|██████    | 18/30 [00:06<00:04,  2.99it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.11 - train acc: 0.95 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.32it/s]\n",
      "Epoch 29: - train loss: 0.17 val loss: 0.15 - train acc: 0.96 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.17it/s]\n",
      "Epoch 29: - train loss: 0.11 val loss: 0.15 - train acc: 0.98 val acc: 0.98:  67%|██████▋   | 20/30 [00:06<00:03,  3.02it/s]\n",
      "Epoch 29: - train loss: 0.11 val loss: 0.15 - train acc: 0.98 val acc: 0.98:  73%|███████▎  | 22/30 [00:06<00:02,  3.32it/s]\n",
      "Epoch 29: - train loss: 0.14 val loss: 0.11 - train acc: 0.98 val acc: 0.97:  73%|███████▎  | 22/30 [00:06<00:02,  3.18it/s]\n",
      "Epoch 29: - train loss: 0.10 val loss: 0.28 - train acc: 1.00 val acc: 0.91:  73%|███████▎  | 22/30 [00:07<00:02,  3.05it/s]\n",
      "Epoch 29: - train loss: 0.10 val loss: 0.28 - train acc: 1.00 val acc: 0.91:  80%|████████  | 24/30 [00:07<00:01,  3.32it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.11 - train acc: 0.96 val acc: 0.97:  80%|████████  | 24/30 [00:07<00:01,  3.20it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.16 - train acc: 0.97 val acc: 0.98:  80%|████████  | 24/30 [00:07<00:01,  3.08it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.16 - train acc: 0.97 val acc: 0.98:  87%|████████▋ | 26/30 [00:07<00:01,  3.33it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.15 - train acc: 0.96 val acc: 0.96:  87%|████████▋ | 26/30 [00:08<00:01,  3.20it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.11 - train acc: 0.97 val acc: 0.98:  87%|████████▋ | 26/30 [00:08<00:01,  3.09it/s]\n",
      "Epoch 29: - train loss: 0.15 val loss: 0.11 - train acc: 0.97 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.33it/s]\n",
      "Epoch 29: - train loss: 0.18 val loss: 0.14 - train acc: 0.97 val acc: 0.98:  93%|█████████▎| 28/30 [00:08<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: - train loss: 0.13 val loss: 0.11 - train acc: 0.96 val acc: 0.99:  93%|█████████▎| 28/30 [00:09<00:00,  3.11it/s]\n",
      "Epoch 29: - train loss: 0.13 val loss: 0.11 - train acc: 0.96 val acc: 0.99: 100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
      "Training progress: 100%|██████████| 30/30 [04:31<00:00,  9.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "scatternet_define_flags() \n",
    "scatternet_classifier = scatternet_train()  # no pretrained weights for the hybrid scatter net so we do not need to specify a k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE VISUALIZATION\n",
    "Sample some data points from MNIST to map to a feature space with both of our classifiers. Once we have both of these new feature spaces we can use TSNE to reduce dimensionality to a space easily visualized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on 50 layer residual network features\n",
    "Looks like we are forming some clusters of each of the classes however there is some overlap. Multiple clusters are being formed for some of the classes. Some interesting future work could be a more in depth cluster analysis. There looks to be 2 different clusters for images representing 4s. Perhaps one cluster contains 4s that are straight while another could be slanted 4s. It coudl also be interesting to look at the images of the points which overlap between class clusters. Perhaps 4s and 9s are indeed quite similar. It is easy to visualize a 4 sloppily drawn to look very similar to a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/feature_viz/resnet/mnist_ckpt_block3/mnist-4200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d32ce2630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d2edec6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph(); resnet_classifier_k.load() # have to save and load b/c of conflicting params between resnets\n",
    "\n",
    "resnet_k_features_test = resnet_classifier_k.get_features(x_test)\n",
    "visualize_features(resnet_k_features_test, y_test, 'resnet50_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on unfrozen 50 layer residual network features\n",
    "It appears that we generate far better separation between classes with the unfrozen residual network. I suspect that this is the case because the MNIST dataset did not impose a data constraint on us. However, if we were to significantly reduce access to data I suspect that the frozen residual network would provide better features. We still experience a cluster overlap between clusters albeit less than in the case of frozen weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/feature_viz/resnet/mnist_ckpt_block0/mnist-4200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d3171afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d2edaa978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph(); resnet_classifier_0.load() # have to save and load b/c of conflicting params between resnets\\\n",
    "\n",
    "resnet_0_features_test = resnet_classifier_0.get_features(x_test)\n",
    "visualize_features(resnet_0_features_test, y_test, 'resnet50_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on Deep Hybrid Network\n",
    "Class separation is strong here but not quite as dense as we experienced in our 50 layer residual network. Perhaps this is because the deep hybrid network is far shallower than our 50 layer resnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d2edec208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d308a75c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatternet_features_test = scatternet_classifier.get_features(x_test)\n",
    "visualize_features(scatternet_features_test, y_test, 'scatternet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE CLASSIFICATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train images and labels\n",
    "collect a batch of training images we can use as a training set for the logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = mnist.train.next_batch(1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Neural Network & Logistic Regression\n",
    "The score function we use for comparison is just the mean number of labels correctly assigned to the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(train_features, train_labels, test_features, test_labels):\n",
    "    lm = sklearn.linear_model.LogisticRegression(multi_class='multinomial', solver='saga')\n",
    "    lm.fit(train_features, train_labels)\n",
    "    score = lm.score(test_features, test_labels)\n",
    "    return score\n",
    "\n",
    "def NN_score(nn, x_test, test_labels):\n",
    "    '''\n",
    "    nn here either represents the resnet or hybrid scatter network. Here we call them to generate a mean accuracy\n",
    "    \n",
    "    we don't submit the same test features here because the network is deterministic and will generate the same\n",
    "    intermediate features during the forward pass\n",
    "    '''\n",
    "    return nn.score(x_test, test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Hybrid Scatter Network: logistic regression vs fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression on deep hybrid scatter network features accuracy:  0.96875\n",
      "fully connected neural network stacked on scatter network features accuracy:  0.9664062\n"
     ]
    }
   ],
   "source": [
    "scatternet_features_train = scatternet_classifier.get_features(x_train)\n",
    "\n",
    "lm_scatternet_score = logistic_regression(scatternet_features_train, y_train, scatternet_features_test, y_test)\n",
    "print('logistic regression on deep hybrid scatter network features accuracy: ', lm_scatternet_score)\n",
    "\n",
    "nn_scatternet_score = NN_score(scatternet_classifier, x_test, y_test)\n",
    "print('fully connected neural network stacked on scatter network features accuracy: ', nn_scatternet_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen block K resnet: logistic regression vs fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/feature_viz/resnet/mnist_ckpt_block3/mnist-4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression on frozen resnet features accuracy:  0.96015625\n",
      "fully connected neural network stacked on frozen resnet features accuracy:  0.9429687\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph(); resnet_classifier_k.load() # have to save and load b/c of conflicting params between resnets\n",
    "resnet_k_features_train = resnet_classifier_k.get_features(x_train)\n",
    "\n",
    "lm_res_k_score = logistic_regression(resnet_k_features_train, y_train, resnet_k_features_test, y_test)\n",
    "print('logistic regression on frozen resnet features accuracy: ', lm_res_k_score)\n",
    "\n",
    "nn_res_k_score = NN_score(resnet_classifier_k, x_test, y_test)\n",
    "print('fully connected neural network stacked on frozen resnet features accuracy: ', nn_res_k_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfrozen resnet: logistic regression vs fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/feature_viz/resnet/mnist_ckpt_block0/mnist-4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression on unfrozen resnet features accuracy:  0.98828125\n",
      "fully connected neural network stacked on unfrozen resnet features accuracy:  0.98515624\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph(); resnet_classifier_0.load() # have to save and load b/c of conflicting params between resnets\n",
    "resnet_0_features_train = resnet_classifier_0.get_features(x_train)\n",
    "\n",
    "lm_res_0_score = logistic_regression(resnet_0_features_train, y_train, resnet_0_features_test, y_test)\n",
    "print('logistic regression on unfrozen resnet features accuracy: ', lm_res_0_score)\n",
    "\n",
    "nn_res_0_score = NN_score(resnet_classifier_0, x_test, y_test)\n",
    "print('fully connected neural network stacked on unfrozen resnet features accuracy: ', nn_res_0_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "In our analysis we compared 6 different types of classifiers. The 6 classifiers fell into a few different sub groups. First, the features were either generated from a 50 layer residual network or a deep hybrid network. Second The variables included in the 50 layer residual network were either frozen if they belonged to a layer earlier than K or they were initialized but left free to train. Third, the actual classification was done in one of two ways. The first choice of classification was using a basic multiclass logistic regression model. Our logistic regression model used saga for optimization. More information about saga can be read [here](https://www.di.ens.fr/~fbach/Defazio_NIPS2014.pdf) in a 2014 NIPs paper. The second choice of classification was using a multilayer fully connected neural network.\n",
    "\n",
    "The frozen residual network and the deep hybrid network performed very similarly. It is unclear which of these two is actually supperior at this task. The Deep Hybrid Network performed marginally better, but hyperparams and preprocessing were optized for MNIST. While in the case of the residual network there was no preprocessing techniques used aside from copying gray scale representations to 3 channels to be compatible with pretrained imagenet weights. Hyperparameters were also left as default for the residual network. I am also unsure if any image preprocessing techniques were used when training the initialized residual network on imagenet. For example we did not apply mean shifting to mnist images and if mean shifting each channel was used during pretraining this could render the initialized weights less than useful.\n",
    "\n",
    "The unfrozen residual network has come out as the clear champion for extracting features. We suspect that it trumps the frozen residual network because the task at hand does not have a data constraint which could incentivise us to concetrate our efforts on optimizing a subset of the weights.\n",
    "\n",
    "Interestingly Our logistic regression classifier outperforms the multi-layer neural network. I suspect this is because the features generated in all cases(frozen resnet, unfrozen resnet, and deep hybrid network) are close to being linearly separable. The logistic regression classifier we use comes with some handy regularization techniques out of the box. I suspect that the reason the logistic regression classifier outperforms the neural network is because of these regularizers. The training error reached by the residual networks is extremely close to 1 while the test error plateus suggesting we may be overfitting to noise in the training data. Some interesting next steps to close this performance gap could be introducing l2 regularization on the weights, dropout, and some image augmentations.\n",
    "\n",
    "Another interesting next piece of work would be to make a comparison between the features generated by a basic Scattering Convolutional Network with a Deep Hybrid Network.\n",
    "\n",
    "The performance we reached in this paper was short of what others have reported online and in other papers. I suspect this has to do with our lack of regularizers, image augmentations, hyperparameter search, and a relatively short training time.\n",
    "\n",
    "| Frozen Resnet LR | Frozen Resnet NN | Unfrozen Resnet LR | Unfrozen Resnet NN | Deep Hybrid Network LR | Deep Hybrid Network NN\n",
    "------------ | ------------- | ------------- | ------------- | ------------- | ------------- |\n",
    "test | 0.96015625 | 0.9429687 | 0.98828125 | 0.98515624 | 0.96875 | 0.9664062  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
